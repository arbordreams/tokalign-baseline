{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 10,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0004,
      "grad_norm": 0.45103724846952004,
      "learning_rate": 6.666666666666667e-07,
      "loss": 2.1772,
      "step": 1
    },
    {
      "epoch": 0.0008,
      "grad_norm": 0.4675288113886871,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 2.2104,
      "step": 2
    },
    {
      "epoch": 0.0012,
      "grad_norm": 0.46014787461188844,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 2.231,
      "step": 3
    },
    {
      "epoch": 0.0016,
      "grad_norm": 0.4579820420018304,
      "learning_rate": 2.666666666666667e-06,
      "loss": 2.2217,
      "step": 4
    },
    {
      "epoch": 0.002,
      "grad_norm": 0.45409338227668117,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 2.2856,
      "step": 5
    },
    {
      "epoch": 0.0024,
      "grad_norm": 0.4380131919139561,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.3062,
      "step": 6
    },
    {
      "epoch": 0.0028,
      "grad_norm": 0.4385290201091863,
      "learning_rate": 4.666666666666667e-06,
      "loss": 2.1655,
      "step": 7
    },
    {
      "epoch": 0.0032,
      "grad_norm": 0.4661229021225603,
      "learning_rate": 5.333333333333334e-06,
      "loss": 2.2168,
      "step": 8
    },
    {
      "epoch": 0.0036,
      "grad_norm": 0.4380541624555055,
      "learning_rate": 6e-06,
      "loss": 2.2344,
      "step": 9
    },
    {
      "epoch": 0.004,
      "grad_norm": 0.44438713485777465,
      "learning_rate": 6.666666666666667e-06,
      "loss": 2.2754,
      "step": 10
    },
    {
      "epoch": 0.0044,
      "grad_norm": 0.47413510845067897,
      "learning_rate": 7.333333333333334e-06,
      "loss": 2.3076,
      "step": 11
    },
    {
      "epoch": 0.0048,
      "grad_norm": 0.459166917655834,
      "learning_rate": 8.000000000000001e-06,
      "loss": 2.2119,
      "step": 12
    },
    {
      "epoch": 0.0052,
      "grad_norm": 0.5150223712752987,
      "learning_rate": 8.666666666666668e-06,
      "loss": 2.2373,
      "step": 13
    },
    {
      "epoch": 0.0056,
      "grad_norm": 0.4779589324716575,
      "learning_rate": 9.333333333333334e-06,
      "loss": 2.2632,
      "step": 14
    },
    {
      "epoch": 0.006,
      "grad_norm": 0.4806136743131945,
      "learning_rate": 1e-05,
      "loss": 2.1406,
      "step": 15
    },
    {
      "epoch": 0.0064,
      "grad_norm": 0.5187825895754657,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 2.1108,
      "step": 16
    },
    {
      "epoch": 0.0068,
      "grad_norm": 0.48628435714289914,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 2.1802,
      "step": 17
    },
    {
      "epoch": 0.0072,
      "grad_norm": 0.5309840734312661,
      "learning_rate": 1.2e-05,
      "loss": 2.2563,
      "step": 18
    },
    {
      "epoch": 0.0076,
      "grad_norm": 0.5026152310637446,
      "learning_rate": 1.2666666666666668e-05,
      "loss": 2.2505,
      "step": 19
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.49372761053778663,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 2.251,
      "step": 20
    },
    {
      "epoch": 0.0084,
      "grad_norm": 0.5000002995839812,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 2.2793,
      "step": 21
    },
    {
      "epoch": 0.0088,
      "grad_norm": 0.47419915397124546,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 2.1035,
      "step": 22
    },
    {
      "epoch": 0.0092,
      "grad_norm": 0.5101596529101995,
      "learning_rate": 1.5333333333333334e-05,
      "loss": 2.1719,
      "step": 23
    },
    {
      "epoch": 0.0096,
      "grad_norm": 0.5542545979355025,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 2.2319,
      "step": 24
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5105083059581869,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 2.1968,
      "step": 25
    },
    {
      "epoch": 0.0104,
      "grad_norm": 0.5375074762028615,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 2.21,
      "step": 26
    },
    {
      "epoch": 0.0108,
      "grad_norm": 0.4910550653315533,
      "learning_rate": 1.8e-05,
      "loss": 2.2539,
      "step": 27
    },
    {
      "epoch": 0.0112,
      "grad_norm": 0.6012887431618006,
      "learning_rate": 1.866666666666667e-05,
      "loss": 2.2192,
      "step": 28
    },
    {
      "epoch": 0.0116,
      "grad_norm": 0.5243779319322337,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 2.2397,
      "step": 29
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.545591644765943,
      "learning_rate": 2e-05,
      "loss": 2.23,
      "step": 30
    },
    {
      "epoch": 0.0124,
      "grad_norm": 0.6428958256955664,
      "learning_rate": 2.0666666666666666e-05,
      "loss": 2.3398,
      "step": 31
    },
    {
      "epoch": 0.0128,
      "grad_norm": 0.6020450897652233,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 2.2061,
      "step": 32
    },
    {
      "epoch": 0.0132,
      "grad_norm": 0.5139258084627687,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 2.1846,
      "step": 33
    },
    {
      "epoch": 0.0136,
      "grad_norm": 0.5240220338418644,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 2.2031,
      "step": 34
    },
    {
      "epoch": 0.014,
      "grad_norm": 0.5765269213268828,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 2.209,
      "step": 35
    },
    {
      "epoch": 0.0144,
      "grad_norm": 0.5064794413768402,
      "learning_rate": 2.4e-05,
      "loss": 2.1919,
      "step": 36
    },
    {
      "epoch": 0.0148,
      "grad_norm": 0.5344951777778929,
      "learning_rate": 2.466666666666667e-05,
      "loss": 2.2349,
      "step": 37
    },
    {
      "epoch": 0.0152,
      "grad_norm": 0.5015468016876293,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 2.2622,
      "step": 38
    },
    {
      "epoch": 0.0156,
      "grad_norm": 0.5777425408228702,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 2.2378,
      "step": 39
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.5982081854905135,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 2.252,
      "step": 40
    },
    {
      "epoch": 0.0164,
      "grad_norm": 0.5080634846265522,
      "learning_rate": 2.733333333333333e-05,
      "loss": 2.0894,
      "step": 41
    },
    {
      "epoch": 0.0168,
      "grad_norm": 0.5349171586421472,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 2.228,
      "step": 42
    },
    {
      "epoch": 0.0172,
      "grad_norm": 0.5811085357351895,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 2.335,
      "step": 43
    },
    {
      "epoch": 0.0176,
      "grad_norm": 0.6502986644794774,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 2.2651,
      "step": 44
    },
    {
      "epoch": 0.018,
      "grad_norm": 0.49209297378686473,
      "learning_rate": 3e-05,
      "loss": 2.2114,
      "step": 45
    },
    {
      "epoch": 0.0184,
      "grad_norm": 0.6329214035218113,
      "learning_rate": 3.066666666666667e-05,
      "loss": 2.2739,
      "step": 46
    },
    {
      "epoch": 0.0188,
      "grad_norm": 0.5493629662515459,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 2.2109,
      "step": 47
    },
    {
      "epoch": 0.0192,
      "grad_norm": 0.5995444664131713,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 2.1899,
      "step": 48
    },
    {
      "epoch": 0.0196,
      "grad_norm": 0.6497459398387524,
      "learning_rate": 3.266666666666667e-05,
      "loss": 2.2876,
      "step": 49
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6038006160791234,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 2.2773,
      "step": 50
    },
    {
      "epoch": 0.0204,
      "grad_norm": 0.576631792123866,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 2.2119,
      "step": 51
    },
    {
      "epoch": 0.0208,
      "grad_norm": 0.5284349319054233,
      "learning_rate": 3.466666666666667e-05,
      "loss": 2.1782,
      "step": 52
    },
    {
      "epoch": 0.0212,
      "grad_norm": 0.6052742125486996,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 2.1577,
      "step": 53
    },
    {
      "epoch": 0.0216,
      "grad_norm": 0.5741401943257387,
      "learning_rate": 3.6e-05,
      "loss": 2.2393,
      "step": 54
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.5262740561938919,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 2.2363,
      "step": 55
    },
    {
      "epoch": 0.0224,
      "grad_norm": 0.5514907695225559,
      "learning_rate": 3.733333333333334e-05,
      "loss": 2.228,
      "step": 56
    },
    {
      "epoch": 0.0228,
      "grad_norm": 0.5869791536913241,
      "learning_rate": 3.8e-05,
      "loss": 2.2271,
      "step": 57
    },
    {
      "epoch": 0.0232,
      "grad_norm": 0.5376612397326634,
      "learning_rate": 3.866666666666667e-05,
      "loss": 2.2739,
      "step": 58
    },
    {
      "epoch": 0.0236,
      "grad_norm": 0.5192390213428048,
      "learning_rate": 3.933333333333333e-05,
      "loss": 2.2397,
      "step": 59
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.5526532031701553,
      "learning_rate": 4e-05,
      "loss": 2.2139,
      "step": 60
    },
    {
      "epoch": 0.0244,
      "grad_norm": 0.5276531353317189,
      "learning_rate": 4.066666666666667e-05,
      "loss": 2.2192,
      "step": 61
    },
    {
      "epoch": 0.0248,
      "grad_norm": 0.5566966360581125,
      "learning_rate": 4.133333333333333e-05,
      "loss": 2.2178,
      "step": 62
    },
    {
      "epoch": 0.0252,
      "grad_norm": 0.5281533249087984,
      "learning_rate": 4.2e-05,
      "loss": 2.1655,
      "step": 63
    },
    {
      "epoch": 0.0256,
      "grad_norm": 0.5613282402610525,
      "learning_rate": 4.266666666666667e-05,
      "loss": 2.2363,
      "step": 64
    },
    {
      "epoch": 0.026,
      "grad_norm": 0.5580628116918435,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 2.167,
      "step": 65
    },
    {
      "epoch": 0.0264,
      "grad_norm": 0.553872414615729,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 2.2036,
      "step": 66
    },
    {
      "epoch": 0.0268,
      "grad_norm": 0.6268237872928947,
      "learning_rate": 4.466666666666667e-05,
      "loss": 2.2339,
      "step": 67
    },
    {
      "epoch": 0.0272,
      "grad_norm": 0.5726970399041682,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 2.2183,
      "step": 68
    },
    {
      "epoch": 0.0276,
      "grad_norm": 0.5662687189306598,
      "learning_rate": 4.600000000000001e-05,
      "loss": 2.2529,
      "step": 69
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.6147660030066138,
      "learning_rate": 4.666666666666667e-05,
      "loss": 2.2466,
      "step": 70
    },
    {
      "epoch": 0.0284,
      "grad_norm": 0.5875801626573526,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 2.3052,
      "step": 71
    },
    {
      "epoch": 0.0288,
      "grad_norm": 0.6475744777581661,
      "learning_rate": 4.8e-05,
      "loss": 2.252,
      "step": 72
    },
    {
      "epoch": 0.0292,
      "grad_norm": 0.7658225050431915,
      "learning_rate": 4.866666666666667e-05,
      "loss": 2.269,
      "step": 73
    },
    {
      "epoch": 0.0296,
      "grad_norm": 0.5706034322762908,
      "learning_rate": 4.933333333333334e-05,
      "loss": 2.1021,
      "step": 74
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7038813444349892,
      "learning_rate": 5e-05,
      "loss": 2.1562,
      "step": 75
    },
    {
      "epoch": 0.0304,
      "grad_norm": 0.6493952988729712,
      "learning_rate": 4.999997902093098e-05,
      "loss": 2.1875,
      "step": 76
    },
    {
      "epoch": 0.0308,
      "grad_norm": 0.5966166053257818,
      "learning_rate": 4.999991608375913e-05,
      "loss": 2.3027,
      "step": 77
    },
    {
      "epoch": 0.0312,
      "grad_norm": 0.7645207838058343,
      "learning_rate": 4.9999811188590075e-05,
      "loss": 2.1445,
      "step": 78
    },
    {
      "epoch": 0.0316,
      "grad_norm": 0.6262077898507258,
      "learning_rate": 4.9999664335599864e-05,
      "loss": 2.2529,
      "step": 79
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.6181179457082002,
      "learning_rate": 4.999947552503497e-05,
      "loss": 2.3047,
      "step": 80
    },
    {
      "epoch": 0.0324,
      "grad_norm": 0.7057154105809661,
      "learning_rate": 4.9999244757212273e-05,
      "loss": 2.2441,
      "step": 81
    },
    {
      "epoch": 0.0328,
      "grad_norm": 0.5835277614263052,
      "learning_rate": 4.999897203251908e-05,
      "loss": 2.2876,
      "step": 82
    },
    {
      "epoch": 0.0332,
      "grad_norm": 0.6918799337746308,
      "learning_rate": 4.999865735141311e-05,
      "loss": 2.188,
      "step": 83
    },
    {
      "epoch": 0.0336,
      "grad_norm": 0.6669285041188411,
      "learning_rate": 4.99983007144225e-05,
      "loss": 2.2368,
      "step": 84
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.5777370133451808,
      "learning_rate": 4.99979021221458e-05,
      "loss": 2.2876,
      "step": 85
    },
    {
      "epoch": 0.0344,
      "grad_norm": 0.6448314059637873,
      "learning_rate": 4.999746157525198e-05,
      "loss": 2.1216,
      "step": 86
    },
    {
      "epoch": 0.0348,
      "grad_norm": 0.5809939064933923,
      "learning_rate": 4.9996979074480425e-05,
      "loss": 2.1904,
      "step": 87
    },
    {
      "epoch": 0.0352,
      "grad_norm": 0.6819765856929352,
      "learning_rate": 4.9996454620640924e-05,
      "loss": 2.2012,
      "step": 88
    },
    {
      "epoch": 0.0356,
      "grad_norm": 0.5954201882909256,
      "learning_rate": 4.999588821461369e-05,
      "loss": 2.2334,
      "step": 89
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.579732195091237,
      "learning_rate": 4.999527985734932e-05,
      "loss": 2.1924,
      "step": 90
    },
    {
      "epoch": 0.0364,
      "grad_norm": 0.6626629764004188,
      "learning_rate": 4.999462954986884e-05,
      "loss": 2.269,
      "step": 91
    },
    {
      "epoch": 0.0368,
      "grad_norm": 0.8316561495939084,
      "learning_rate": 4.9993937293263695e-05,
      "loss": 2.2842,
      "step": 92
    },
    {
      "epoch": 0.0372,
      "grad_norm": 0.579952382912898,
      "learning_rate": 4.9993203088695696e-05,
      "loss": 2.146,
      "step": 93
    },
    {
      "epoch": 0.0376,
      "grad_norm": 0.635427119818226,
      "learning_rate": 4.999242693739709e-05,
      "loss": 2.3149,
      "step": 94
    },
    {
      "epoch": 0.038,
      "grad_norm": 0.5593205624768297,
      "learning_rate": 4.999160884067051e-05,
      "loss": 2.1714,
      "step": 95
    },
    {
      "epoch": 0.0384,
      "grad_norm": 0.6354659154206609,
      "learning_rate": 4.999074879988898e-05,
      "loss": 2.2021,
      "step": 96
    },
    {
      "epoch": 0.0388,
      "grad_norm": 0.5565833680623167,
      "learning_rate": 4.998984681649593e-05,
      "loss": 2.187,
      "step": 97
    },
    {
      "epoch": 0.0392,
      "grad_norm": 0.5889269060990729,
      "learning_rate": 4.9988902892005197e-05,
      "loss": 2.1704,
      "step": 98
    },
    {
      "epoch": 0.0396,
      "grad_norm": 0.5853636952614266,
      "learning_rate": 4.9987917028000974e-05,
      "loss": 2.2397,
      "step": 99
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6000204548882788,
      "learning_rate": 4.998688922613788e-05,
      "loss": 2.3604,
      "step": 100
    },
    {
      "epoch": 0.0404,
      "grad_norm": 0.5786125447857678,
      "learning_rate": 4.9985819488140876e-05,
      "loss": 2.249,
      "step": 101
    },
    {
      "epoch": 0.0408,
      "grad_norm": 0.5381827868421707,
      "learning_rate": 4.998470781580535e-05,
      "loss": 2.1001,
      "step": 102
    },
    {
      "epoch": 0.0412,
      "grad_norm": 0.5738903084691621,
      "learning_rate": 4.998355421099706e-05,
      "loss": 2.3057,
      "step": 103
    },
    {
      "epoch": 0.0416,
      "grad_norm": 0.5968928690793504,
      "learning_rate": 4.998235867565211e-05,
      "loss": 2.3721,
      "step": 104
    },
    {
      "epoch": 0.042,
      "grad_norm": 0.5753014741919557,
      "learning_rate": 4.998112121177699e-05,
      "loss": 2.1724,
      "step": 105
    },
    {
      "epoch": 0.0424,
      "grad_norm": 0.5682188176889041,
      "learning_rate": 4.997984182144859e-05,
      "loss": 2.1621,
      "step": 106
    },
    {
      "epoch": 0.0428,
      "grad_norm": 0.5800343590874095,
      "learning_rate": 4.997852050681414e-05,
      "loss": 2.2422,
      "step": 107
    },
    {
      "epoch": 0.0432,
      "grad_norm": 0.5512121451435689,
      "learning_rate": 4.997715727009122e-05,
      "loss": 2.3027,
      "step": 108
    },
    {
      "epoch": 0.0436,
      "grad_norm": 0.5436242523292705,
      "learning_rate": 4.997575211356781e-05,
      "loss": 2.1597,
      "step": 109
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.525191479716218,
      "learning_rate": 4.99743050396022e-05,
      "loss": 2.2295,
      "step": 110
    },
    {
      "epoch": 0.0444,
      "grad_norm": 0.5683429617862322,
      "learning_rate": 4.9972816050623054e-05,
      "loss": 2.2388,
      "step": 111
    },
    {
      "epoch": 0.0448,
      "grad_norm": 0.5336546703215378,
      "learning_rate": 4.997128514912938e-05,
      "loss": 2.1519,
      "step": 112
    },
    {
      "epoch": 0.0452,
      "grad_norm": 0.5617725194447177,
      "learning_rate": 4.996971233769053e-05,
      "loss": 2.2095,
      "step": 113
    },
    {
      "epoch": 0.0456,
      "grad_norm": 0.5370757127123894,
      "learning_rate": 4.9968097618946204e-05,
      "loss": 2.127,
      "step": 114
    },
    {
      "epoch": 0.046,
      "grad_norm": 0.572799208363289,
      "learning_rate": 4.9966440995606415e-05,
      "loss": 2.2959,
      "step": 115
    },
    {
      "epoch": 0.0464,
      "grad_norm": 0.5477276338046712,
      "learning_rate": 4.996474247045151e-05,
      "loss": 2.2075,
      "step": 116
    },
    {
      "epoch": 0.0468,
      "grad_norm": 0.5907691644209431,
      "learning_rate": 4.996300204633219e-05,
      "loss": 2.3472,
      "step": 117
    },
    {
      "epoch": 0.0472,
      "grad_norm": 0.544842041239876,
      "learning_rate": 4.996121972616943e-05,
      "loss": 2.2637,
      "step": 118
    },
    {
      "epoch": 0.0476,
      "grad_norm": 0.6739240727416335,
      "learning_rate": 4.9959395512954555e-05,
      "loss": 2.373,
      "step": 119
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.5577315495604707,
      "learning_rate": 4.995752940974918e-05,
      "loss": 2.2754,
      "step": 120
    },
    {
      "epoch": 0.0484,
      "grad_norm": 0.5211206831952457,
      "learning_rate": 4.9955621419685246e-05,
      "loss": 2.2197,
      "step": 121
    },
    {
      "epoch": 0.0488,
      "grad_norm": 0.6021931011060292,
      "learning_rate": 4.995367154596497e-05,
      "loss": 2.2227,
      "step": 122
    },
    {
      "epoch": 0.0492,
      "grad_norm": 0.5148700488844592,
      "learning_rate": 4.995167979186088e-05,
      "loss": 2.2192,
      "step": 123
    },
    {
      "epoch": 0.0496,
      "grad_norm": 0.5867865883261059,
      "learning_rate": 4.9949646160715794e-05,
      "loss": 2.2598,
      "step": 124
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5329341068280733,
      "learning_rate": 4.9947570655942796e-05,
      "loss": 2.251,
      "step": 125
    },
    {
      "epoch": 0.0504,
      "grad_norm": 0.5028171408648119,
      "learning_rate": 4.994545328102526e-05,
      "loss": 2.1572,
      "step": 126
    },
    {
      "epoch": 0.0508,
      "grad_norm": 0.5485729216840466,
      "learning_rate": 4.994329403951684e-05,
      "loss": 2.29,
      "step": 127
    },
    {
      "epoch": 0.0512,
      "grad_norm": 0.4959050622221551,
      "learning_rate": 4.994109293504143e-05,
      "loss": 2.2412,
      "step": 128
    },
    {
      "epoch": 0.0516,
      "grad_norm": 0.5344837330306825,
      "learning_rate": 4.993884997129322e-05,
      "loss": 2.2021,
      "step": 129
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.5792417275256196,
      "learning_rate": 4.993656515203662e-05,
      "loss": 2.2983,
      "step": 130
    },
    {
      "epoch": 0.0524,
      "grad_norm": 0.5944611933664032,
      "learning_rate": 4.99342384811063e-05,
      "loss": 2.3311,
      "step": 131
    },
    {
      "epoch": 0.0528,
      "grad_norm": 0.5194004219410845,
      "learning_rate": 4.9931869962407174e-05,
      "loss": 2.1484,
      "step": 132
    },
    {
      "epoch": 0.0532,
      "grad_norm": 0.5645392515751555,
      "learning_rate": 4.992945959991439e-05,
      "loss": 2.2129,
      "step": 133
    },
    {
      "epoch": 0.0536,
      "grad_norm": 0.5176434334689738,
      "learning_rate": 4.992700739767332e-05,
      "loss": 2.2026,
      "step": 134
    },
    {
      "epoch": 0.054,
      "grad_norm": 0.5443032027504578,
      "learning_rate": 4.9924513359799554e-05,
      "loss": 2.1567,
      "step": 135
    },
    {
      "epoch": 0.0544,
      "grad_norm": 0.5680723166405518,
      "learning_rate": 4.99219774904789e-05,
      "loss": 2.2734,
      "step": 136
    },
    {
      "epoch": 0.0548,
      "grad_norm": 0.5590516919407124,
      "learning_rate": 4.991939979396738e-05,
      "loss": 2.2769,
      "step": 137
    },
    {
      "epoch": 0.0552,
      "grad_norm": 0.6173045421734894,
      "learning_rate": 4.991678027459119e-05,
      "loss": 2.3291,
      "step": 138
    },
    {
      "epoch": 0.0556,
      "grad_norm": 0.593052059156479,
      "learning_rate": 4.991411893674675e-05,
      "loss": 2.229,
      "step": 139
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.5725573790478956,
      "learning_rate": 4.991141578490066e-05,
      "loss": 2.251,
      "step": 140
    },
    {
      "epoch": 0.0564,
      "grad_norm": 0.6088456541472143,
      "learning_rate": 4.9908670823589674e-05,
      "loss": 2.2109,
      "step": 141
    },
    {
      "epoch": 0.0568,
      "grad_norm": 0.5736780559665237,
      "learning_rate": 4.990588405742074e-05,
      "loss": 2.2227,
      "step": 142
    },
    {
      "epoch": 0.0572,
      "grad_norm": 0.5361477982121833,
      "learning_rate": 4.9903055491070946e-05,
      "loss": 2.1699,
      "step": 143
    },
    {
      "epoch": 0.0576,
      "grad_norm": 0.5885500363124349,
      "learning_rate": 4.990018512928755e-05,
      "loss": 2.228,
      "step": 144
    },
    {
      "epoch": 0.058,
      "grad_norm": 0.5165448618878756,
      "learning_rate": 4.989727297688797e-05,
      "loss": 2.1826,
      "step": 145
    },
    {
      "epoch": 0.0584,
      "grad_norm": 0.5906412866710755,
      "learning_rate": 4.989431903875972e-05,
      "loss": 2.209,
      "step": 146
    },
    {
      "epoch": 0.0588,
      "grad_norm": 1.0585669108970823,
      "learning_rate": 4.9891323319860496e-05,
      "loss": 2.2476,
      "step": 147
    },
    {
      "epoch": 0.0592,
      "grad_norm": 0.6107898604954097,
      "learning_rate": 4.988828582521806e-05,
      "loss": 2.2314,
      "step": 148
    },
    {
      "epoch": 0.0596,
      "grad_norm": 0.60043615734278,
      "learning_rate": 4.9885206559930355e-05,
      "loss": 2.2456,
      "step": 149
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.517644940134327,
      "learning_rate": 4.988208552916535e-05,
      "loss": 2.2534,
      "step": 150
    },
    {
      "epoch": 0.0604,
      "grad_norm": 0.5688829645975194,
      "learning_rate": 4.987892273816118e-05,
      "loss": 2.3257,
      "step": 151
    },
    {
      "epoch": 0.0608,
      "grad_norm": 0.5773896574925879,
      "learning_rate": 4.9875718192226026e-05,
      "loss": 2.2705,
      "step": 152
    },
    {
      "epoch": 0.0612,
      "grad_norm": 0.5468057091006545,
      "learning_rate": 4.9872471896738157e-05,
      "loss": 2.1636,
      "step": 153
    },
    {
      "epoch": 0.0616,
      "grad_norm": 0.5730117873723661,
      "learning_rate": 4.986918385714592e-05,
      "loss": 2.2666,
      "step": 154
    },
    {
      "epoch": 0.062,
      "grad_norm": 0.5859029146985696,
      "learning_rate": 4.986585407896772e-05,
      "loss": 2.3447,
      "step": 155
    },
    {
      "epoch": 0.0624,
      "grad_norm": 0.5170755904187502,
      "learning_rate": 4.986248256779199e-05,
      "loss": 2.271,
      "step": 156
    },
    {
      "epoch": 0.0628,
      "grad_norm": 0.5539039860719,
      "learning_rate": 4.985906932927724e-05,
      "loss": 2.2715,
      "step": 157
    },
    {
      "epoch": 0.0632,
      "grad_norm": 0.5661176744578335,
      "learning_rate": 4.985561436915199e-05,
      "loss": 2.3325,
      "step": 158
    },
    {
      "epoch": 0.0636,
      "grad_norm": 0.5419858601829749,
      "learning_rate": 4.985211769321479e-05,
      "loss": 2.1621,
      "step": 159
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.507854181966252,
      "learning_rate": 4.98485793073342e-05,
      "loss": 2.1855,
      "step": 160
    },
    {
      "epoch": 0.0644,
      "grad_norm": 0.5776572389569211,
      "learning_rate": 4.984499921744877e-05,
      "loss": 2.1924,
      "step": 161
    },
    {
      "epoch": 0.0648,
      "grad_norm": 0.5264279556952426,
      "learning_rate": 4.9841377429567085e-05,
      "loss": 2.2554,
      "step": 162
    },
    {
      "epoch": 0.0652,
      "grad_norm": 0.5449570481503988,
      "learning_rate": 4.983771394976766e-05,
      "loss": 2.0918,
      "step": 163
    },
    {
      "epoch": 0.0656,
      "grad_norm": 0.565382648887472,
      "learning_rate": 4.983400878419901e-05,
      "loss": 2.2749,
      "step": 164
    },
    {
      "epoch": 0.066,
      "grad_norm": 0.5990454288652223,
      "learning_rate": 4.9830261939079614e-05,
      "loss": 2.2021,
      "step": 165
    },
    {
      "epoch": 0.0664,
      "grad_norm": 0.56828851143311,
      "learning_rate": 4.98264734206979e-05,
      "loss": 2.2085,
      "step": 166
    },
    {
      "epoch": 0.0668,
      "grad_norm": 0.5843717310250761,
      "learning_rate": 4.982264323541223e-05,
      "loss": 2.2017,
      "step": 167
    },
    {
      "epoch": 0.0672,
      "grad_norm": 0.5996347496753532,
      "learning_rate": 4.98187713896509e-05,
      "loss": 2.2676,
      "step": 168
    },
    {
      "epoch": 0.0676,
      "grad_norm": 0.5633285889764026,
      "learning_rate": 4.981485788991214e-05,
      "loss": 2.251,
      "step": 169
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.5664001684063787,
      "learning_rate": 4.981090274276406e-05,
      "loss": 2.1846,
      "step": 170
    },
    {
      "epoch": 0.0684,
      "grad_norm": 0.543098015009821,
      "learning_rate": 4.9806905954844696e-05,
      "loss": 2.2573,
      "step": 171
    },
    {
      "epoch": 0.0688,
      "grad_norm": 0.5342287049725405,
      "learning_rate": 4.980286753286195e-05,
      "loss": 2.2109,
      "step": 172
    },
    {
      "epoch": 0.0692,
      "grad_norm": 0.500597286279495,
      "learning_rate": 4.979878748359361e-05,
      "loss": 2.1421,
      "step": 173
    },
    {
      "epoch": 0.0696,
      "grad_norm": 0.5141163036137953,
      "learning_rate": 4.9794665813887346e-05,
      "loss": 2.2505,
      "step": 174
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5218303045396046,
      "learning_rate": 4.9790502530660635e-05,
      "loss": 2.2993,
      "step": 175
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.5511077077969503,
      "learning_rate": 4.9786297640900825e-05,
      "loss": 2.1821,
      "step": 176
    },
    {
      "epoch": 0.0708,
      "grad_norm": 0.4832256181835357,
      "learning_rate": 4.978205115166511e-05,
      "loss": 2.1021,
      "step": 177
    },
    {
      "epoch": 0.0712,
      "grad_norm": 0.541798691592295,
      "learning_rate": 4.9777763070080465e-05,
      "loss": 2.1699,
      "step": 178
    },
    {
      "epoch": 0.0716,
      "grad_norm": 0.5126048345396819,
      "learning_rate": 4.977343340334369e-05,
      "loss": 2.2236,
      "step": 179
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.5460503840480366,
      "learning_rate": 4.976906215872138e-05,
      "loss": 2.2471,
      "step": 180
    },
    {
      "epoch": 0.0724,
      "grad_norm": 0.5308295590443194,
      "learning_rate": 4.976464934354989e-05,
      "loss": 2.2505,
      "step": 181
    },
    {
      "epoch": 0.0728,
      "grad_norm": 0.6080724811320686,
      "learning_rate": 4.976019496523538e-05,
      "loss": 2.1885,
      "step": 182
    },
    {
      "epoch": 0.0732,
      "grad_norm": 0.5550878372638889,
      "learning_rate": 4.975569903125373e-05,
      "loss": 2.2021,
      "step": 183
    },
    {
      "epoch": 0.0736,
      "grad_norm": 0.5620988322736408,
      "learning_rate": 4.97511615491506e-05,
      "loss": 2.2515,
      "step": 184
    },
    {
      "epoch": 0.074,
      "grad_norm": 0.5824561909274321,
      "learning_rate": 4.9746582526541355e-05,
      "loss": 2.1548,
      "step": 185
    },
    {
      "epoch": 0.0744,
      "grad_norm": 0.5528859661910047,
      "learning_rate": 4.9741961971111076e-05,
      "loss": 2.3047,
      "step": 186
    },
    {
      "epoch": 0.0748,
      "grad_norm": 0.6587489992351666,
      "learning_rate": 4.973729989061456e-05,
      "loss": 2.2202,
      "step": 187
    },
    {
      "epoch": 0.0752,
      "grad_norm": 0.5194652342641722,
      "learning_rate": 4.973259629287631e-05,
      "loss": 2.1992,
      "step": 188
    },
    {
      "epoch": 0.0756,
      "grad_norm": 0.548738197725554,
      "learning_rate": 4.9727851185790485e-05,
      "loss": 2.2339,
      "step": 189
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.5152556708037066,
      "learning_rate": 4.972306457732091e-05,
      "loss": 2.2549,
      "step": 190
    },
    {
      "epoch": 0.0764,
      "grad_norm": 0.5504543269852612,
      "learning_rate": 4.971823647550109e-05,
      "loss": 2.1631,
      "step": 191
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.5242013199981974,
      "learning_rate": 4.971336688843414e-05,
      "loss": 2.2441,
      "step": 192
    },
    {
      "epoch": 0.0772,
      "grad_norm": 0.574026407789556,
      "learning_rate": 4.970845582429282e-05,
      "loss": 2.2603,
      "step": 193
    },
    {
      "epoch": 0.0776,
      "grad_norm": 0.538481710416695,
      "learning_rate": 4.9703503291319483e-05,
      "loss": 2.2002,
      "step": 194
    },
    {
      "epoch": 0.078,
      "grad_norm": 0.5188429649397974,
      "learning_rate": 4.96985092978261e-05,
      "loss": 2.1938,
      "step": 195
    },
    {
      "epoch": 0.0784,
      "grad_norm": 0.6283873892252502,
      "learning_rate": 4.969347385219422e-05,
      "loss": 2.3037,
      "step": 196
    },
    {
      "epoch": 0.0788,
      "grad_norm": 0.5084540558598601,
      "learning_rate": 4.968839696287495e-05,
      "loss": 2.1865,
      "step": 197
    },
    {
      "epoch": 0.0792,
      "grad_norm": 0.5309730628259128,
      "learning_rate": 4.968327863838897e-05,
      "loss": 2.1904,
      "step": 198
    },
    {
      "epoch": 0.0796,
      "grad_norm": 0.5374812659917606,
      "learning_rate": 4.96781188873265e-05,
      "loss": 2.3105,
      "step": 199
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5653338878090028,
      "learning_rate": 4.967291771834727e-05,
      "loss": 2.2524,
      "step": 200
    },
    {
      "epoch": 0.0804,
      "grad_norm": 0.5210885898839513,
      "learning_rate": 4.9667675140180535e-05,
      "loss": 2.1626,
      "step": 201
    },
    {
      "epoch": 0.0808,
      "grad_norm": 0.562768916308657,
      "learning_rate": 4.966239116162506e-05,
      "loss": 2.3306,
      "step": 202
    },
    {
      "epoch": 0.0812,
      "grad_norm": 0.5033621825239467,
      "learning_rate": 4.965706579154907e-05,
      "loss": 2.1831,
      "step": 203
    },
    {
      "epoch": 0.0816,
      "grad_norm": 0.4909241909056604,
      "learning_rate": 4.965169903889027e-05,
      "loss": 2.1182,
      "step": 204
    },
    {
      "epoch": 0.082,
      "grad_norm": 0.5660292148882505,
      "learning_rate": 4.9646290912655834e-05,
      "loss": 2.2197,
      "step": 205
    },
    {
      "epoch": 0.0824,
      "grad_norm": 0.5305760560733863,
      "learning_rate": 4.964084142192234e-05,
      "loss": 2.2173,
      "step": 206
    },
    {
      "epoch": 0.0828,
      "grad_norm": 0.5347019470205164,
      "learning_rate": 4.9635350575835805e-05,
      "loss": 2.2583,
      "step": 207
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.5254478115819978,
      "learning_rate": 4.9629818383611674e-05,
      "loss": 2.2354,
      "step": 208
    },
    {
      "epoch": 0.0836,
      "grad_norm": 0.50988162133311,
      "learning_rate": 4.9624244854534744e-05,
      "loss": 2.1978,
      "step": 209
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.5478721249817043,
      "learning_rate": 4.9618629997959235e-05,
      "loss": 2.1777,
      "step": 210
    },
    {
      "epoch": 0.0844,
      "grad_norm": 0.5106959590579628,
      "learning_rate": 4.9612973823308686e-05,
      "loss": 2.1934,
      "step": 211
    },
    {
      "epoch": 0.0848,
      "grad_norm": 0.5306817245857798,
      "learning_rate": 4.9607276340076006e-05,
      "loss": 2.2383,
      "step": 212
    },
    {
      "epoch": 0.0852,
      "grad_norm": 0.5398341882136588,
      "learning_rate": 4.960153755782343e-05,
      "loss": 2.1787,
      "step": 213
    },
    {
      "epoch": 0.0856,
      "grad_norm": 0.5116470317167913,
      "learning_rate": 4.959575748618249e-05,
      "loss": 2.2251,
      "step": 214
    },
    {
      "epoch": 0.086,
      "grad_norm": 0.4940381187254484,
      "learning_rate": 4.958993613485405e-05,
      "loss": 2.2812,
      "step": 215
    },
    {
      "epoch": 0.0864,
      "grad_norm": 0.492188523459547,
      "learning_rate": 4.958407351360821e-05,
      "loss": 2.1758,
      "step": 216
    },
    {
      "epoch": 0.0868,
      "grad_norm": 0.5025745796685116,
      "learning_rate": 4.9578169632284373e-05,
      "loss": 2.2471,
      "step": 217
    },
    {
      "epoch": 0.0872,
      "grad_norm": 0.5318858288130289,
      "learning_rate": 4.9572224500791166e-05,
      "loss": 2.2168,
      "step": 218
    },
    {
      "epoch": 0.0876,
      "grad_norm": 0.5191198822513593,
      "learning_rate": 4.9566238129106446e-05,
      "loss": 2.2461,
      "step": 219
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.48686168296571164,
      "learning_rate": 4.956021052727731e-05,
      "loss": 2.1118,
      "step": 220
    },
    {
      "epoch": 0.0884,
      "grad_norm": 0.5219531478964997,
      "learning_rate": 4.955414170542003e-05,
      "loss": 2.2007,
      "step": 221
    },
    {
      "epoch": 0.0888,
      "grad_norm": 0.4753039429367897,
      "learning_rate": 4.9548031673720064e-05,
      "loss": 2.1836,
      "step": 222
    },
    {
      "epoch": 0.0892,
      "grad_norm": 0.518956787599726,
      "learning_rate": 4.954188044243203e-05,
      "loss": 2.189,
      "step": 223
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.4976420763179861,
      "learning_rate": 4.95356880218797e-05,
      "loss": 2.1909,
      "step": 224
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.517952143629479,
      "learning_rate": 4.9529454422455976e-05,
      "loss": 2.3022,
      "step": 225
    },
    {
      "epoch": 0.0904,
      "grad_norm": 0.5126503267646928,
      "learning_rate": 4.9523179654622864e-05,
      "loss": 2.2192,
      "step": 226
    },
    {
      "epoch": 0.0908,
      "grad_norm": 0.5027077388577129,
      "learning_rate": 4.9516863728911464e-05,
      "loss": 2.1929,
      "step": 227
    },
    {
      "epoch": 0.0912,
      "grad_norm": 0.5414141299157056,
      "learning_rate": 4.951050665592195e-05,
      "loss": 2.2295,
      "step": 228
    },
    {
      "epoch": 0.0916,
      "grad_norm": 0.5014919877425075,
      "learning_rate": 4.9504108446323575e-05,
      "loss": 2.1328,
      "step": 229
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.5064298648849981,
      "learning_rate": 4.949766911085461e-05,
      "loss": 2.2021,
      "step": 230
    },
    {
      "epoch": 0.0924,
      "grad_norm": 0.5042860572599059,
      "learning_rate": 4.9491188660322354e-05,
      "loss": 2.1089,
      "step": 231
    },
    {
      "epoch": 0.0928,
      "grad_norm": 0.4993822777151499,
      "learning_rate": 4.948466710560311e-05,
      "loss": 2.228,
      "step": 232
    },
    {
      "epoch": 0.0932,
      "grad_norm": 0.47007991473546473,
      "learning_rate": 4.9478104457642185e-05,
      "loss": 2.1177,
      "step": 233
    },
    {
      "epoch": 0.0936,
      "grad_norm": 0.5497099848441317,
      "learning_rate": 4.947150072745381e-05,
      "loss": 2.2437,
      "step": 234
    },
    {
      "epoch": 0.094,
      "grad_norm": 0.5753458479213712,
      "learning_rate": 4.9464855926121225e-05,
      "loss": 2.2021,
      "step": 235
    },
    {
      "epoch": 0.0944,
      "grad_norm": 0.5122868901898464,
      "learning_rate": 4.945817006479655e-05,
      "loss": 2.1304,
      "step": 236
    },
    {
      "epoch": 0.0948,
      "grad_norm": 0.5352324196416841,
      "learning_rate": 4.945144315470084e-05,
      "loss": 2.2246,
      "step": 237
    },
    {
      "epoch": 0.0952,
      "grad_norm": 0.5162616846472441,
      "learning_rate": 4.944467520712405e-05,
      "loss": 2.2402,
      "step": 238
    },
    {
      "epoch": 0.0956,
      "grad_norm": 0.512910226000078,
      "learning_rate": 4.9437866233424984e-05,
      "loss": 2.3057,
      "step": 239
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.5220288137765066,
      "learning_rate": 4.943101624503132e-05,
      "loss": 2.2905,
      "step": 240
    },
    {
      "epoch": 0.0964,
      "grad_norm": 0.5005507179896193,
      "learning_rate": 4.942412525343959e-05,
      "loss": 2.1938,
      "step": 241
    },
    {
      "epoch": 0.0968,
      "grad_norm": 0.5083756618013239,
      "learning_rate": 4.941719327021509e-05,
      "loss": 2.1929,
      "step": 242
    },
    {
      "epoch": 0.0972,
      "grad_norm": 0.4760563127908242,
      "learning_rate": 4.941022030699196e-05,
      "loss": 2.2251,
      "step": 243
    },
    {
      "epoch": 0.0976,
      "grad_norm": 0.5205264995823257,
      "learning_rate": 4.94032063754731e-05,
      "loss": 2.3149,
      "step": 244
    },
    {
      "epoch": 0.098,
      "grad_norm": 0.521429725931495,
      "learning_rate": 4.939615148743017e-05,
      "loss": 2.2881,
      "step": 245
    },
    {
      "epoch": 0.0984,
      "grad_norm": 0.525675187445119,
      "learning_rate": 4.938905565470357e-05,
      "loss": 2.249,
      "step": 246
    },
    {
      "epoch": 0.0988,
      "grad_norm": 0.5422502563354392,
      "learning_rate": 4.938191888920242e-05,
      "loss": 2.1411,
      "step": 247
    },
    {
      "epoch": 0.0992,
      "grad_norm": 0.49948240792287274,
      "learning_rate": 4.937474120290452e-05,
      "loss": 2.1709,
      "step": 248
    },
    {
      "epoch": 0.0996,
      "grad_norm": 0.5035455538682655,
      "learning_rate": 4.936752260785639e-05,
      "loss": 2.2075,
      "step": 249
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4705602955075506,
      "learning_rate": 4.936026311617316e-05,
      "loss": 2.1841,
      "step": 250
    },
    {
      "epoch": 0.1004,
      "grad_norm": 0.510671635502518,
      "learning_rate": 4.935296274003862e-05,
      "loss": 2.3037,
      "step": 251
    },
    {
      "epoch": 0.1008,
      "grad_norm": 0.4890269795200488,
      "learning_rate": 4.9345621491705196e-05,
      "loss": 2.2163,
      "step": 252
    },
    {
      "epoch": 0.1012,
      "grad_norm": 0.4653391159620232,
      "learning_rate": 4.933823938349388e-05,
      "loss": 2.0947,
      "step": 253
    },
    {
      "epoch": 0.1016,
      "grad_norm": 0.5244175398437954,
      "learning_rate": 4.933081642779426e-05,
      "loss": 2.2402,
      "step": 254
    },
    {
      "epoch": 0.102,
      "grad_norm": 0.5455920644893346,
      "learning_rate": 4.9323352637064455e-05,
      "loss": 2.27,
      "step": 255
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.5135907719347024,
      "learning_rate": 4.9315848023831154e-05,
      "loss": 2.2764,
      "step": 256
    },
    {
      "epoch": 0.1028,
      "grad_norm": 0.5462870375530912,
      "learning_rate": 4.930830260068954e-05,
      "loss": 2.2827,
      "step": 257
    },
    {
      "epoch": 0.1032,
      "grad_norm": 0.5043193307766636,
      "learning_rate": 4.9300716380303276e-05,
      "loss": 2.2588,
      "step": 258
    },
    {
      "epoch": 0.1036,
      "grad_norm": 0.5798841982385453,
      "learning_rate": 4.9293089375404515e-05,
      "loss": 2.2197,
      "step": 259
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.5452033105347065,
      "learning_rate": 4.928542159879386e-05,
      "loss": 2.1279,
      "step": 260
    },
    {
      "epoch": 0.1044,
      "grad_norm": 0.5130076513017211,
      "learning_rate": 4.927771306334033e-05,
      "loss": 2.207,
      "step": 261
    },
    {
      "epoch": 0.1048,
      "grad_norm": 0.5460352483091618,
      "learning_rate": 4.926996378198136e-05,
      "loss": 2.1997,
      "step": 262
    },
    {
      "epoch": 0.1052,
      "grad_norm": 0.5039189713077733,
      "learning_rate": 4.926217376772276e-05,
      "loss": 2.2295,
      "step": 263
    },
    {
      "epoch": 0.1056,
      "grad_norm": 0.5022809494158914,
      "learning_rate": 4.9254343033638726e-05,
      "loss": 2.1436,
      "step": 264
    },
    {
      "epoch": 0.106,
      "grad_norm": 0.5370707284613124,
      "learning_rate": 4.924647159287176e-05,
      "loss": 2.228,
      "step": 265
    },
    {
      "epoch": 0.1064,
      "grad_norm": 0.5102373532143918,
      "learning_rate": 4.923855945863272e-05,
      "loss": 2.2085,
      "step": 266
    },
    {
      "epoch": 0.1068,
      "grad_norm": 0.5647106056406511,
      "learning_rate": 4.9230606644200716e-05,
      "loss": 2.1851,
      "step": 267
    },
    {
      "epoch": 0.1072,
      "grad_norm": 0.5278010333506677,
      "learning_rate": 4.922261316292318e-05,
      "loss": 2.2144,
      "step": 268
    },
    {
      "epoch": 0.1076,
      "grad_norm": 0.4737242657499774,
      "learning_rate": 4.9214579028215776e-05,
      "loss": 2.1494,
      "step": 269
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.5066142937740901,
      "learning_rate": 4.92065042535624e-05,
      "loss": 2.0967,
      "step": 270
    },
    {
      "epoch": 0.1084,
      "grad_norm": 0.5269361818757304,
      "learning_rate": 4.9198388852515135e-05,
      "loss": 2.3115,
      "step": 271
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.5276732545570323,
      "learning_rate": 4.9190232838694284e-05,
      "loss": 2.1548,
      "step": 272
    },
    {
      "epoch": 0.1092,
      "grad_norm": 0.5188852962176025,
      "learning_rate": 4.918203622578828e-05,
      "loss": 2.2734,
      "step": 273
    },
    {
      "epoch": 0.1096,
      "grad_norm": 0.5281060828506792,
      "learning_rate": 4.9173799027553715e-05,
      "loss": 2.2773,
      "step": 274
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5024948828514526,
      "learning_rate": 4.916552125781528e-05,
      "loss": 2.1509,
      "step": 275
    },
    {
      "epoch": 0.1104,
      "grad_norm": 0.49835404579751663,
      "learning_rate": 4.9157202930465784e-05,
      "loss": 2.2412,
      "step": 276
    },
    {
      "epoch": 0.1108,
      "grad_norm": 0.5235879829656138,
      "learning_rate": 4.914884405946607e-05,
      "loss": 2.1846,
      "step": 277
    },
    {
      "epoch": 0.1112,
      "grad_norm": 0.5037261147309887,
      "learning_rate": 4.9140444658845064e-05,
      "loss": 2.1641,
      "step": 278
    },
    {
      "epoch": 0.1116,
      "grad_norm": 0.5091856853585806,
      "learning_rate": 4.913200474269967e-05,
      "loss": 2.2354,
      "step": 279
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.5516419230934211,
      "learning_rate": 4.912352432519484e-05,
      "loss": 2.252,
      "step": 280
    },
    {
      "epoch": 0.1124,
      "grad_norm": 0.4934445630637258,
      "learning_rate": 4.9115003420563454e-05,
      "loss": 2.2236,
      "step": 281
    },
    {
      "epoch": 0.1128,
      "grad_norm": 0.5302903026164273,
      "learning_rate": 4.910644204310638e-05,
      "loss": 2.2339,
      "step": 282
    },
    {
      "epoch": 0.1132,
      "grad_norm": 0.5644705137671039,
      "learning_rate": 4.909784020719238e-05,
      "loss": 2.186,
      "step": 283
    },
    {
      "epoch": 0.1136,
      "grad_norm": 0.5167688324011658,
      "learning_rate": 4.9089197927258144e-05,
      "loss": 2.2109,
      "step": 284
    },
    {
      "epoch": 0.114,
      "grad_norm": 0.6057220173022838,
      "learning_rate": 4.908051521780824e-05,
      "loss": 2.2163,
      "step": 285
    },
    {
      "epoch": 0.1144,
      "grad_norm": 0.530456155455354,
      "learning_rate": 4.907179209341507e-05,
      "loss": 2.1528,
      "step": 286
    },
    {
      "epoch": 0.1148,
      "grad_norm": 0.5498121188844687,
      "learning_rate": 4.906302856871887e-05,
      "loss": 2.2349,
      "step": 287
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.529689203254931,
      "learning_rate": 4.9054224658427707e-05,
      "loss": 2.1904,
      "step": 288
    },
    {
      "epoch": 0.1156,
      "grad_norm": 0.5304263389599362,
      "learning_rate": 4.904538037731739e-05,
      "loss": 2.2319,
      "step": 289
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.5361439389023336,
      "learning_rate": 4.90364957402315e-05,
      "loss": 2.2319,
      "step": 290
    },
    {
      "epoch": 0.1164,
      "grad_norm": 0.5128534433248991,
      "learning_rate": 4.9027570762081366e-05,
      "loss": 2.1899,
      "step": 291
    },
    {
      "epoch": 0.1168,
      "grad_norm": 0.590403212217437,
      "learning_rate": 4.9018605457846e-05,
      "loss": 2.2495,
      "step": 292
    },
    {
      "epoch": 0.1172,
      "grad_norm": 0.5183699185693064,
      "learning_rate": 4.9009599842572095e-05,
      "loss": 2.2871,
      "step": 293
    },
    {
      "epoch": 0.1176,
      "grad_norm": 0.6027569697643292,
      "learning_rate": 4.9000553931374015e-05,
      "loss": 2.0938,
      "step": 294
    },
    {
      "epoch": 0.118,
      "grad_norm": 0.4854837776144772,
      "learning_rate": 4.899146773943374e-05,
      "loss": 2.1968,
      "step": 295
    },
    {
      "epoch": 0.1184,
      "grad_norm": 0.523596698022819,
      "learning_rate": 4.8982341282000855e-05,
      "loss": 2.1489,
      "step": 296
    },
    {
      "epoch": 0.1188,
      "grad_norm": 0.5579014181156838,
      "learning_rate": 4.897317457439252e-05,
      "loss": 2.3306,
      "step": 297
    },
    {
      "epoch": 0.1192,
      "grad_norm": 0.5212376848201588,
      "learning_rate": 4.896396763199347e-05,
      "loss": 2.2095,
      "step": 298
    },
    {
      "epoch": 0.1196,
      "grad_norm": 0.5683904727998708,
      "learning_rate": 4.895472047025594e-05,
      "loss": 2.2075,
      "step": 299
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.602741483586765,
      "learning_rate": 4.894543310469968e-05,
      "loss": 2.2983,
      "step": 300
    },
    {
      "epoch": 0.1204,
      "grad_norm": 0.5073475485724982,
      "learning_rate": 4.893610555091192e-05,
      "loss": 2.1797,
      "step": 301
    },
    {
      "epoch": 0.1208,
      "grad_norm": 0.5373603223367762,
      "learning_rate": 4.8926737824547314e-05,
      "loss": 2.2339,
      "step": 302
    },
    {
      "epoch": 0.1212,
      "grad_norm": 0.5284927167545982,
      "learning_rate": 4.8917329941327975e-05,
      "loss": 2.2451,
      "step": 303
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.5133132356331735,
      "learning_rate": 4.8907881917043386e-05,
      "loss": 2.1636,
      "step": 304
    },
    {
      "epoch": 0.122,
      "grad_norm": 0.46980218375653815,
      "learning_rate": 4.8898393767550405e-05,
      "loss": 2.1973,
      "step": 305
    },
    {
      "epoch": 0.1224,
      "grad_norm": 0.510272874508965,
      "learning_rate": 4.888886550877324e-05,
      "loss": 2.2656,
      "step": 306
    },
    {
      "epoch": 0.1228,
      "grad_norm": 0.5648702185579456,
      "learning_rate": 4.887929715670341e-05,
      "loss": 2.1152,
      "step": 307
    },
    {
      "epoch": 0.1232,
      "grad_norm": 0.4606793067143644,
      "learning_rate": 4.886968872739971e-05,
      "loss": 2.2671,
      "step": 308
    },
    {
      "epoch": 0.1236,
      "grad_norm": 0.53809824614875,
      "learning_rate": 4.886004023698824e-05,
      "loss": 2.1865,
      "step": 309
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.49617251196597273,
      "learning_rate": 4.885035170166228e-05,
      "loss": 2.2217,
      "step": 310
    },
    {
      "epoch": 0.1244,
      "grad_norm": 0.49903620402446774,
      "learning_rate": 4.884062313768237e-05,
      "loss": 2.2871,
      "step": 311
    },
    {
      "epoch": 0.1248,
      "grad_norm": 0.5288730640155611,
      "learning_rate": 4.8830854561376196e-05,
      "loss": 2.2329,
      "step": 312
    },
    {
      "epoch": 0.1252,
      "grad_norm": 0.5394039617353181,
      "learning_rate": 4.88210459891386e-05,
      "loss": 2.1953,
      "step": 313
    },
    {
      "epoch": 0.1256,
      "grad_norm": 0.49192216794227794,
      "learning_rate": 4.8811197437431575e-05,
      "loss": 2.1865,
      "step": 314
    },
    {
      "epoch": 0.126,
      "grad_norm": 0.5263603935615845,
      "learning_rate": 4.880130892278419e-05,
      "loss": 2.1743,
      "step": 315
    },
    {
      "epoch": 0.1264,
      "grad_norm": 0.49929215508309294,
      "learning_rate": 4.879138046179259e-05,
      "loss": 2.2886,
      "step": 316
    },
    {
      "epoch": 0.1268,
      "grad_norm": 0.5396169164270745,
      "learning_rate": 4.878141207111997e-05,
      "loss": 2.2754,
      "step": 317
    },
    {
      "epoch": 0.1272,
      "grad_norm": 0.524148290522446,
      "learning_rate": 4.8771403767496527e-05,
      "loss": 2.208,
      "step": 318
    },
    {
      "epoch": 0.1276,
      "grad_norm": 0.5476516442992856,
      "learning_rate": 4.876135556771945e-05,
      "loss": 2.2773,
      "step": 319
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.5198375839820063,
      "learning_rate": 4.87512674886529e-05,
      "loss": 2.2476,
      "step": 320
    },
    {
      "epoch": 0.1284,
      "grad_norm": 0.522874872977872,
      "learning_rate": 4.874113954722795e-05,
      "loss": 2.1865,
      "step": 321
    },
    {
      "epoch": 0.1288,
      "grad_norm": 0.5081417680530649,
      "learning_rate": 4.873097176044259e-05,
      "loss": 2.2188,
      "step": 322
    },
    {
      "epoch": 0.1292,
      "grad_norm": 0.5140038128835311,
      "learning_rate": 4.8720764145361666e-05,
      "loss": 2.3218,
      "step": 323
    },
    {
      "epoch": 0.1296,
      "grad_norm": 0.5855322364628378,
      "learning_rate": 4.871051671911688e-05,
      "loss": 2.311,
      "step": 324
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.49646399716311435,
      "learning_rate": 4.870022949890676e-05,
      "loss": 2.2173,
      "step": 325
    },
    {
      "epoch": 0.1304,
      "grad_norm": 0.48918921418294437,
      "learning_rate": 4.868990250199661e-05,
      "loss": 2.1147,
      "step": 326
    },
    {
      "epoch": 0.1308,
      "grad_norm": 0.4752510970349296,
      "learning_rate": 4.867953574571847e-05,
      "loss": 2.1772,
      "step": 327
    },
    {
      "epoch": 0.1312,
      "grad_norm": 0.6008395833637191,
      "learning_rate": 4.8669129247471156e-05,
      "loss": 2.2485,
      "step": 328
    },
    {
      "epoch": 0.1316,
      "grad_norm": 0.5184458528460192,
      "learning_rate": 4.865868302472015e-05,
      "loss": 2.2705,
      "step": 329
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.5257098162588264,
      "learning_rate": 4.8648197094997616e-05,
      "loss": 2.2144,
      "step": 330
    },
    {
      "epoch": 0.1324,
      "grad_norm": 0.5210432306305403,
      "learning_rate": 4.8637671475902355e-05,
      "loss": 2.2944,
      "step": 331
    },
    {
      "epoch": 0.1328,
      "grad_norm": 0.47297149125166993,
      "learning_rate": 4.862710618509978e-05,
      "loss": 2.144,
      "step": 332
    },
    {
      "epoch": 0.1332,
      "grad_norm": 0.4701971287636927,
      "learning_rate": 4.8616501240321896e-05,
      "loss": 2.1846,
      "step": 333
    },
    {
      "epoch": 0.1336,
      "grad_norm": 0.524966938280284,
      "learning_rate": 4.8605856659367256e-05,
      "loss": 2.3027,
      "step": 334
    },
    {
      "epoch": 0.134,
      "grad_norm": 0.49855845404627136,
      "learning_rate": 4.859517246010091e-05,
      "loss": 2.2686,
      "step": 335
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.49475988687715333,
      "learning_rate": 4.8584448660454445e-05,
      "loss": 2.1968,
      "step": 336
    },
    {
      "epoch": 0.1348,
      "grad_norm": 0.49752756786155405,
      "learning_rate": 4.857368527842588e-05,
      "loss": 2.2231,
      "step": 337
    },
    {
      "epoch": 0.1352,
      "grad_norm": 0.4933948086639869,
      "learning_rate": 4.856288233207967e-05,
      "loss": 2.2075,
      "step": 338
    },
    {
      "epoch": 0.1356,
      "grad_norm": 0.47409882560576033,
      "learning_rate": 4.855203983954668e-05,
      "loss": 2.1899,
      "step": 339
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.49421580135380233,
      "learning_rate": 4.854115781902414e-05,
      "loss": 2.1753,
      "step": 340
    },
    {
      "epoch": 0.1364,
      "grad_norm": 0.49058532388063225,
      "learning_rate": 4.853023628877562e-05,
      "loss": 2.2354,
      "step": 341
    },
    {
      "epoch": 0.1368,
      "grad_norm": 0.49449318974688544,
      "learning_rate": 4.851927526713101e-05,
      "loss": 2.123,
      "step": 342
    },
    {
      "epoch": 0.1372,
      "grad_norm": 0.5170196527358888,
      "learning_rate": 4.8508274772486465e-05,
      "loss": 2.2505,
      "step": 343
    },
    {
      "epoch": 0.1376,
      "grad_norm": 0.5495599079173557,
      "learning_rate": 4.8497234823304404e-05,
      "loss": 2.3398,
      "step": 344
    },
    {
      "epoch": 0.138,
      "grad_norm": 0.47937119952809987,
      "learning_rate": 4.8486155438113454e-05,
      "loss": 2.1528,
      "step": 345
    },
    {
      "epoch": 0.1384,
      "grad_norm": 0.48522284087789425,
      "learning_rate": 4.847503663550842e-05,
      "loss": 2.1943,
      "step": 346
    },
    {
      "epoch": 0.1388,
      "grad_norm": 0.507594292176236,
      "learning_rate": 4.8463878434150276e-05,
      "loss": 2.209,
      "step": 347
    },
    {
      "epoch": 0.1392,
      "grad_norm": 0.47806072268253447,
      "learning_rate": 4.845268085276613e-05,
      "loss": 2.1973,
      "step": 348
    },
    {
      "epoch": 0.1396,
      "grad_norm": 0.5151499151870791,
      "learning_rate": 4.844144391014915e-05,
      "loss": 2.2725,
      "step": 349
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4973451429933089,
      "learning_rate": 4.8430167625158595e-05,
      "loss": 2.2886,
      "step": 350
    },
    {
      "epoch": 0.1404,
      "grad_norm": 0.47971893241440755,
      "learning_rate": 4.841885201671973e-05,
      "loss": 2.1548,
      "step": 351
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.4953632391272017,
      "learning_rate": 4.840749710382385e-05,
      "loss": 2.1958,
      "step": 352
    },
    {
      "epoch": 0.1412,
      "grad_norm": 0.4728466100849495,
      "learning_rate": 4.8396102905528176e-05,
      "loss": 2.2773,
      "step": 353
    },
    {
      "epoch": 0.1416,
      "grad_norm": 0.4959923745880177,
      "learning_rate": 4.8384669440955886e-05,
      "loss": 2.1904,
      "step": 354
    },
    {
      "epoch": 0.142,
      "grad_norm": 0.49012706876879525,
      "learning_rate": 4.837319672929607e-05,
      "loss": 2.291,
      "step": 355
    },
    {
      "epoch": 0.1424,
      "grad_norm": 0.5197689020587661,
      "learning_rate": 4.836168478980365e-05,
      "loss": 2.2339,
      "step": 356
    },
    {
      "epoch": 0.1428,
      "grad_norm": 0.5103631389231434,
      "learning_rate": 4.835013364179942e-05,
      "loss": 2.2388,
      "step": 357
    },
    {
      "epoch": 0.1432,
      "grad_norm": 0.5090336185602786,
      "learning_rate": 4.833854330466997e-05,
      "loss": 2.2603,
      "step": 358
    },
    {
      "epoch": 0.1436,
      "grad_norm": 0.4995576014792616,
      "learning_rate": 4.832691379786765e-05,
      "loss": 2.3081,
      "step": 359
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.4895957908830627,
      "learning_rate": 4.8315245140910556e-05,
      "loss": 2.2002,
      "step": 360
    },
    {
      "epoch": 0.1444,
      "grad_norm": 0.48767377709602794,
      "learning_rate": 4.830353735338251e-05,
      "loss": 2.144,
      "step": 361
    },
    {
      "epoch": 0.1448,
      "grad_norm": 0.49729939055370215,
      "learning_rate": 4.829179045493297e-05,
      "loss": 2.2207,
      "step": 362
    },
    {
      "epoch": 0.1452,
      "grad_norm": 0.45825588429331704,
      "learning_rate": 4.828000446527707e-05,
      "loss": 2.0781,
      "step": 363
    },
    {
      "epoch": 0.1456,
      "grad_norm": 0.5285915409761653,
      "learning_rate": 4.826817940419553e-05,
      "loss": 2.228,
      "step": 364
    },
    {
      "epoch": 0.146,
      "grad_norm": 0.4723285297952844,
      "learning_rate": 4.825631529153466e-05,
      "loss": 2.1807,
      "step": 365
    },
    {
      "epoch": 0.1464,
      "grad_norm": 0.48918994624788265,
      "learning_rate": 4.8244412147206284e-05,
      "loss": 2.2456,
      "step": 366
    },
    {
      "epoch": 0.1468,
      "grad_norm": 0.5024191117239268,
      "learning_rate": 4.823246999118778e-05,
      "loss": 2.228,
      "step": 367
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.45140270404801464,
      "learning_rate": 4.822048884352195e-05,
      "loss": 2.1636,
      "step": 368
    },
    {
      "epoch": 0.1476,
      "grad_norm": 0.5026347927286026,
      "learning_rate": 4.820846872431707e-05,
      "loss": 2.2549,
      "step": 369
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.48320185300214935,
      "learning_rate": 4.819640965374681e-05,
      "loss": 2.1641,
      "step": 370
    },
    {
      "epoch": 0.1484,
      "grad_norm": 0.47108743199987996,
      "learning_rate": 4.818431165205022e-05,
      "loss": 2.2041,
      "step": 371
    },
    {
      "epoch": 0.1488,
      "grad_norm": 0.4760702487602761,
      "learning_rate": 4.817217473953168e-05,
      "loss": 2.2598,
      "step": 372
    },
    {
      "epoch": 0.1492,
      "grad_norm": 0.5094507764778473,
      "learning_rate": 4.815999893656089e-05,
      "loss": 2.2246,
      "step": 373
    },
    {
      "epoch": 0.1496,
      "grad_norm": 0.5090210829164743,
      "learning_rate": 4.81477842635728e-05,
      "loss": 2.2007,
      "step": 374
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5121315288308855,
      "learning_rate": 4.813553074106761e-05,
      "loss": 2.2148,
      "step": 375
    },
    {
      "epoch": 0.1504,
      "grad_norm": 0.5365943933204984,
      "learning_rate": 4.812323838961071e-05,
      "loss": 2.2632,
      "step": 376
    },
    {
      "epoch": 0.1508,
      "grad_norm": 0.48834678379003355,
      "learning_rate": 4.811090722983269e-05,
      "loss": 2.2612,
      "step": 377
    },
    {
      "epoch": 0.1512,
      "grad_norm": 0.49779208952422427,
      "learning_rate": 4.809853728242924e-05,
      "loss": 2.1733,
      "step": 378
    },
    {
      "epoch": 0.1516,
      "grad_norm": 0.4868766370655724,
      "learning_rate": 4.808612856816115e-05,
      "loss": 2.2031,
      "step": 379
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.49136658802826344,
      "learning_rate": 4.80736811078543e-05,
      "loss": 2.2158,
      "step": 380
    },
    {
      "epoch": 0.1524,
      "grad_norm": 0.45801673458093217,
      "learning_rate": 4.806119492239955e-05,
      "loss": 2.1255,
      "step": 381
    },
    {
      "epoch": 0.1528,
      "grad_norm": 0.506150065663695,
      "learning_rate": 4.804867003275281e-05,
      "loss": 2.1938,
      "step": 382
    },
    {
      "epoch": 0.1532,
      "grad_norm": 0.5103975346684965,
      "learning_rate": 4.8036106459934915e-05,
      "loss": 2.2441,
      "step": 383
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.4893199759555404,
      "learning_rate": 4.802350422503163e-05,
      "loss": 2.2363,
      "step": 384
    },
    {
      "epoch": 0.154,
      "grad_norm": 0.47061953461526174,
      "learning_rate": 4.8010863349193605e-05,
      "loss": 2.2139,
      "step": 385
    },
    {
      "epoch": 0.1544,
      "grad_norm": 0.5054528327742097,
      "learning_rate": 4.7998183853636346e-05,
      "loss": 2.1636,
      "step": 386
    },
    {
      "epoch": 0.1548,
      "grad_norm": 0.5112285110297811,
      "learning_rate": 4.798546575964017e-05,
      "loss": 2.3291,
      "step": 387
    },
    {
      "epoch": 0.1552,
      "grad_norm": 0.504468258269308,
      "learning_rate": 4.7972709088550187e-05,
      "loss": 2.187,
      "step": 388
    },
    {
      "epoch": 0.1556,
      "grad_norm": 0.5091361547904245,
      "learning_rate": 4.795991386177624e-05,
      "loss": 2.1484,
      "step": 389
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.4796585328106975,
      "learning_rate": 4.794708010079289e-05,
      "loss": 2.1768,
      "step": 390
    },
    {
      "epoch": 0.1564,
      "grad_norm": 0.5464371028410698,
      "learning_rate": 4.793420782713935e-05,
      "loss": 2.332,
      "step": 391
    },
    {
      "epoch": 0.1568,
      "grad_norm": 0.5071358844334194,
      "learning_rate": 4.792129706241949e-05,
      "loss": 2.2026,
      "step": 392
    },
    {
      "epoch": 0.1572,
      "grad_norm": 0.5278867960556516,
      "learning_rate": 4.7908347828301795e-05,
      "loss": 2.2417,
      "step": 393
    },
    {
      "epoch": 0.1576,
      "grad_norm": 0.5133897995922976,
      "learning_rate": 4.789536014651927e-05,
      "loss": 2.2627,
      "step": 394
    },
    {
      "epoch": 0.158,
      "grad_norm": 0.5130035768609077,
      "learning_rate": 4.7882334038869495e-05,
      "loss": 2.1865,
      "step": 395
    },
    {
      "epoch": 0.1584,
      "grad_norm": 0.5012369073681934,
      "learning_rate": 4.78692695272145e-05,
      "loss": 2.2231,
      "step": 396
    },
    {
      "epoch": 0.1588,
      "grad_norm": 0.5130096738452866,
      "learning_rate": 4.7856166633480794e-05,
      "loss": 2.2231,
      "step": 397
    },
    {
      "epoch": 0.1592,
      "grad_norm": 0.46943437036599617,
      "learning_rate": 4.78430253796593e-05,
      "loss": 2.2192,
      "step": 398
    },
    {
      "epoch": 0.1596,
      "grad_norm": 0.4862020496903176,
      "learning_rate": 4.7829845787805324e-05,
      "loss": 2.1216,
      "step": 399
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5070416095167096,
      "learning_rate": 4.781662788003851e-05,
      "loss": 2.1797,
      "step": 400
    },
    {
      "epoch": 0.1604,
      "grad_norm": 0.49796601954228764,
      "learning_rate": 4.78033716785428e-05,
      "loss": 2.2476,
      "step": 401
    },
    {
      "epoch": 0.1608,
      "grad_norm": 0.505999505939142,
      "learning_rate": 4.7790077205566425e-05,
      "loss": 2.0801,
      "step": 402
    },
    {
      "epoch": 0.1612,
      "grad_norm": 0.5438847218096773,
      "learning_rate": 4.777674448342183e-05,
      "loss": 2.2305,
      "step": 403
    },
    {
      "epoch": 0.1616,
      "grad_norm": 0.4989659128100057,
      "learning_rate": 4.776337353448568e-05,
      "loss": 2.1626,
      "step": 404
    },
    {
      "epoch": 0.162,
      "grad_norm": 0.49676297512708867,
      "learning_rate": 4.7749964381198765e-05,
      "loss": 2.2314,
      "step": 405
    },
    {
      "epoch": 0.1624,
      "grad_norm": 0.5120161679176294,
      "learning_rate": 4.773651704606601e-05,
      "loss": 2.2451,
      "step": 406
    },
    {
      "epoch": 0.1628,
      "grad_norm": 0.49848816404206114,
      "learning_rate": 4.772303155165642e-05,
      "loss": 2.2148,
      "step": 407
    },
    {
      "epoch": 0.1632,
      "grad_norm": 0.5094784962873448,
      "learning_rate": 4.770950792060306e-05,
      "loss": 2.2285,
      "step": 408
    },
    {
      "epoch": 0.1636,
      "grad_norm": 0.45788964973659996,
      "learning_rate": 4.769594617560296e-05,
      "loss": 2.1509,
      "step": 409
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.5153509505800988,
      "learning_rate": 4.768234633941716e-05,
      "loss": 2.1855,
      "step": 410
    },
    {
      "epoch": 0.1644,
      "grad_norm": 0.49534436765672885,
      "learning_rate": 4.7668708434870606e-05,
      "loss": 2.2236,
      "step": 411
    },
    {
      "epoch": 0.1648,
      "grad_norm": 0.4853127093862048,
      "learning_rate": 4.7655032484852146e-05,
      "loss": 2.207,
      "step": 412
    },
    {
      "epoch": 0.1652,
      "grad_norm": 0.4809822382352618,
      "learning_rate": 4.764131851231447e-05,
      "loss": 2.2036,
      "step": 413
    },
    {
      "epoch": 0.1656,
      "grad_norm": 0.4856238747877776,
      "learning_rate": 4.7627566540274095e-05,
      "loss": 2.1416,
      "step": 414
    },
    {
      "epoch": 0.166,
      "grad_norm": 0.44841845941615227,
      "learning_rate": 4.76137765918113e-05,
      "loss": 2.144,
      "step": 415
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.4993358178524103,
      "learning_rate": 4.759994869007011e-05,
      "loss": 2.2314,
      "step": 416
    },
    {
      "epoch": 0.1668,
      "grad_norm": 0.5015949886989495,
      "learning_rate": 4.758608285825825e-05,
      "loss": 2.1982,
      "step": 417
    },
    {
      "epoch": 0.1672,
      "grad_norm": 0.4676742928719098,
      "learning_rate": 4.7572179119647084e-05,
      "loss": 2.23,
      "step": 418
    },
    {
      "epoch": 0.1676,
      "grad_norm": 0.5061485243069045,
      "learning_rate": 4.755823749757163e-05,
      "loss": 2.292,
      "step": 419
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.4487941749183964,
      "learning_rate": 4.7544258015430463e-05,
      "loss": 2.2173,
      "step": 420
    },
    {
      "epoch": 0.1684,
      "grad_norm": 0.46940269499640197,
      "learning_rate": 4.75302406966857e-05,
      "loss": 2.1299,
      "step": 421
    },
    {
      "epoch": 0.1688,
      "grad_norm": 0.4935262145659651,
      "learning_rate": 4.751618556486297e-05,
      "loss": 2.187,
      "step": 422
    },
    {
      "epoch": 0.1692,
      "grad_norm": 0.46432941742205697,
      "learning_rate": 4.750209264355135e-05,
      "loss": 2.2529,
      "step": 423
    },
    {
      "epoch": 0.1696,
      "grad_norm": 0.4895220128852399,
      "learning_rate": 4.748796195640336e-05,
      "loss": 2.188,
      "step": 424
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.46701794483580045,
      "learning_rate": 4.747379352713489e-05,
      "loss": 2.1284,
      "step": 425
    },
    {
      "epoch": 0.1704,
      "grad_norm": 0.47437804352358803,
      "learning_rate": 4.7459587379525174e-05,
      "loss": 2.1699,
      "step": 426
    },
    {
      "epoch": 0.1708,
      "grad_norm": 0.46809972215250195,
      "learning_rate": 4.7445343537416746e-05,
      "loss": 2.1348,
      "step": 427
    },
    {
      "epoch": 0.1712,
      "grad_norm": 0.4760919139547465,
      "learning_rate": 4.743106202471542e-05,
      "loss": 2.249,
      "step": 428
    },
    {
      "epoch": 0.1716,
      "grad_norm": 0.4834368177255597,
      "learning_rate": 4.741674286539023e-05,
      "loss": 2.2119,
      "step": 429
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.5123352595856485,
      "learning_rate": 4.740238608347336e-05,
      "loss": 2.2837,
      "step": 430
    },
    {
      "epoch": 0.1724,
      "grad_norm": 0.4927378023271705,
      "learning_rate": 4.73879917030602e-05,
      "loss": 2.2646,
      "step": 431
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.46195235402006246,
      "learning_rate": 4.7373559748309175e-05,
      "loss": 2.1592,
      "step": 432
    },
    {
      "epoch": 0.1732,
      "grad_norm": 0.5036306549958127,
      "learning_rate": 4.7359090243441814e-05,
      "loss": 2.2832,
      "step": 433
    },
    {
      "epoch": 0.1736,
      "grad_norm": 0.4534363984789441,
      "learning_rate": 4.7344583212742666e-05,
      "loss": 2.1714,
      "step": 434
    },
    {
      "epoch": 0.174,
      "grad_norm": 0.4985419505444372,
      "learning_rate": 4.733003868055923e-05,
      "loss": 2.2002,
      "step": 435
    },
    {
      "epoch": 0.1744,
      "grad_norm": 0.4748313436699936,
      "learning_rate": 4.731545667130198e-05,
      "loss": 2.1909,
      "step": 436
    },
    {
      "epoch": 0.1748,
      "grad_norm": 0.4685282716687799,
      "learning_rate": 4.730083720944427e-05,
      "loss": 2.1934,
      "step": 437
    },
    {
      "epoch": 0.1752,
      "grad_norm": 0.5230352657941082,
      "learning_rate": 4.728618031952232e-05,
      "loss": 2.2314,
      "step": 438
    },
    {
      "epoch": 0.1756,
      "grad_norm": 0.48223583146039384,
      "learning_rate": 4.727148602613517e-05,
      "loss": 2.2271,
      "step": 439
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.5120401378654,
      "learning_rate": 4.72567543539446e-05,
      "loss": 2.2622,
      "step": 440
    },
    {
      "epoch": 0.1764,
      "grad_norm": 0.5362325626581287,
      "learning_rate": 4.724198532767518e-05,
      "loss": 2.2207,
      "step": 441
    },
    {
      "epoch": 0.1768,
      "grad_norm": 0.4958112073019397,
      "learning_rate": 4.722717897211413e-05,
      "loss": 2.2539,
      "step": 442
    },
    {
      "epoch": 0.1772,
      "grad_norm": 0.49822761891095724,
      "learning_rate": 4.721233531211133e-05,
      "loss": 2.2026,
      "step": 443
    },
    {
      "epoch": 0.1776,
      "grad_norm": 0.48167895087812707,
      "learning_rate": 4.719745437257929e-05,
      "loss": 2.1621,
      "step": 444
    },
    {
      "epoch": 0.178,
      "grad_norm": 0.4855733047183537,
      "learning_rate": 4.718253617849306e-05,
      "loss": 2.2109,
      "step": 445
    },
    {
      "epoch": 0.1784,
      "grad_norm": 0.5075469222902721,
      "learning_rate": 4.716758075489022e-05,
      "loss": 2.1445,
      "step": 446
    },
    {
      "epoch": 0.1788,
      "grad_norm": 0.5164529899204756,
      "learning_rate": 4.715258812687086e-05,
      "loss": 2.2637,
      "step": 447
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.49922454183997295,
      "learning_rate": 4.7137558319597456e-05,
      "loss": 2.3027,
      "step": 448
    },
    {
      "epoch": 0.1796,
      "grad_norm": 0.5269058177957775,
      "learning_rate": 4.7122491358294954e-05,
      "loss": 2.2295,
      "step": 449
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5024397733415412,
      "learning_rate": 4.710738726825059e-05,
      "loss": 2.2026,
      "step": 450
    },
    {
      "epoch": 0.1804,
      "grad_norm": 0.48637498326946144,
      "learning_rate": 4.7092246074813963e-05,
      "loss": 2.0811,
      "step": 451
    },
    {
      "epoch": 0.1808,
      "grad_norm": 0.4938565622985034,
      "learning_rate": 4.707706780339693e-05,
      "loss": 2.2197,
      "step": 452
    },
    {
      "epoch": 0.1812,
      "grad_norm": 0.49198268196148226,
      "learning_rate": 4.7061852479473536e-05,
      "loss": 2.1875,
      "step": 453
    },
    {
      "epoch": 0.1816,
      "grad_norm": 0.4844089303557517,
      "learning_rate": 4.704660012858009e-05,
      "loss": 2.2744,
      "step": 454
    },
    {
      "epoch": 0.182,
      "grad_norm": 0.48017241377302067,
      "learning_rate": 4.703131077631497e-05,
      "loss": 2.2612,
      "step": 455
    },
    {
      "epoch": 0.1824,
      "grad_norm": 0.5142642879209809,
      "learning_rate": 4.701598444833871e-05,
      "loss": 2.2295,
      "step": 456
    },
    {
      "epoch": 0.1828,
      "grad_norm": 0.45564460917262883,
      "learning_rate": 4.7000621170373856e-05,
      "loss": 2.1909,
      "step": 457
    },
    {
      "epoch": 0.1832,
      "grad_norm": 0.5057386836927121,
      "learning_rate": 4.6985220968205e-05,
      "loss": 2.248,
      "step": 458
    },
    {
      "epoch": 0.1836,
      "grad_norm": 0.4705698658306484,
      "learning_rate": 4.696978386767871e-05,
      "loss": 2.126,
      "step": 459
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.47193913244905183,
      "learning_rate": 4.695430989470343e-05,
      "loss": 2.1899,
      "step": 460
    },
    {
      "epoch": 0.1844,
      "grad_norm": 0.48628543315698153,
      "learning_rate": 4.693879907524955e-05,
      "loss": 2.2148,
      "step": 461
    },
    {
      "epoch": 0.1848,
      "grad_norm": 0.5258095374853937,
      "learning_rate": 4.692325143534928e-05,
      "loss": 2.2646,
      "step": 462
    },
    {
      "epoch": 0.1852,
      "grad_norm": 0.4799001537964823,
      "learning_rate": 4.690766700109659e-05,
      "loss": 2.1948,
      "step": 463
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.4705187115762738,
      "learning_rate": 4.689204579864727e-05,
      "loss": 2.2144,
      "step": 464
    },
    {
      "epoch": 0.186,
      "grad_norm": 0.4874371264608158,
      "learning_rate": 4.687638785421875e-05,
      "loss": 2.1865,
      "step": 465
    },
    {
      "epoch": 0.1864,
      "grad_norm": 0.483875122167504,
      "learning_rate": 4.686069319409018e-05,
      "loss": 2.1836,
      "step": 466
    },
    {
      "epoch": 0.1868,
      "grad_norm": 0.5252921458962554,
      "learning_rate": 4.68449618446023e-05,
      "loss": 2.1987,
      "step": 467
    },
    {
      "epoch": 0.1872,
      "grad_norm": 0.46354642954880065,
      "learning_rate": 4.682919383215744e-05,
      "loss": 2.2031,
      "step": 468
    },
    {
      "epoch": 0.1876,
      "grad_norm": 0.48336898840199694,
      "learning_rate": 4.6813389183219445e-05,
      "loss": 2.2222,
      "step": 469
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.47064487743509914,
      "learning_rate": 4.679754792431368e-05,
      "loss": 2.1812,
      "step": 470
    },
    {
      "epoch": 0.1884,
      "grad_norm": 0.46919893796399254,
      "learning_rate": 4.678167008202692e-05,
      "loss": 2.2173,
      "step": 471
    },
    {
      "epoch": 0.1888,
      "grad_norm": 0.4764704851012529,
      "learning_rate": 4.676575568300736e-05,
      "loss": 2.1929,
      "step": 472
    },
    {
      "epoch": 0.1892,
      "grad_norm": 0.4646507691768134,
      "learning_rate": 4.674980475396453e-05,
      "loss": 2.1826,
      "step": 473
    },
    {
      "epoch": 0.1896,
      "grad_norm": 0.48996845839078823,
      "learning_rate": 4.67338173216693e-05,
      "loss": 2.1499,
      "step": 474
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4871573540107831,
      "learning_rate": 4.671779341295378e-05,
      "loss": 2.2031,
      "step": 475
    },
    {
      "epoch": 0.1904,
      "grad_norm": 0.439732225990999,
      "learning_rate": 4.670173305471129e-05,
      "loss": 2.0845,
      "step": 476
    },
    {
      "epoch": 0.1908,
      "grad_norm": 0.48462438627893833,
      "learning_rate": 4.668563627389636e-05,
      "loss": 2.2651,
      "step": 477
    },
    {
      "epoch": 0.1912,
      "grad_norm": 0.43999078360537425,
      "learning_rate": 4.6669503097524615e-05,
      "loss": 2.1235,
      "step": 478
    },
    {
      "epoch": 0.1916,
      "grad_norm": 0.4893741623328723,
      "learning_rate": 4.665333355267278e-05,
      "loss": 2.1323,
      "step": 479
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.48045416960124726,
      "learning_rate": 4.663712766647862e-05,
      "loss": 2.1992,
      "step": 480
    },
    {
      "epoch": 0.1924,
      "grad_norm": 0.44559404012544257,
      "learning_rate": 4.662088546614087e-05,
      "loss": 2.1914,
      "step": 481
    },
    {
      "epoch": 0.1928,
      "grad_norm": 0.454142308699843,
      "learning_rate": 4.660460697891925e-05,
      "loss": 2.2944,
      "step": 482
    },
    {
      "epoch": 0.1932,
      "grad_norm": 0.4941241933511073,
      "learning_rate": 4.6588292232134354e-05,
      "loss": 2.231,
      "step": 483
    },
    {
      "epoch": 0.1936,
      "grad_norm": 0.4699836747607072,
      "learning_rate": 4.657194125316763e-05,
      "loss": 2.1523,
      "step": 484
    },
    {
      "epoch": 0.194,
      "grad_norm": 0.5148101214170921,
      "learning_rate": 4.655555406946135e-05,
      "loss": 2.2192,
      "step": 485
    },
    {
      "epoch": 0.1944,
      "grad_norm": 0.5035016076403931,
      "learning_rate": 4.653913070851855e-05,
      "loss": 2.1196,
      "step": 486
    },
    {
      "epoch": 0.1948,
      "grad_norm": 0.5129999963912437,
      "learning_rate": 4.6522671197902955e-05,
      "loss": 2.1704,
      "step": 487
    },
    {
      "epoch": 0.1952,
      "grad_norm": 0.5143956170355788,
      "learning_rate": 4.650617556523901e-05,
      "loss": 2.1997,
      "step": 488
    },
    {
      "epoch": 0.1956,
      "grad_norm": 0.532049775120337,
      "learning_rate": 4.648964383821173e-05,
      "loss": 2.2476,
      "step": 489
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.48918037260234565,
      "learning_rate": 4.647307604456674e-05,
      "loss": 2.2412,
      "step": 490
    },
    {
      "epoch": 0.1964,
      "grad_norm": 0.5179749991318248,
      "learning_rate": 4.645647221211021e-05,
      "loss": 2.2095,
      "step": 491
    },
    {
      "epoch": 0.1968,
      "grad_norm": 0.4703588441668153,
      "learning_rate": 4.6439832368708756e-05,
      "loss": 2.1089,
      "step": 492
    },
    {
      "epoch": 0.1972,
      "grad_norm": 0.4632497326222306,
      "learning_rate": 4.642315654228946e-05,
      "loss": 2.1733,
      "step": 493
    },
    {
      "epoch": 0.1976,
      "grad_norm": 0.5043813431366397,
      "learning_rate": 4.640644476083978e-05,
      "loss": 2.2573,
      "step": 494
    },
    {
      "epoch": 0.198,
      "grad_norm": 0.4525120906679787,
      "learning_rate": 4.6389697052407534e-05,
      "loss": 2.1494,
      "step": 495
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.4978886372856171,
      "learning_rate": 4.637291344510082e-05,
      "loss": 2.127,
      "step": 496
    },
    {
      "epoch": 0.1988,
      "grad_norm": 0.46164579176034626,
      "learning_rate": 4.6356093967088005e-05,
      "loss": 2.1777,
      "step": 497
    },
    {
      "epoch": 0.1992,
      "grad_norm": 0.4941437347484188,
      "learning_rate": 4.633923864659764e-05,
      "loss": 2.2456,
      "step": 498
    },
    {
      "epoch": 0.1996,
      "grad_norm": 0.4691666079202479,
      "learning_rate": 4.632234751191844e-05,
      "loss": 2.1284,
      "step": 499
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4771517957795159,
      "learning_rate": 4.630542059139924e-05,
      "loss": 2.2495,
      "step": 500
    },
    {
      "epoch": 0.2004,
      "grad_norm": 0.48830453410434294,
      "learning_rate": 4.62884579134489e-05,
      "loss": 2.2754,
      "step": 501
    },
    {
      "epoch": 0.2008,
      "grad_norm": 0.4451752882541677,
      "learning_rate": 4.627145950653633e-05,
      "loss": 2.2153,
      "step": 502
    },
    {
      "epoch": 0.2012,
      "grad_norm": 0.48639656121470104,
      "learning_rate": 4.625442539919039e-05,
      "loss": 2.3218,
      "step": 503
    },
    {
      "epoch": 0.2016,
      "grad_norm": 0.43418976374204943,
      "learning_rate": 4.623735561999985e-05,
      "loss": 2.084,
      "step": 504
    },
    {
      "epoch": 0.202,
      "grad_norm": 0.4577111603114536,
      "learning_rate": 4.622025019761336e-05,
      "loss": 2.165,
      "step": 505
    },
    {
      "epoch": 0.2024,
      "grad_norm": 0.46707164400568985,
      "learning_rate": 4.62031091607394e-05,
      "loss": 2.188,
      "step": 506
    },
    {
      "epoch": 0.2028,
      "grad_norm": 0.44897515423403345,
      "learning_rate": 4.618593253814618e-05,
      "loss": 2.2251,
      "step": 507
    },
    {
      "epoch": 0.2032,
      "grad_norm": 0.4607689650529429,
      "learning_rate": 4.61687203586617e-05,
      "loss": 2.1831,
      "step": 508
    },
    {
      "epoch": 0.2036,
      "grad_norm": 0.4456775266428172,
      "learning_rate": 4.615147265117356e-05,
      "loss": 2.1733,
      "step": 509
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.48457167476406526,
      "learning_rate": 4.613418944462907e-05,
      "loss": 2.2236,
      "step": 510
    },
    {
      "epoch": 0.2044,
      "grad_norm": 0.45903166144501756,
      "learning_rate": 4.6116870768035046e-05,
      "loss": 2.1792,
      "step": 511
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.4785056848219941,
      "learning_rate": 4.6099516650457876e-05,
      "loss": 2.1987,
      "step": 512
    },
    {
      "epoch": 0.2052,
      "grad_norm": 0.48607059421731047,
      "learning_rate": 4.608212712102341e-05,
      "loss": 2.1084,
      "step": 513
    },
    {
      "epoch": 0.2056,
      "grad_norm": 0.5012990002603451,
      "learning_rate": 4.6064702208916955e-05,
      "loss": 2.2534,
      "step": 514
    },
    {
      "epoch": 0.206,
      "grad_norm": 0.47128517407836706,
      "learning_rate": 4.6047241943383176e-05,
      "loss": 2.1392,
      "step": 515
    },
    {
      "epoch": 0.2064,
      "grad_norm": 0.4747125245213326,
      "learning_rate": 4.6029746353726085e-05,
      "loss": 2.1958,
      "step": 516
    },
    {
      "epoch": 0.2068,
      "grad_norm": 0.4812557448481859,
      "learning_rate": 4.601221546930897e-05,
      "loss": 2.2261,
      "step": 517
    },
    {
      "epoch": 0.2072,
      "grad_norm": 0.4361962532283022,
      "learning_rate": 4.599464931955437e-05,
      "loss": 2.2065,
      "step": 518
    },
    {
      "epoch": 0.2076,
      "grad_norm": 0.4922201263583968,
      "learning_rate": 4.5977047933943995e-05,
      "loss": 2.1968,
      "step": 519
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.4649441997431433,
      "learning_rate": 4.595941134201871e-05,
      "loss": 2.1401,
      "step": 520
    },
    {
      "epoch": 0.2084,
      "grad_norm": 0.4887775916042944,
      "learning_rate": 4.594173957337844e-05,
      "loss": 2.2441,
      "step": 521
    },
    {
      "epoch": 0.2088,
      "grad_norm": 0.49692186716926506,
      "learning_rate": 4.5924032657682185e-05,
      "loss": 2.208,
      "step": 522
    },
    {
      "epoch": 0.2092,
      "grad_norm": 0.45950904082379923,
      "learning_rate": 4.590629062464791e-05,
      "loss": 2.1631,
      "step": 523
    },
    {
      "epoch": 0.2096,
      "grad_norm": 0.46029517780284923,
      "learning_rate": 4.5888513504052504e-05,
      "loss": 2.1172,
      "step": 524
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.47568264802224797,
      "learning_rate": 4.587070132573178e-05,
      "loss": 2.2153,
      "step": 525
    },
    {
      "epoch": 0.2104,
      "grad_norm": 0.44715438833224674,
      "learning_rate": 4.585285411958037e-05,
      "loss": 2.1948,
      "step": 526
    },
    {
      "epoch": 0.2108,
      "grad_norm": 0.48727701723590516,
      "learning_rate": 4.583497191555169e-05,
      "loss": 2.1694,
      "step": 527
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.45362682247693226,
      "learning_rate": 4.58170547436579e-05,
      "loss": 2.1641,
      "step": 528
    },
    {
      "epoch": 0.2116,
      "grad_norm": 0.4659958591037967,
      "learning_rate": 4.5799102633969845e-05,
      "loss": 2.1523,
      "step": 529
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.46731598381372946,
      "learning_rate": 4.578111561661702e-05,
      "loss": 2.209,
      "step": 530
    },
    {
      "epoch": 0.2124,
      "grad_norm": 0.43184631291829334,
      "learning_rate": 4.576309372178749e-05,
      "loss": 2.1895,
      "step": 531
    },
    {
      "epoch": 0.2128,
      "grad_norm": 0.47964476891740576,
      "learning_rate": 4.574503697972784e-05,
      "loss": 2.1147,
      "step": 532
    },
    {
      "epoch": 0.2132,
      "grad_norm": 0.5078402608147669,
      "learning_rate": 4.5726945420743194e-05,
      "loss": 2.1895,
      "step": 533
    },
    {
      "epoch": 0.2136,
      "grad_norm": 0.5149452242414474,
      "learning_rate": 4.570881907519706e-05,
      "loss": 2.1777,
      "step": 534
    },
    {
      "epoch": 0.214,
      "grad_norm": 0.4870747901396786,
      "learning_rate": 4.569065797351135e-05,
      "loss": 2.1899,
      "step": 535
    },
    {
      "epoch": 0.2144,
      "grad_norm": 0.49530750735429807,
      "learning_rate": 4.5672462146166306e-05,
      "loss": 2.166,
      "step": 536
    },
    {
      "epoch": 0.2148,
      "grad_norm": 0.4738206855728224,
      "learning_rate": 4.565423162370044e-05,
      "loss": 2.1484,
      "step": 537
    },
    {
      "epoch": 0.2152,
      "grad_norm": 0.461236110038122,
      "learning_rate": 4.563596643671051e-05,
      "loss": 2.2373,
      "step": 538
    },
    {
      "epoch": 0.2156,
      "grad_norm": 0.4475649724596905,
      "learning_rate": 4.561766661585145e-05,
      "loss": 2.1484,
      "step": 539
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.4813887918861564,
      "learning_rate": 4.5599332191836316e-05,
      "loss": 2.1587,
      "step": 540
    },
    {
      "epoch": 0.2164,
      "grad_norm": 0.4691784149411088,
      "learning_rate": 4.5580963195436225e-05,
      "loss": 2.1914,
      "step": 541
    },
    {
      "epoch": 0.2168,
      "grad_norm": 0.4617700150915224,
      "learning_rate": 4.5562559657480354e-05,
      "loss": 2.2393,
      "step": 542
    },
    {
      "epoch": 0.2172,
      "grad_norm": 0.4762179307977652,
      "learning_rate": 4.554412160885581e-05,
      "loss": 2.1416,
      "step": 543
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.5136208755909264,
      "learning_rate": 4.552564908050765e-05,
      "loss": 2.2476,
      "step": 544
    },
    {
      "epoch": 0.218,
      "grad_norm": 0.46622837580059406,
      "learning_rate": 4.5507142103438794e-05,
      "loss": 2.2236,
      "step": 545
    },
    {
      "epoch": 0.2184,
      "grad_norm": 0.45528955589301345,
      "learning_rate": 4.548860070870997e-05,
      "loss": 2.188,
      "step": 546
    },
    {
      "epoch": 0.2188,
      "grad_norm": 0.44566278494303835,
      "learning_rate": 4.547002492743967e-05,
      "loss": 2.1914,
      "step": 547
    },
    {
      "epoch": 0.2192,
      "grad_norm": 0.45281825803699627,
      "learning_rate": 4.545141479080412e-05,
      "loss": 2.1729,
      "step": 548
    },
    {
      "epoch": 0.2196,
      "grad_norm": 0.45768082955270534,
      "learning_rate": 4.543277033003715e-05,
      "loss": 2.1846,
      "step": 549
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4828567470068587,
      "learning_rate": 4.541409157643027e-05,
      "loss": 2.2114,
      "step": 550
    },
    {
      "epoch": 0.2204,
      "grad_norm": 0.47605547428777556,
      "learning_rate": 4.5395378561332504e-05,
      "loss": 2.2573,
      "step": 551
    },
    {
      "epoch": 0.2208,
      "grad_norm": 0.48125883913127504,
      "learning_rate": 4.5376631316150365e-05,
      "loss": 2.1514,
      "step": 552
    },
    {
      "epoch": 0.2212,
      "grad_norm": 0.45537726436619186,
      "learning_rate": 4.5357849872347844e-05,
      "loss": 2.1768,
      "step": 553
    },
    {
      "epoch": 0.2216,
      "grad_norm": 0.4568702691640254,
      "learning_rate": 4.5339034261446315e-05,
      "loss": 2.1406,
      "step": 554
    },
    {
      "epoch": 0.222,
      "grad_norm": 0.4658898642400385,
      "learning_rate": 4.53201845150245e-05,
      "loss": 2.252,
      "step": 555
    },
    {
      "epoch": 0.2224,
      "grad_norm": 0.5039187349059965,
      "learning_rate": 4.530130066471841e-05,
      "loss": 2.252,
      "step": 556
    },
    {
      "epoch": 0.2228,
      "grad_norm": 0.4733085931728575,
      "learning_rate": 4.528238274222129e-05,
      "loss": 2.2246,
      "step": 557
    },
    {
      "epoch": 0.2232,
      "grad_norm": 0.4575488644792462,
      "learning_rate": 4.526343077928358e-05,
      "loss": 2.1895,
      "step": 558
    },
    {
      "epoch": 0.2236,
      "grad_norm": 0.4696322666012624,
      "learning_rate": 4.524444480771283e-05,
      "loss": 2.1914,
      "step": 559
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.4629854028647057,
      "learning_rate": 4.522542485937369e-05,
      "loss": 2.1328,
      "step": 560
    },
    {
      "epoch": 0.2244,
      "grad_norm": 0.44941116698573663,
      "learning_rate": 4.520637096618782e-05,
      "loss": 2.2134,
      "step": 561
    },
    {
      "epoch": 0.2248,
      "grad_norm": 0.5098133907296057,
      "learning_rate": 4.518728316013386e-05,
      "loss": 2.1875,
      "step": 562
    },
    {
      "epoch": 0.2252,
      "grad_norm": 0.48742882961131767,
      "learning_rate": 4.516816147324736e-05,
      "loss": 2.1567,
      "step": 563
    },
    {
      "epoch": 0.2256,
      "grad_norm": 0.46992155856015505,
      "learning_rate": 4.5149005937620734e-05,
      "loss": 2.2241,
      "step": 564
    },
    {
      "epoch": 0.226,
      "grad_norm": 0.45917585783560727,
      "learning_rate": 4.5129816585403206e-05,
      "loss": 2.1753,
      "step": 565
    },
    {
      "epoch": 0.2264,
      "grad_norm": 0.4926648008534796,
      "learning_rate": 4.511059344880076e-05,
      "loss": 2.2026,
      "step": 566
    },
    {
      "epoch": 0.2268,
      "grad_norm": 0.45833193965133945,
      "learning_rate": 4.509133656007607e-05,
      "loss": 2.1499,
      "step": 567
    },
    {
      "epoch": 0.2272,
      "grad_norm": 0.47482008901748884,
      "learning_rate": 4.507204595154847e-05,
      "loss": 2.1362,
      "step": 568
    },
    {
      "epoch": 0.2276,
      "grad_norm": 0.4967282005497287,
      "learning_rate": 4.505272165559388e-05,
      "loss": 2.2471,
      "step": 569
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.4584875810945552,
      "learning_rate": 4.503336370464476e-05,
      "loss": 2.0366,
      "step": 570
    },
    {
      "epoch": 0.2284,
      "grad_norm": 0.4577554920028301,
      "learning_rate": 4.501397213119004e-05,
      "loss": 2.0767,
      "step": 571
    },
    {
      "epoch": 0.2288,
      "grad_norm": 0.47052324020374686,
      "learning_rate": 4.4994546967775105e-05,
      "loss": 2.1763,
      "step": 572
    },
    {
      "epoch": 0.2292,
      "grad_norm": 0.45563820583811576,
      "learning_rate": 4.49750882470017e-05,
      "loss": 2.1929,
      "step": 573
    },
    {
      "epoch": 0.2296,
      "grad_norm": 0.4636878817086697,
      "learning_rate": 4.49555960015279e-05,
      "loss": 2.2285,
      "step": 574
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4731955510202618,
      "learning_rate": 4.493607026406802e-05,
      "loss": 2.2544,
      "step": 575
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.4755999580162783,
      "learning_rate": 4.491651106739262e-05,
      "loss": 2.1777,
      "step": 576
    },
    {
      "epoch": 0.2308,
      "grad_norm": 0.49559014153396197,
      "learning_rate": 4.4896918444328395e-05,
      "loss": 2.2856,
      "step": 577
    },
    {
      "epoch": 0.2312,
      "grad_norm": 0.5105890077826356,
      "learning_rate": 4.4877292427758147e-05,
      "loss": 2.2705,
      "step": 578
    },
    {
      "epoch": 0.2316,
      "grad_norm": 0.44453749225073697,
      "learning_rate": 4.485763305062071e-05,
      "loss": 2.0669,
      "step": 579
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.4716162716026497,
      "learning_rate": 4.4837940345910925e-05,
      "loss": 2.1997,
      "step": 580
    },
    {
      "epoch": 0.2324,
      "grad_norm": 0.4498331506095055,
      "learning_rate": 4.481821434667956e-05,
      "loss": 2.2363,
      "step": 581
    },
    {
      "epoch": 0.2328,
      "grad_norm": 0.5062199613529035,
      "learning_rate": 4.4798455086033264e-05,
      "loss": 2.1655,
      "step": 582
    },
    {
      "epoch": 0.2332,
      "grad_norm": 0.47113886223514867,
      "learning_rate": 4.477866259713451e-05,
      "loss": 2.2051,
      "step": 583
    },
    {
      "epoch": 0.2336,
      "grad_norm": 0.519307132694357,
      "learning_rate": 4.4758836913201536e-05,
      "loss": 2.2246,
      "step": 584
    },
    {
      "epoch": 0.234,
      "grad_norm": 0.47507782399473514,
      "learning_rate": 4.473897806750829e-05,
      "loss": 2.2651,
      "step": 585
    },
    {
      "epoch": 0.2344,
      "grad_norm": 0.5233344745207319,
      "learning_rate": 4.4719086093384385e-05,
      "loss": 2.1973,
      "step": 586
    },
    {
      "epoch": 0.2348,
      "grad_norm": 0.48435754030821526,
      "learning_rate": 4.469916102421502e-05,
      "loss": 2.2959,
      "step": 587
    },
    {
      "epoch": 0.2352,
      "grad_norm": 0.5075220577234562,
      "learning_rate": 4.467920289344096e-05,
      "loss": 2.1201,
      "step": 588
    },
    {
      "epoch": 0.2356,
      "grad_norm": 0.47585989651713256,
      "learning_rate": 4.4659211734558435e-05,
      "loss": 2.1616,
      "step": 589
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.5241863585784937,
      "learning_rate": 4.463918758111912e-05,
      "loss": 2.1689,
      "step": 590
    },
    {
      "epoch": 0.2364,
      "grad_norm": 0.4853701304327406,
      "learning_rate": 4.4619130466730065e-05,
      "loss": 2.29,
      "step": 591
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.5270394612116647,
      "learning_rate": 4.459904042505363e-05,
      "loss": 2.144,
      "step": 592
    },
    {
      "epoch": 0.2372,
      "grad_norm": 0.490304351131468,
      "learning_rate": 4.457891748980746e-05,
      "loss": 2.269,
      "step": 593
    },
    {
      "epoch": 0.2376,
      "grad_norm": 0.49521475146916366,
      "learning_rate": 4.455876169476437e-05,
      "loss": 2.1973,
      "step": 594
    },
    {
      "epoch": 0.238,
      "grad_norm": 0.5092747220589455,
      "learning_rate": 4.4538573073752365e-05,
      "loss": 2.0952,
      "step": 595
    },
    {
      "epoch": 0.2384,
      "grad_norm": 0.48995165231626353,
      "learning_rate": 4.4518351660654504e-05,
      "loss": 2.2212,
      "step": 596
    },
    {
      "epoch": 0.2388,
      "grad_norm": 0.498838521649635,
      "learning_rate": 4.449809748940892e-05,
      "loss": 2.145,
      "step": 597
    },
    {
      "epoch": 0.2392,
      "grad_norm": 0.45620261773427057,
      "learning_rate": 4.447781059400869e-05,
      "loss": 2.1885,
      "step": 598
    },
    {
      "epoch": 0.2396,
      "grad_norm": 0.4684409414804571,
      "learning_rate": 4.445749100850184e-05,
      "loss": 2.2036,
      "step": 599
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.47686857673142014,
      "learning_rate": 4.443713876699124e-05,
      "loss": 2.3047,
      "step": 600
    },
    {
      "epoch": 0.2404,
      "grad_norm": 0.4872073301440845,
      "learning_rate": 4.441675390363458e-05,
      "loss": 2.2173,
      "step": 601
    },
    {
      "epoch": 0.2408,
      "grad_norm": 0.4740481312620313,
      "learning_rate": 4.4396336452644296e-05,
      "loss": 2.228,
      "step": 602
    },
    {
      "epoch": 0.2412,
      "grad_norm": 0.4392113515356955,
      "learning_rate": 4.437588644828751e-05,
      "loss": 2.1675,
      "step": 603
    },
    {
      "epoch": 0.2416,
      "grad_norm": 0.4616360876113348,
      "learning_rate": 4.4355403924885996e-05,
      "loss": 2.1484,
      "step": 604
    },
    {
      "epoch": 0.242,
      "grad_norm": 0.4595513111423401,
      "learning_rate": 4.43348889168161e-05,
      "loss": 2.168,
      "step": 605
    },
    {
      "epoch": 0.2424,
      "grad_norm": 0.44970427966755855,
      "learning_rate": 4.4314341458508674e-05,
      "loss": 2.1577,
      "step": 606
    },
    {
      "epoch": 0.2428,
      "grad_norm": 0.4885625827665708,
      "learning_rate": 4.429376158444905e-05,
      "loss": 2.2144,
      "step": 607
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.48517337929257376,
      "learning_rate": 4.4273149329176934e-05,
      "loss": 2.1548,
      "step": 608
    },
    {
      "epoch": 0.2436,
      "grad_norm": 0.4890668745585946,
      "learning_rate": 4.425250472728643e-05,
      "loss": 2.189,
      "step": 609
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.4501624100720458,
      "learning_rate": 4.4231827813425885e-05,
      "loss": 2.1465,
      "step": 610
    },
    {
      "epoch": 0.2444,
      "grad_norm": 0.5091447185001774,
      "learning_rate": 4.4211118622297885e-05,
      "loss": 2.2148,
      "step": 611
    },
    {
      "epoch": 0.2448,
      "grad_norm": 0.5039609243382136,
      "learning_rate": 4.4190377188659215e-05,
      "loss": 2.228,
      "step": 612
    },
    {
      "epoch": 0.2452,
      "grad_norm": 0.4861058945249217,
      "learning_rate": 4.4169603547320726e-05,
      "loss": 2.2178,
      "step": 613
    },
    {
      "epoch": 0.2456,
      "grad_norm": 0.48264593721144483,
      "learning_rate": 4.4148797733147374e-05,
      "loss": 2.2178,
      "step": 614
    },
    {
      "epoch": 0.246,
      "grad_norm": 0.4735883059007915,
      "learning_rate": 4.412795978105807e-05,
      "loss": 2.1211,
      "step": 615
    },
    {
      "epoch": 0.2464,
      "grad_norm": 0.4486744240117307,
      "learning_rate": 4.41070897260257e-05,
      "loss": 2.1318,
      "step": 616
    },
    {
      "epoch": 0.2468,
      "grad_norm": 0.47492899835406305,
      "learning_rate": 4.408618760307699e-05,
      "loss": 2.2939,
      "step": 617
    },
    {
      "epoch": 0.2472,
      "grad_norm": 0.4566794001217435,
      "learning_rate": 4.406525344729251e-05,
      "loss": 2.2559,
      "step": 618
    },
    {
      "epoch": 0.2476,
      "grad_norm": 0.46488707259400514,
      "learning_rate": 4.40442872938066e-05,
      "loss": 2.1318,
      "step": 619
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.48668200620738633,
      "learning_rate": 4.402328917780728e-05,
      "loss": 2.2051,
      "step": 620
    },
    {
      "epoch": 0.2484,
      "grad_norm": 0.4663245132762808,
      "learning_rate": 4.400225913453623e-05,
      "loss": 2.27,
      "step": 621
    },
    {
      "epoch": 0.2488,
      "grad_norm": 0.4660689347522734,
      "learning_rate": 4.39811971992887e-05,
      "loss": 2.1548,
      "step": 622
    },
    {
      "epoch": 0.2492,
      "grad_norm": 0.48734028044200284,
      "learning_rate": 4.396010340741349e-05,
      "loss": 2.2676,
      "step": 623
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.48243058195892324,
      "learning_rate": 4.393897779431283e-05,
      "loss": 2.2314,
      "step": 624
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.49411053077746475,
      "learning_rate": 4.391782039544238e-05,
      "loss": 2.2036,
      "step": 625
    },
    {
      "epoch": 0.2504,
      "grad_norm": 0.4862756543739581,
      "learning_rate": 4.389663124631115e-05,
      "loss": 2.1475,
      "step": 626
    },
    {
      "epoch": 0.2508,
      "grad_norm": 0.46655326919728374,
      "learning_rate": 4.387541038248143e-05,
      "loss": 2.2007,
      "step": 627
    },
    {
      "epoch": 0.2512,
      "grad_norm": 0.4493262994232095,
      "learning_rate": 4.385415783956873e-05,
      "loss": 2.1685,
      "step": 628
    },
    {
      "epoch": 0.2516,
      "grad_norm": 0.467182368913035,
      "learning_rate": 4.383287365324175e-05,
      "loss": 2.2246,
      "step": 629
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.44341056263969436,
      "learning_rate": 4.3811557859222254e-05,
      "loss": 2.1982,
      "step": 630
    },
    {
      "epoch": 0.2524,
      "grad_norm": 0.5354146071097677,
      "learning_rate": 4.3790210493285114e-05,
      "loss": 2.2314,
      "step": 631
    },
    {
      "epoch": 0.2528,
      "grad_norm": 0.4450031829560977,
      "learning_rate": 4.376883159125814e-05,
      "loss": 2.126,
      "step": 632
    },
    {
      "epoch": 0.2532,
      "grad_norm": 0.45431091193701545,
      "learning_rate": 4.3747421189022095e-05,
      "loss": 2.1538,
      "step": 633
    },
    {
      "epoch": 0.2536,
      "grad_norm": 0.46657227671059043,
      "learning_rate": 4.372597932251061e-05,
      "loss": 2.1245,
      "step": 634
    },
    {
      "epoch": 0.254,
      "grad_norm": 0.45974715733367033,
      "learning_rate": 4.3704506027710105e-05,
      "loss": 2.1963,
      "step": 635
    },
    {
      "epoch": 0.2544,
      "grad_norm": 0.4549344162598273,
      "learning_rate": 4.368300134065976e-05,
      "loss": 2.2017,
      "step": 636
    },
    {
      "epoch": 0.2548,
      "grad_norm": 0.44237485729367054,
      "learning_rate": 4.366146529745145e-05,
      "loss": 2.2061,
      "step": 637
    },
    {
      "epoch": 0.2552,
      "grad_norm": 0.4454473381871712,
      "learning_rate": 4.363989793422966e-05,
      "loss": 2.1694,
      "step": 638
    },
    {
      "epoch": 0.2556,
      "grad_norm": 0.4406704864051487,
      "learning_rate": 4.3618299287191446e-05,
      "loss": 2.1655,
      "step": 639
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.4399417991575937,
      "learning_rate": 4.3596669392586365e-05,
      "loss": 2.1631,
      "step": 640
    },
    {
      "epoch": 0.2564,
      "grad_norm": 0.443437960644541,
      "learning_rate": 4.357500828671642e-05,
      "loss": 2.166,
      "step": 641
    },
    {
      "epoch": 0.2568,
      "grad_norm": 0.45090548720533896,
      "learning_rate": 4.355331600593601e-05,
      "loss": 2.1465,
      "step": 642
    },
    {
      "epoch": 0.2572,
      "grad_norm": 0.4482795290868131,
      "learning_rate": 4.3531592586651834e-05,
      "loss": 2.1562,
      "step": 643
    },
    {
      "epoch": 0.2576,
      "grad_norm": 0.4670484404203382,
      "learning_rate": 4.3509838065322875e-05,
      "loss": 2.188,
      "step": 644
    },
    {
      "epoch": 0.258,
      "grad_norm": 0.4502232753307084,
      "learning_rate": 4.348805247846027e-05,
      "loss": 2.1514,
      "step": 645
    },
    {
      "epoch": 0.2584,
      "grad_norm": 0.46505552310818726,
      "learning_rate": 4.3466235862627355e-05,
      "loss": 2.2368,
      "step": 646
    },
    {
      "epoch": 0.2588,
      "grad_norm": 0.46315098458088516,
      "learning_rate": 4.34443882544395e-05,
      "loss": 2.1865,
      "step": 647
    },
    {
      "epoch": 0.2592,
      "grad_norm": 0.43130958447733025,
      "learning_rate": 4.3422509690564106e-05,
      "loss": 2.2139,
      "step": 648
    },
    {
      "epoch": 0.2596,
      "grad_norm": 0.48841163118238945,
      "learning_rate": 4.340060020772053e-05,
      "loss": 2.1899,
      "step": 649
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4584516514180604,
      "learning_rate": 4.337865984268001e-05,
      "loss": 2.2012,
      "step": 650
    },
    {
      "epoch": 0.2604,
      "grad_norm": 0.47037064827458247,
      "learning_rate": 4.335668863226562e-05,
      "loss": 2.2095,
      "step": 651
    },
    {
      "epoch": 0.2608,
      "grad_norm": 0.48800031369204355,
      "learning_rate": 4.333468661335221e-05,
      "loss": 2.1299,
      "step": 652
    },
    {
      "epoch": 0.2612,
      "grad_norm": 0.45122879807246075,
      "learning_rate": 4.3312653822866326e-05,
      "loss": 2.1938,
      "step": 653
    },
    {
      "epoch": 0.2616,
      "grad_norm": 0.49711183213319143,
      "learning_rate": 4.329059029778616e-05,
      "loss": 2.2798,
      "step": 654
    },
    {
      "epoch": 0.262,
      "grad_norm": 0.43855003388764296,
      "learning_rate": 4.326849607514148e-05,
      "loss": 2.1567,
      "step": 655
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.4940097107039588,
      "learning_rate": 4.3246371192013615e-05,
      "loss": 2.3081,
      "step": 656
    },
    {
      "epoch": 0.2628,
      "grad_norm": 0.47448391311591714,
      "learning_rate": 4.3224215685535294e-05,
      "loss": 2.2002,
      "step": 657
    },
    {
      "epoch": 0.2632,
      "grad_norm": 0.470876309108362,
      "learning_rate": 4.320202959289067e-05,
      "loss": 2.1245,
      "step": 658
    },
    {
      "epoch": 0.2636,
      "grad_norm": 0.44380053942845193,
      "learning_rate": 4.3179812951315235e-05,
      "loss": 2.1899,
      "step": 659
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.4756837447137437,
      "learning_rate": 4.3157565798095753e-05,
      "loss": 2.2632,
      "step": 660
    },
    {
      "epoch": 0.2644,
      "grad_norm": 0.4503235030133973,
      "learning_rate": 4.3135288170570176e-05,
      "loss": 2.187,
      "step": 661
    },
    {
      "epoch": 0.2648,
      "grad_norm": 0.46493244708352516,
      "learning_rate": 4.311298010612762e-05,
      "loss": 2.1519,
      "step": 662
    },
    {
      "epoch": 0.2652,
      "grad_norm": 0.447453110483967,
      "learning_rate": 4.3090641642208274e-05,
      "loss": 2.1987,
      "step": 663
    },
    {
      "epoch": 0.2656,
      "grad_norm": 0.4664091563987541,
      "learning_rate": 4.306827281630337e-05,
      "loss": 2.2285,
      "step": 664
    },
    {
      "epoch": 0.266,
      "grad_norm": 0.4576065049563734,
      "learning_rate": 4.304587366595506e-05,
      "loss": 2.1904,
      "step": 665
    },
    {
      "epoch": 0.2664,
      "grad_norm": 0.4676909876548512,
      "learning_rate": 4.302344422875641e-05,
      "loss": 2.1816,
      "step": 666
    },
    {
      "epoch": 0.2668,
      "grad_norm": 0.44202598127577064,
      "learning_rate": 4.300098454235133e-05,
      "loss": 2.1357,
      "step": 667
    },
    {
      "epoch": 0.2672,
      "grad_norm": 0.45987726314610394,
      "learning_rate": 4.297849464443447e-05,
      "loss": 2.2627,
      "step": 668
    },
    {
      "epoch": 0.2676,
      "grad_norm": 0.46871656154049807,
      "learning_rate": 4.295597457275121e-05,
      "loss": 2.1382,
      "step": 669
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.42715761199645946,
      "learning_rate": 4.2933424365097564e-05,
      "loss": 2.1094,
      "step": 670
    },
    {
      "epoch": 0.2684,
      "grad_norm": 0.4594748534196209,
      "learning_rate": 4.291084405932011e-05,
      "loss": 2.1426,
      "step": 671
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.5011240925594447,
      "learning_rate": 4.288823369331596e-05,
      "loss": 2.2891,
      "step": 672
    },
    {
      "epoch": 0.2692,
      "grad_norm": 0.4463965351623485,
      "learning_rate": 4.286559330503267e-05,
      "loss": 2.1577,
      "step": 673
    },
    {
      "epoch": 0.2696,
      "grad_norm": 0.47377226408328993,
      "learning_rate": 4.284292293246817e-05,
      "loss": 2.1953,
      "step": 674
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5045800377710983,
      "learning_rate": 4.2820222613670736e-05,
      "loss": 2.2778,
      "step": 675
    },
    {
      "epoch": 0.2704,
      "grad_norm": 0.4307766941173899,
      "learning_rate": 4.279749238673888e-05,
      "loss": 2.1104,
      "step": 676
    },
    {
      "epoch": 0.2708,
      "grad_norm": 0.4933804227268604,
      "learning_rate": 4.277473228982134e-05,
      "loss": 2.1387,
      "step": 677
    },
    {
      "epoch": 0.2712,
      "grad_norm": 0.47127506934089725,
      "learning_rate": 4.2751942361116954e-05,
      "loss": 2.1704,
      "step": 678
    },
    {
      "epoch": 0.2716,
      "grad_norm": 0.4385917382990667,
      "learning_rate": 4.272912263887464e-05,
      "loss": 2.1396,
      "step": 679
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.4558457957852068,
      "learning_rate": 4.2706273161393327e-05,
      "loss": 2.1943,
      "step": 680
    },
    {
      "epoch": 0.2724,
      "grad_norm": 0.4635639988869548,
      "learning_rate": 4.268339396702188e-05,
      "loss": 2.1914,
      "step": 681
    },
    {
      "epoch": 0.2728,
      "grad_norm": 0.4589074332098471,
      "learning_rate": 4.266048509415902e-05,
      "loss": 2.2095,
      "step": 682
    },
    {
      "epoch": 0.2732,
      "grad_norm": 0.4399676740230348,
      "learning_rate": 4.263754658125331e-05,
      "loss": 2.147,
      "step": 683
    },
    {
      "epoch": 0.2736,
      "grad_norm": 0.4470638752902806,
      "learning_rate": 4.261457846680303e-05,
      "loss": 2.2173,
      "step": 684
    },
    {
      "epoch": 0.274,
      "grad_norm": 0.45012177193960823,
      "learning_rate": 4.2591580789356156e-05,
      "loss": 2.2021,
      "step": 685
    },
    {
      "epoch": 0.2744,
      "grad_norm": 0.4538482587264077,
      "learning_rate": 4.256855358751028e-05,
      "loss": 2.1377,
      "step": 686
    },
    {
      "epoch": 0.2748,
      "grad_norm": 0.4685442715305834,
      "learning_rate": 4.254549689991254e-05,
      "loss": 2.189,
      "step": 687
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.43024244813725676,
      "learning_rate": 4.252241076525956e-05,
      "loss": 2.1528,
      "step": 688
    },
    {
      "epoch": 0.2756,
      "grad_norm": 0.45385721051373223,
      "learning_rate": 4.249929522229739e-05,
      "loss": 2.0933,
      "step": 689
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.4239076362958694,
      "learning_rate": 4.247615030982144e-05,
      "loss": 2.1504,
      "step": 690
    },
    {
      "epoch": 0.2764,
      "grad_norm": 0.4833194484428807,
      "learning_rate": 4.24529760666764e-05,
      "loss": 2.2129,
      "step": 691
    },
    {
      "epoch": 0.2768,
      "grad_norm": 0.4385618406167918,
      "learning_rate": 4.242977253175621e-05,
      "loss": 2.1792,
      "step": 692
    },
    {
      "epoch": 0.2772,
      "grad_norm": 0.44827979789219163,
      "learning_rate": 4.2406539744003933e-05,
      "loss": 2.2612,
      "step": 693
    },
    {
      "epoch": 0.2776,
      "grad_norm": 0.4376079952759063,
      "learning_rate": 4.238327774241176e-05,
      "loss": 2.1211,
      "step": 694
    },
    {
      "epoch": 0.278,
      "grad_norm": 0.46460524136892817,
      "learning_rate": 4.2359986566020906e-05,
      "loss": 2.2925,
      "step": 695
    },
    {
      "epoch": 0.2784,
      "grad_norm": 0.4415700427384649,
      "learning_rate": 4.233666625392154e-05,
      "loss": 2.1274,
      "step": 696
    },
    {
      "epoch": 0.2788,
      "grad_norm": 0.4526743723118714,
      "learning_rate": 4.2313316845252746e-05,
      "loss": 2.0938,
      "step": 697
    },
    {
      "epoch": 0.2792,
      "grad_norm": 0.4522159940178125,
      "learning_rate": 4.228993837920242e-05,
      "loss": 2.3066,
      "step": 698
    },
    {
      "epoch": 0.2796,
      "grad_norm": 0.44767245363787966,
      "learning_rate": 4.226653089500725e-05,
      "loss": 2.2056,
      "step": 699
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.44927336777463756,
      "learning_rate": 4.224309443195261e-05,
      "loss": 2.1606,
      "step": 700
    },
    {
      "epoch": 0.2804,
      "grad_norm": 0.44503674506014845,
      "learning_rate": 4.221962902937251e-05,
      "loss": 2.2837,
      "step": 701
    },
    {
      "epoch": 0.2808,
      "grad_norm": 0.42754667047025957,
      "learning_rate": 4.2196134726649535e-05,
      "loss": 2.167,
      "step": 702
    },
    {
      "epoch": 0.2812,
      "grad_norm": 0.4310897228356244,
      "learning_rate": 4.217261156321477e-05,
      "loss": 2.186,
      "step": 703
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.45288148093683767,
      "learning_rate": 4.214905957854775e-05,
      "loss": 2.2925,
      "step": 704
    },
    {
      "epoch": 0.282,
      "grad_norm": 0.4591642203306714,
      "learning_rate": 4.2125478812176364e-05,
      "loss": 2.2173,
      "step": 705
    },
    {
      "epoch": 0.2824,
      "grad_norm": 0.43882892637852683,
      "learning_rate": 4.210186930367683e-05,
      "loss": 2.1626,
      "step": 706
    },
    {
      "epoch": 0.2828,
      "grad_norm": 0.44303783575090305,
      "learning_rate": 4.207823109267357e-05,
      "loss": 2.1729,
      "step": 707
    },
    {
      "epoch": 0.2832,
      "grad_norm": 0.4799249458095984,
      "learning_rate": 4.2054564218839185e-05,
      "loss": 2.1567,
      "step": 708
    },
    {
      "epoch": 0.2836,
      "grad_norm": 0.4547494596064379,
      "learning_rate": 4.203086872189443e-05,
      "loss": 2.2197,
      "step": 709
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.4609122737869018,
      "learning_rate": 4.200714464160804e-05,
      "loss": 2.1914,
      "step": 710
    },
    {
      "epoch": 0.2844,
      "grad_norm": 0.468140549001551,
      "learning_rate": 4.198339201779674e-05,
      "loss": 2.1255,
      "step": 711
    },
    {
      "epoch": 0.2848,
      "grad_norm": 0.46851395897504344,
      "learning_rate": 4.195961089032518e-05,
      "loss": 2.2202,
      "step": 712
    },
    {
      "epoch": 0.2852,
      "grad_norm": 0.4711280365524286,
      "learning_rate": 4.193580129910583e-05,
      "loss": 2.2085,
      "step": 713
    },
    {
      "epoch": 0.2856,
      "grad_norm": 0.5057362787907342,
      "learning_rate": 4.191196328409892e-05,
      "loss": 2.1958,
      "step": 714
    },
    {
      "epoch": 0.286,
      "grad_norm": 0.5064983846781806,
      "learning_rate": 4.188809688531241e-05,
      "loss": 2.105,
      "step": 715
    },
    {
      "epoch": 0.2864,
      "grad_norm": 0.5141693752749926,
      "learning_rate": 4.186420214280189e-05,
      "loss": 2.1406,
      "step": 716
    },
    {
      "epoch": 0.2868,
      "grad_norm": 0.4843202168537253,
      "learning_rate": 4.184027909667051e-05,
      "loss": 2.1157,
      "step": 717
    },
    {
      "epoch": 0.2872,
      "grad_norm": 0.46175584692216465,
      "learning_rate": 4.181632778706893e-05,
      "loss": 2.2153,
      "step": 718
    },
    {
      "epoch": 0.2876,
      "grad_norm": 0.52187914226504,
      "learning_rate": 4.1792348254195246e-05,
      "loss": 2.1367,
      "step": 719
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.49846544535535753,
      "learning_rate": 4.176834053829492e-05,
      "loss": 2.2471,
      "step": 720
    },
    {
      "epoch": 0.2884,
      "grad_norm": 0.43301219348696124,
      "learning_rate": 4.174430467966071e-05,
      "loss": 2.1875,
      "step": 721
    },
    {
      "epoch": 0.2888,
      "grad_norm": 0.4790337300179208,
      "learning_rate": 4.1720240718632616e-05,
      "loss": 2.2212,
      "step": 722
    },
    {
      "epoch": 0.2892,
      "grad_norm": 0.46860534289655886,
      "learning_rate": 4.1696148695597795e-05,
      "loss": 2.2334,
      "step": 723
    },
    {
      "epoch": 0.2896,
      "grad_norm": 0.48506439629739395,
      "learning_rate": 4.1672028650990506e-05,
      "loss": 2.2476,
      "step": 724
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.46603996442879925,
      "learning_rate": 4.164788062529203e-05,
      "loss": 2.1421,
      "step": 725
    },
    {
      "epoch": 0.2904,
      "grad_norm": 0.4962735403527294,
      "learning_rate": 4.162370465903062e-05,
      "loss": 2.1982,
      "step": 726
    },
    {
      "epoch": 0.2908,
      "grad_norm": 0.45764951993713804,
      "learning_rate": 4.159950079278142e-05,
      "loss": 2.1201,
      "step": 727
    },
    {
      "epoch": 0.2912,
      "grad_norm": 0.41903333939877424,
      "learning_rate": 4.1575269067166396e-05,
      "loss": 2.083,
      "step": 728
    },
    {
      "epoch": 0.2916,
      "grad_norm": 0.483794355641455,
      "learning_rate": 4.155100952285426e-05,
      "loss": 2.1938,
      "step": 729
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.4275669911747238,
      "learning_rate": 4.1526722200560445e-05,
      "loss": 2.1025,
      "step": 730
    },
    {
      "epoch": 0.2924,
      "grad_norm": 0.43485033600757866,
      "learning_rate": 4.1502407141046954e-05,
      "loss": 2.165,
      "step": 731
    },
    {
      "epoch": 0.2928,
      "grad_norm": 0.4739060868819183,
      "learning_rate": 4.147806438512241e-05,
      "loss": 2.186,
      "step": 732
    },
    {
      "epoch": 0.2932,
      "grad_norm": 0.46721192531412686,
      "learning_rate": 4.1453693973641835e-05,
      "loss": 2.2241,
      "step": 733
    },
    {
      "epoch": 0.2936,
      "grad_norm": 0.4682138248381565,
      "learning_rate": 4.142929594750676e-05,
      "loss": 2.2573,
      "step": 734
    },
    {
      "epoch": 0.294,
      "grad_norm": 0.4731841053738272,
      "learning_rate": 4.140487034766499e-05,
      "loss": 2.167,
      "step": 735
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.46456879329335693,
      "learning_rate": 4.138041721511063e-05,
      "loss": 2.1431,
      "step": 736
    },
    {
      "epoch": 0.2948,
      "grad_norm": 0.470108640376089,
      "learning_rate": 4.135593659088401e-05,
      "loss": 2.168,
      "step": 737
    },
    {
      "epoch": 0.2952,
      "grad_norm": 0.4951528230366094,
      "learning_rate": 4.133142851607157e-05,
      "loss": 2.2124,
      "step": 738
    },
    {
      "epoch": 0.2956,
      "grad_norm": 0.4486824578207766,
      "learning_rate": 4.130689303180586e-05,
      "loss": 2.2251,
      "step": 739
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.48974886481212665,
      "learning_rate": 4.128233017926538e-05,
      "loss": 2.1396,
      "step": 740
    },
    {
      "epoch": 0.2964,
      "grad_norm": 0.449783166761813,
      "learning_rate": 4.125773999967462e-05,
      "loss": 2.2783,
      "step": 741
    },
    {
      "epoch": 0.2968,
      "grad_norm": 0.5026362489933119,
      "learning_rate": 4.1233122534303894e-05,
      "loss": 2.1943,
      "step": 742
    },
    {
      "epoch": 0.2972,
      "grad_norm": 0.4647093383283684,
      "learning_rate": 4.120847782446932e-05,
      "loss": 2.1968,
      "step": 743
    },
    {
      "epoch": 0.2976,
      "grad_norm": 0.4668378593442844,
      "learning_rate": 4.118380591153275e-05,
      "loss": 2.1836,
      "step": 744
    },
    {
      "epoch": 0.298,
      "grad_norm": 0.4508778533130206,
      "learning_rate": 4.1159106836901674e-05,
      "loss": 2.2075,
      "step": 745
    },
    {
      "epoch": 0.2984,
      "grad_norm": 0.46676860613790694,
      "learning_rate": 4.1134380642029184e-05,
      "loss": 2.2397,
      "step": 746
    },
    {
      "epoch": 0.2988,
      "grad_norm": 0.4362960008365409,
      "learning_rate": 4.1109627368413895e-05,
      "loss": 2.1128,
      "step": 747
    },
    {
      "epoch": 0.2992,
      "grad_norm": 0.46202581840683926,
      "learning_rate": 4.108484705759985e-05,
      "loss": 2.1226,
      "step": 748
    },
    {
      "epoch": 0.2996,
      "grad_norm": 0.4586394216342396,
      "learning_rate": 4.106003975117647e-05,
      "loss": 2.2305,
      "step": 749
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4232228567272685,
      "learning_rate": 4.10352054907785e-05,
      "loss": 2.1675,
      "step": 750
    },
    {
      "epoch": 0.3004,
      "grad_norm": 0.44137818077919744,
      "learning_rate": 4.101034431808591e-05,
      "loss": 2.2002,
      "step": 751
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.4426441211946204,
      "learning_rate": 4.098545627482384e-05,
      "loss": 2.2026,
      "step": 752
    },
    {
      "epoch": 0.3012,
      "grad_norm": 0.4531246391343243,
      "learning_rate": 4.0960541402762534e-05,
      "loss": 2.0845,
      "step": 753
    },
    {
      "epoch": 0.3016,
      "grad_norm": 0.414231202000759,
      "learning_rate": 4.093559974371725e-05,
      "loss": 2.1733,
      "step": 754
    },
    {
      "epoch": 0.302,
      "grad_norm": 0.47664440546827835,
      "learning_rate": 4.0910631339548206e-05,
      "loss": 2.1455,
      "step": 755
    },
    {
      "epoch": 0.3024,
      "grad_norm": 0.4533260778685991,
      "learning_rate": 4.088563623216053e-05,
      "loss": 2.2017,
      "step": 756
    },
    {
      "epoch": 0.3028,
      "grad_norm": 0.46871108878809015,
      "learning_rate": 4.086061446350413e-05,
      "loss": 2.186,
      "step": 757
    },
    {
      "epoch": 0.3032,
      "grad_norm": 0.42157445700275187,
      "learning_rate": 4.083556607557369e-05,
      "loss": 2.1611,
      "step": 758
    },
    {
      "epoch": 0.3036,
      "grad_norm": 0.4601377677509986,
      "learning_rate": 4.0810491110408556e-05,
      "loss": 2.2822,
      "step": 759
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.45465010148387663,
      "learning_rate": 4.0785389610092686e-05,
      "loss": 2.2559,
      "step": 760
    },
    {
      "epoch": 0.3044,
      "grad_norm": 0.4316607046739964,
      "learning_rate": 4.076026161675455e-05,
      "loss": 2.2129,
      "step": 761
    },
    {
      "epoch": 0.3048,
      "grad_norm": 0.4443139009198503,
      "learning_rate": 4.073510717256713e-05,
      "loss": 2.2671,
      "step": 762
    },
    {
      "epoch": 0.3052,
      "grad_norm": 0.42800685557126944,
      "learning_rate": 4.070992631974775e-05,
      "loss": 2.0986,
      "step": 763
    },
    {
      "epoch": 0.3056,
      "grad_norm": 0.44592015382353417,
      "learning_rate": 4.068471910055808e-05,
      "loss": 2.1201,
      "step": 764
    },
    {
      "epoch": 0.306,
      "grad_norm": 0.4435152551747722,
      "learning_rate": 4.065948555730405e-05,
      "loss": 2.271,
      "step": 765
    },
    {
      "epoch": 0.3064,
      "grad_norm": 0.4252159738513661,
      "learning_rate": 4.063422573233575e-05,
      "loss": 2.1147,
      "step": 766
    },
    {
      "epoch": 0.3068,
      "grad_norm": 0.44000695403901635,
      "learning_rate": 4.0608939668047394e-05,
      "loss": 2.1553,
      "step": 767
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.45636648249745976,
      "learning_rate": 4.058362740687723e-05,
      "loss": 2.1426,
      "step": 768
    },
    {
      "epoch": 0.3076,
      "grad_norm": 0.42588843793400205,
      "learning_rate": 4.055828899130747e-05,
      "loss": 2.1602,
      "step": 769
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.4490081219637004,
      "learning_rate": 4.053292446386422e-05,
      "loss": 2.2124,
      "step": 770
    },
    {
      "epoch": 0.3084,
      "grad_norm": 0.46952826034049344,
      "learning_rate": 4.0507533867117415e-05,
      "loss": 2.1646,
      "step": 771
    },
    {
      "epoch": 0.3088,
      "grad_norm": 0.4445602812817699,
      "learning_rate": 4.048211724368074e-05,
      "loss": 2.2144,
      "step": 772
    },
    {
      "epoch": 0.3092,
      "grad_norm": 0.44491683078987526,
      "learning_rate": 4.0456674636211574e-05,
      "loss": 2.0791,
      "step": 773
    },
    {
      "epoch": 0.3096,
      "grad_norm": 0.44691312216962087,
      "learning_rate": 4.043120608741088e-05,
      "loss": 2.2339,
      "step": 774
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4661335752615377,
      "learning_rate": 4.0405711640023186e-05,
      "loss": 2.2002,
      "step": 775
    },
    {
      "epoch": 0.3104,
      "grad_norm": 0.45386524693258723,
      "learning_rate": 4.038019133683646e-05,
      "loss": 2.2349,
      "step": 776
    },
    {
      "epoch": 0.3108,
      "grad_norm": 0.44746997604979116,
      "learning_rate": 4.035464522068209e-05,
      "loss": 2.1021,
      "step": 777
    },
    {
      "epoch": 0.3112,
      "grad_norm": 0.43356211776825554,
      "learning_rate": 4.032907333443477e-05,
      "loss": 2.1704,
      "step": 778
    },
    {
      "epoch": 0.3116,
      "grad_norm": 0.4506857415007297,
      "learning_rate": 4.030347572101245e-05,
      "loss": 2.2373,
      "step": 779
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.45827554191506265,
      "learning_rate": 4.027785242337626e-05,
      "loss": 2.1851,
      "step": 780
    },
    {
      "epoch": 0.3124,
      "grad_norm": 0.45515571845901087,
      "learning_rate": 4.025220348453043e-05,
      "loss": 2.2368,
      "step": 781
    },
    {
      "epoch": 0.3128,
      "grad_norm": 0.42404562526654604,
      "learning_rate": 4.022652894752222e-05,
      "loss": 2.1631,
      "step": 782
    },
    {
      "epoch": 0.3132,
      "grad_norm": 0.4452289370546631,
      "learning_rate": 4.0200828855441883e-05,
      "loss": 2.1426,
      "step": 783
    },
    {
      "epoch": 0.3136,
      "grad_norm": 0.43912091982099355,
      "learning_rate": 4.017510325142253e-05,
      "loss": 2.1934,
      "step": 784
    },
    {
      "epoch": 0.314,
      "grad_norm": 0.4293535780568919,
      "learning_rate": 4.014935217864009e-05,
      "loss": 2.1777,
      "step": 785
    },
    {
      "epoch": 0.3144,
      "grad_norm": 0.4523373971410891,
      "learning_rate": 4.012357568031325e-05,
      "loss": 2.1143,
      "step": 786
    },
    {
      "epoch": 0.3148,
      "grad_norm": 0.42617497687206596,
      "learning_rate": 4.0097773799703376e-05,
      "loss": 2.1768,
      "step": 787
    },
    {
      "epoch": 0.3152,
      "grad_norm": 0.4313478351944166,
      "learning_rate": 4.0071946580114404e-05,
      "loss": 2.1802,
      "step": 788
    },
    {
      "epoch": 0.3156,
      "grad_norm": 0.445698655405654,
      "learning_rate": 4.0046094064892834e-05,
      "loss": 2.082,
      "step": 789
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.43451466342637596,
      "learning_rate": 4.0020216297427594e-05,
      "loss": 2.2051,
      "step": 790
    },
    {
      "epoch": 0.3164,
      "grad_norm": 0.47857869134718584,
      "learning_rate": 3.999431332115e-05,
      "loss": 2.2812,
      "step": 791
    },
    {
      "epoch": 0.3168,
      "grad_norm": 0.47076236797414456,
      "learning_rate": 3.9968385179533675e-05,
      "loss": 2.1929,
      "step": 792
    },
    {
      "epoch": 0.3172,
      "grad_norm": 0.48274815160770346,
      "learning_rate": 3.994243191609449e-05,
      "loss": 2.0884,
      "step": 793
    },
    {
      "epoch": 0.3176,
      "grad_norm": 0.4695509210904078,
      "learning_rate": 3.991645357439046e-05,
      "loss": 2.1567,
      "step": 794
    },
    {
      "epoch": 0.318,
      "grad_norm": 0.46002179401056026,
      "learning_rate": 3.9890450198021704e-05,
      "loss": 2.1558,
      "step": 795
    },
    {
      "epoch": 0.3184,
      "grad_norm": 0.4544689632220838,
      "learning_rate": 3.986442183063036e-05,
      "loss": 2.1904,
      "step": 796
    },
    {
      "epoch": 0.3188,
      "grad_norm": 0.4833639989419307,
      "learning_rate": 3.983836851590048e-05,
      "loss": 2.1606,
      "step": 797
    },
    {
      "epoch": 0.3192,
      "grad_norm": 0.4516729286272424,
      "learning_rate": 3.981229029755803e-05,
      "loss": 2.1255,
      "step": 798
    },
    {
      "epoch": 0.3196,
      "grad_norm": 0.46252128242393237,
      "learning_rate": 3.978618721937074e-05,
      "loss": 2.2202,
      "step": 799
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4568652928667891,
      "learning_rate": 3.976005932514807e-05,
      "loss": 2.1748,
      "step": 800
    },
    {
      "epoch": 0.3204,
      "grad_norm": 0.4297322150515376,
      "learning_rate": 3.973390665874113e-05,
      "loss": 2.1865,
      "step": 801
    },
    {
      "epoch": 0.3208,
      "grad_norm": 0.4348731685687448,
      "learning_rate": 3.970772926404261e-05,
      "loss": 2.1572,
      "step": 802
    },
    {
      "epoch": 0.3212,
      "grad_norm": 0.4507266124267978,
      "learning_rate": 3.9681527184986714e-05,
      "loss": 2.1714,
      "step": 803
    },
    {
      "epoch": 0.3216,
      "grad_norm": 0.4555462355444057,
      "learning_rate": 3.965530046554903e-05,
      "loss": 2.1333,
      "step": 804
    },
    {
      "epoch": 0.322,
      "grad_norm": 0.45521404799573567,
      "learning_rate": 3.962904914974656e-05,
      "loss": 2.2021,
      "step": 805
    },
    {
      "epoch": 0.3224,
      "grad_norm": 0.44290305190432794,
      "learning_rate": 3.960277328163754e-05,
      "loss": 2.1621,
      "step": 806
    },
    {
      "epoch": 0.3228,
      "grad_norm": 0.42694984192436686,
      "learning_rate": 3.957647290532143e-05,
      "loss": 2.1133,
      "step": 807
    },
    {
      "epoch": 0.3232,
      "grad_norm": 0.44824986212050594,
      "learning_rate": 3.955014806493883e-05,
      "loss": 2.1831,
      "step": 808
    },
    {
      "epoch": 0.3236,
      "grad_norm": 0.44917796524008063,
      "learning_rate": 3.95237988046714e-05,
      "loss": 2.2368,
      "step": 809
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.4400575596369513,
      "learning_rate": 3.949742516874175e-05,
      "loss": 2.1123,
      "step": 810
    },
    {
      "epoch": 0.3244,
      "grad_norm": 0.42574581778920595,
      "learning_rate": 3.9471027201413446e-05,
      "loss": 2.0801,
      "step": 811
    },
    {
      "epoch": 0.3248,
      "grad_norm": 0.4469296544685048,
      "learning_rate": 3.944460494699087e-05,
      "loss": 2.0508,
      "step": 812
    },
    {
      "epoch": 0.3252,
      "grad_norm": 0.4676741866043109,
      "learning_rate": 3.941815844981915e-05,
      "loss": 2.2427,
      "step": 813
    },
    {
      "epoch": 0.3256,
      "grad_norm": 0.4367935484388271,
      "learning_rate": 3.939168775428414e-05,
      "loss": 2.1685,
      "step": 814
    },
    {
      "epoch": 0.326,
      "grad_norm": 0.47132979223960875,
      "learning_rate": 3.936519290481226e-05,
      "loss": 2.1758,
      "step": 815
    },
    {
      "epoch": 0.3264,
      "grad_norm": 0.46741589597572425,
      "learning_rate": 3.933867394587052e-05,
      "loss": 2.1221,
      "step": 816
    },
    {
      "epoch": 0.3268,
      "grad_norm": 0.4396414611024639,
      "learning_rate": 3.931213092196634e-05,
      "loss": 2.1602,
      "step": 817
    },
    {
      "epoch": 0.3272,
      "grad_norm": 0.4844536703378973,
      "learning_rate": 3.928556387764757e-05,
      "loss": 2.1689,
      "step": 818
    },
    {
      "epoch": 0.3276,
      "grad_norm": 0.49380281721085495,
      "learning_rate": 3.925897285750235e-05,
      "loss": 2.2871,
      "step": 819
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.46750745779627595,
      "learning_rate": 3.923235790615907e-05,
      "loss": 2.1348,
      "step": 820
    },
    {
      "epoch": 0.3284,
      "grad_norm": 0.5157590937130492,
      "learning_rate": 3.920571906828629e-05,
      "loss": 2.1895,
      "step": 821
    },
    {
      "epoch": 0.3288,
      "grad_norm": 0.43381232081386933,
      "learning_rate": 3.917905638859263e-05,
      "loss": 2.1074,
      "step": 822
    },
    {
      "epoch": 0.3292,
      "grad_norm": 0.5385275360897169,
      "learning_rate": 3.915236991182677e-05,
      "loss": 2.231,
      "step": 823
    },
    {
      "epoch": 0.3296,
      "grad_norm": 0.4371117762990444,
      "learning_rate": 3.91256596827773e-05,
      "loss": 2.1875,
      "step": 824
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5108856137463136,
      "learning_rate": 3.909892574627266e-05,
      "loss": 2.1782,
      "step": 825
    },
    {
      "epoch": 0.3304,
      "grad_norm": 0.4584949507101933,
      "learning_rate": 3.9072168147181123e-05,
      "loss": 2.1523,
      "step": 826
    },
    {
      "epoch": 0.3308,
      "grad_norm": 0.4711301402686328,
      "learning_rate": 3.904538693041064e-05,
      "loss": 2.2158,
      "step": 827
    },
    {
      "epoch": 0.3312,
      "grad_norm": 0.5009757981296301,
      "learning_rate": 3.901858214090881e-05,
      "loss": 2.1914,
      "step": 828
    },
    {
      "epoch": 0.3316,
      "grad_norm": 0.4508416986968978,
      "learning_rate": 3.899175382366279e-05,
      "loss": 2.2158,
      "step": 829
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.5396367090018948,
      "learning_rate": 3.896490202369924e-05,
      "loss": 2.2861,
      "step": 830
    },
    {
      "epoch": 0.3324,
      "grad_norm": 0.4450752438349557,
      "learning_rate": 3.8938026786084214e-05,
      "loss": 2.104,
      "step": 831
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.4379653931992061,
      "learning_rate": 3.8911128155923117e-05,
      "loss": 2.1313,
      "step": 832
    },
    {
      "epoch": 0.3332,
      "grad_norm": 0.46634829111318354,
      "learning_rate": 3.8884206178360594e-05,
      "loss": 2.1797,
      "step": 833
    },
    {
      "epoch": 0.3336,
      "grad_norm": 0.4429569921339247,
      "learning_rate": 3.8857260898580495e-05,
      "loss": 2.1543,
      "step": 834
    },
    {
      "epoch": 0.334,
      "grad_norm": 0.436374135657306,
      "learning_rate": 3.883029236180577e-05,
      "loss": 2.1768,
      "step": 835
    },
    {
      "epoch": 0.3344,
      "grad_norm": 0.4436706186430138,
      "learning_rate": 3.880330061329841e-05,
      "loss": 2.1421,
      "step": 836
    },
    {
      "epoch": 0.3348,
      "grad_norm": 0.4890641664819289,
      "learning_rate": 3.8776285698359335e-05,
      "loss": 2.2173,
      "step": 837
    },
    {
      "epoch": 0.3352,
      "grad_norm": 0.43530089324723886,
      "learning_rate": 3.874924766232839e-05,
      "loss": 2.1519,
      "step": 838
    },
    {
      "epoch": 0.3356,
      "grad_norm": 0.502363493520274,
      "learning_rate": 3.8722186550584184e-05,
      "loss": 2.2256,
      "step": 839
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.4298600402628505,
      "learning_rate": 3.8695102408544076e-05,
      "loss": 2.2148,
      "step": 840
    },
    {
      "epoch": 0.3364,
      "grad_norm": 0.45236821107328135,
      "learning_rate": 3.866799528166408e-05,
      "loss": 2.1919,
      "step": 841
    },
    {
      "epoch": 0.3368,
      "grad_norm": 0.4663245151384384,
      "learning_rate": 3.8640865215438773e-05,
      "loss": 2.2188,
      "step": 842
    },
    {
      "epoch": 0.3372,
      "grad_norm": 0.4346667705407006,
      "learning_rate": 3.861371225540123e-05,
      "loss": 2.1514,
      "step": 843
    },
    {
      "epoch": 0.3376,
      "grad_norm": 0.42533990755956685,
      "learning_rate": 3.858653644712297e-05,
      "loss": 2.2007,
      "step": 844
    },
    {
      "epoch": 0.338,
      "grad_norm": 0.4422970101255647,
      "learning_rate": 3.855933783621384e-05,
      "loss": 2.1265,
      "step": 845
    },
    {
      "epoch": 0.3384,
      "grad_norm": 0.47621875136683023,
      "learning_rate": 3.8532116468321955e-05,
      "loss": 2.25,
      "step": 846
    },
    {
      "epoch": 0.3388,
      "grad_norm": 0.44671053458166565,
      "learning_rate": 3.850487238913365e-05,
      "loss": 2.1919,
      "step": 847
    },
    {
      "epoch": 0.3392,
      "grad_norm": 0.4747132117174886,
      "learning_rate": 3.847760564437334e-05,
      "loss": 2.2681,
      "step": 848
    },
    {
      "epoch": 0.3396,
      "grad_norm": 0.4257522015469235,
      "learning_rate": 3.845031627980351e-05,
      "loss": 2.1929,
      "step": 849
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.4544972589828486,
      "learning_rate": 3.84230043412246e-05,
      "loss": 2.187,
      "step": 850
    },
    {
      "epoch": 0.3404,
      "grad_norm": 0.44043138551070515,
      "learning_rate": 3.8395669874474915e-05,
      "loss": 2.1211,
      "step": 851
    },
    {
      "epoch": 0.3408,
      "grad_norm": 0.4554867231013678,
      "learning_rate": 3.836831292543061e-05,
      "loss": 2.1875,
      "step": 852
    },
    {
      "epoch": 0.3412,
      "grad_norm": 0.4802296311760391,
      "learning_rate": 3.834093354000553e-05,
      "loss": 2.2852,
      "step": 853
    },
    {
      "epoch": 0.3416,
      "grad_norm": 0.42172794656792467,
      "learning_rate": 3.8313531764151224e-05,
      "loss": 2.1924,
      "step": 854
    },
    {
      "epoch": 0.342,
      "grad_norm": 0.47140754228827986,
      "learning_rate": 3.828610764385676e-05,
      "loss": 2.0952,
      "step": 855
    },
    {
      "epoch": 0.3424,
      "grad_norm": 0.45513853008233335,
      "learning_rate": 3.8258661225148764e-05,
      "loss": 2.2007,
      "step": 856
    },
    {
      "epoch": 0.3428,
      "grad_norm": 0.4611806750927705,
      "learning_rate": 3.823119255409124e-05,
      "loss": 2.251,
      "step": 857
    },
    {
      "epoch": 0.3432,
      "grad_norm": 0.4538085892594899,
      "learning_rate": 3.820370167678558e-05,
      "loss": 2.1875,
      "step": 858
    },
    {
      "epoch": 0.3436,
      "grad_norm": 0.4628730175516887,
      "learning_rate": 3.8176188639370416e-05,
      "loss": 2.1777,
      "step": 859
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.44300743511355456,
      "learning_rate": 3.814865348802157e-05,
      "loss": 2.1958,
      "step": 860
    },
    {
      "epoch": 0.3444,
      "grad_norm": 0.4211550630260064,
      "learning_rate": 3.8121096268952015e-05,
      "loss": 2.165,
      "step": 861
    },
    {
      "epoch": 0.3448,
      "grad_norm": 0.46612294971206647,
      "learning_rate": 3.8093517028411705e-05,
      "loss": 2.1172,
      "step": 862
    },
    {
      "epoch": 0.3452,
      "grad_norm": 0.4330035022464264,
      "learning_rate": 3.80659158126876e-05,
      "loss": 2.123,
      "step": 863
    },
    {
      "epoch": 0.3456,
      "grad_norm": 0.44299704073536667,
      "learning_rate": 3.8038292668103535e-05,
      "loss": 2.1299,
      "step": 864
    },
    {
      "epoch": 0.346,
      "grad_norm": 0.44898009169038805,
      "learning_rate": 3.8010647641020115e-05,
      "loss": 2.1343,
      "step": 865
    },
    {
      "epoch": 0.3464,
      "grad_norm": 0.43660863908470743,
      "learning_rate": 3.798298077783471e-05,
      "loss": 2.0405,
      "step": 866
    },
    {
      "epoch": 0.3468,
      "grad_norm": 0.44837465215407474,
      "learning_rate": 3.7955292124981314e-05,
      "loss": 2.1587,
      "step": 867
    },
    {
      "epoch": 0.3472,
      "grad_norm": 0.4696309146480994,
      "learning_rate": 3.7927581728930514e-05,
      "loss": 2.1821,
      "step": 868
    },
    {
      "epoch": 0.3476,
      "grad_norm": 0.4261698600139275,
      "learning_rate": 3.789984963618936e-05,
      "loss": 2.0752,
      "step": 869
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.4524396355693136,
      "learning_rate": 3.787209589330134e-05,
      "loss": 2.2549,
      "step": 870
    },
    {
      "epoch": 0.3484,
      "grad_norm": 0.4660569395707938,
      "learning_rate": 3.7844320546846254e-05,
      "loss": 2.2876,
      "step": 871
    },
    {
      "epoch": 0.3488,
      "grad_norm": 0.42937374347373036,
      "learning_rate": 3.78165236434402e-05,
      "loss": 2.1328,
      "step": 872
    },
    {
      "epoch": 0.3492,
      "grad_norm": 0.4557146505401778,
      "learning_rate": 3.778870522973541e-05,
      "loss": 2.165,
      "step": 873
    },
    {
      "epoch": 0.3496,
      "grad_norm": 0.4489991287361751,
      "learning_rate": 3.776086535242024e-05,
      "loss": 2.1304,
      "step": 874
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.42779213300082347,
      "learning_rate": 3.773300405821908e-05,
      "loss": 2.1509,
      "step": 875
    },
    {
      "epoch": 0.3504,
      "grad_norm": 0.41984073258895094,
      "learning_rate": 3.770512139389223e-05,
      "loss": 2.1606,
      "step": 876
    },
    {
      "epoch": 0.3508,
      "grad_norm": 0.4305478729341478,
      "learning_rate": 3.7677217406235896e-05,
      "loss": 2.1704,
      "step": 877
    },
    {
      "epoch": 0.3512,
      "grad_norm": 0.4206682301221564,
      "learning_rate": 3.764929214208205e-05,
      "loss": 2.1045,
      "step": 878
    },
    {
      "epoch": 0.3516,
      "grad_norm": 0.4170913740448133,
      "learning_rate": 3.7621345648298365e-05,
      "loss": 2.2266,
      "step": 879
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.44276279955973424,
      "learning_rate": 3.759337797178816e-05,
      "loss": 2.1519,
      "step": 880
    },
    {
      "epoch": 0.3524,
      "grad_norm": 0.4211244008437598,
      "learning_rate": 3.756538915949031e-05,
      "loss": 2.1797,
      "step": 881
    },
    {
      "epoch": 0.3528,
      "grad_norm": 0.4708262301604381,
      "learning_rate": 3.7537379258379134e-05,
      "loss": 2.2012,
      "step": 882
    },
    {
      "epoch": 0.3532,
      "grad_norm": 0.4622195132416617,
      "learning_rate": 3.750934831546438e-05,
      "loss": 2.2529,
      "step": 883
    },
    {
      "epoch": 0.3536,
      "grad_norm": 0.43339501722456525,
      "learning_rate": 3.7481296377791086e-05,
      "loss": 2.1758,
      "step": 884
    },
    {
      "epoch": 0.354,
      "grad_norm": 0.45115053027061014,
      "learning_rate": 3.745322349243954e-05,
      "loss": 2.1567,
      "step": 885
    },
    {
      "epoch": 0.3544,
      "grad_norm": 0.44800219096048094,
      "learning_rate": 3.742512970652518e-05,
      "loss": 2.2759,
      "step": 886
    },
    {
      "epoch": 0.3548,
      "grad_norm": 0.43329925145595544,
      "learning_rate": 3.739701506719853e-05,
      "loss": 2.1382,
      "step": 887
    },
    {
      "epoch": 0.3552,
      "grad_norm": 0.4336475690602521,
      "learning_rate": 3.7368879621645086e-05,
      "loss": 2.2021,
      "step": 888
    },
    {
      "epoch": 0.3556,
      "grad_norm": 0.4263836681384658,
      "learning_rate": 3.734072341708531e-05,
      "loss": 2.0469,
      "step": 889
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.4533182950557641,
      "learning_rate": 3.731254650077446e-05,
      "loss": 2.2051,
      "step": 890
    },
    {
      "epoch": 0.3564,
      "grad_norm": 0.4371056588967663,
      "learning_rate": 3.728434892000258e-05,
      "loss": 2.1426,
      "step": 891
    },
    {
      "epoch": 0.3568,
      "grad_norm": 0.4420006673429911,
      "learning_rate": 3.72561307220944e-05,
      "loss": 2.1836,
      "step": 892
    },
    {
      "epoch": 0.3572,
      "grad_norm": 0.45001501204801914,
      "learning_rate": 3.7227891954409225e-05,
      "loss": 2.1201,
      "step": 893
    },
    {
      "epoch": 0.3576,
      "grad_norm": 0.47395131072697283,
      "learning_rate": 3.719963266434091e-05,
      "loss": 2.2471,
      "step": 894
    },
    {
      "epoch": 0.358,
      "grad_norm": 0.42319836067703726,
      "learning_rate": 3.717135289931774e-05,
      "loss": 2.1523,
      "step": 895
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.4456436898043162,
      "learning_rate": 3.714305270680237e-05,
      "loss": 2.2095,
      "step": 896
    },
    {
      "epoch": 0.3588,
      "grad_norm": 0.4308796307196308,
      "learning_rate": 3.711473213429173e-05,
      "loss": 2.1064,
      "step": 897
    },
    {
      "epoch": 0.3592,
      "grad_norm": 0.43065015157267467,
      "learning_rate": 3.708639122931695e-05,
      "loss": 2.1919,
      "step": 898
    },
    {
      "epoch": 0.3596,
      "grad_norm": 0.4329829720356143,
      "learning_rate": 3.705803003944333e-05,
      "loss": 2.2119,
      "step": 899
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.42485959503252757,
      "learning_rate": 3.702964861227013e-05,
      "loss": 2.1484,
      "step": 900
    },
    {
      "epoch": 0.3604,
      "grad_norm": 0.4649052234776079,
      "learning_rate": 3.700124699543065e-05,
      "loss": 2.2075,
      "step": 901
    },
    {
      "epoch": 0.3608,
      "grad_norm": 0.42040967899436177,
      "learning_rate": 3.697282523659205e-05,
      "loss": 2.2021,
      "step": 902
    },
    {
      "epoch": 0.3612,
      "grad_norm": 0.4272024877971102,
      "learning_rate": 3.6944383383455297e-05,
      "loss": 2.2085,
      "step": 903
    },
    {
      "epoch": 0.3616,
      "grad_norm": 0.43202312704044016,
      "learning_rate": 3.6915921483755066e-05,
      "loss": 2.1675,
      "step": 904
    },
    {
      "epoch": 0.362,
      "grad_norm": 0.4252762580396489,
      "learning_rate": 3.6887439585259694e-05,
      "loss": 2.1641,
      "step": 905
    },
    {
      "epoch": 0.3624,
      "grad_norm": 0.4048744409308096,
      "learning_rate": 3.685893773577108e-05,
      "loss": 2.1519,
      "step": 906
    },
    {
      "epoch": 0.3628,
      "grad_norm": 0.43538064598063075,
      "learning_rate": 3.68304159831246e-05,
      "loss": 2.1338,
      "step": 907
    },
    {
      "epoch": 0.3632,
      "grad_norm": 0.44303803726103935,
      "learning_rate": 3.680187437518905e-05,
      "loss": 2.1011,
      "step": 908
    },
    {
      "epoch": 0.3636,
      "grad_norm": 0.43122751165029827,
      "learning_rate": 3.6773312959866527e-05,
      "loss": 2.2188,
      "step": 909
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.4309939053147153,
      "learning_rate": 3.6744731785092395e-05,
      "loss": 2.1938,
      "step": 910
    },
    {
      "epoch": 0.3644,
      "grad_norm": 0.43031283173382795,
      "learning_rate": 3.6716130898835166e-05,
      "loss": 2.1206,
      "step": 911
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.43826655893978456,
      "learning_rate": 3.668751034909643e-05,
      "loss": 2.1426,
      "step": 912
    },
    {
      "epoch": 0.3652,
      "grad_norm": 0.44881838013951697,
      "learning_rate": 3.665887018391079e-05,
      "loss": 2.2046,
      "step": 913
    },
    {
      "epoch": 0.3656,
      "grad_norm": 0.4296841013973707,
      "learning_rate": 3.6630210451345756e-05,
      "loss": 2.3125,
      "step": 914
    },
    {
      "epoch": 0.366,
      "grad_norm": 0.4506995202000244,
      "learning_rate": 3.6601531199501714e-05,
      "loss": 2.127,
      "step": 915
    },
    {
      "epoch": 0.3664,
      "grad_norm": 0.42281547633028355,
      "learning_rate": 3.6572832476511765e-05,
      "loss": 2.0522,
      "step": 916
    },
    {
      "epoch": 0.3668,
      "grad_norm": 0.4319120733584473,
      "learning_rate": 3.654411433054171e-05,
      "loss": 2.1216,
      "step": 917
    },
    {
      "epoch": 0.3672,
      "grad_norm": 0.4124908961682057,
      "learning_rate": 3.651537680978996e-05,
      "loss": 2.2114,
      "step": 918
    },
    {
      "epoch": 0.3676,
      "grad_norm": 0.4532282994400283,
      "learning_rate": 3.648661996248741e-05,
      "loss": 2.1152,
      "step": 919
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.45432398736353596,
      "learning_rate": 3.645784383689742e-05,
      "loss": 2.1738,
      "step": 920
    },
    {
      "epoch": 0.3684,
      "grad_norm": 0.4788316587602296,
      "learning_rate": 3.6429048481315696e-05,
      "loss": 2.2788,
      "step": 921
    },
    {
      "epoch": 0.3688,
      "grad_norm": 0.4613976710949293,
      "learning_rate": 3.640023394407022e-05,
      "loss": 2.1655,
      "step": 922
    },
    {
      "epoch": 0.3692,
      "grad_norm": 0.41680668844804697,
      "learning_rate": 3.6371400273521164e-05,
      "loss": 2.1201,
      "step": 923
    },
    {
      "epoch": 0.3696,
      "grad_norm": 0.47549049905648894,
      "learning_rate": 3.634254751806081e-05,
      "loss": 2.1929,
      "step": 924
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.42426831756046524,
      "learning_rate": 3.631367572611348e-05,
      "loss": 2.1465,
      "step": 925
    },
    {
      "epoch": 0.3704,
      "grad_norm": 0.4408148145671059,
      "learning_rate": 3.628478494613542e-05,
      "loss": 2.189,
      "step": 926
    },
    {
      "epoch": 0.3708,
      "grad_norm": 0.4484244525323381,
      "learning_rate": 3.625587522661479e-05,
      "loss": 2.1714,
      "step": 927
    },
    {
      "epoch": 0.3712,
      "grad_norm": 0.43973711566053825,
      "learning_rate": 3.62269466160715e-05,
      "loss": 2.1978,
      "step": 928
    },
    {
      "epoch": 0.3716,
      "grad_norm": 0.44927096327604754,
      "learning_rate": 3.6197999163057175e-05,
      "loss": 2.2607,
      "step": 929
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.40830144559541975,
      "learning_rate": 3.616903291615506e-05,
      "loss": 2.1562,
      "step": 930
    },
    {
      "epoch": 0.3724,
      "grad_norm": 0.4229525097324278,
      "learning_rate": 3.6140047923979946e-05,
      "loss": 2.1689,
      "step": 931
    },
    {
      "epoch": 0.3728,
      "grad_norm": 0.40767638598804734,
      "learning_rate": 3.61110442351781e-05,
      "loss": 2.0991,
      "step": 932
    },
    {
      "epoch": 0.3732,
      "grad_norm": 0.44019953963254627,
      "learning_rate": 3.6082021898427134e-05,
      "loss": 2.1655,
      "step": 933
    },
    {
      "epoch": 0.3736,
      "grad_norm": 0.4248804435220239,
      "learning_rate": 3.605298096243599e-05,
      "loss": 2.2534,
      "step": 934
    },
    {
      "epoch": 0.374,
      "grad_norm": 0.4251228598608976,
      "learning_rate": 3.6023921475944794e-05,
      "loss": 2.1465,
      "step": 935
    },
    {
      "epoch": 0.3744,
      "grad_norm": 0.42944841809791284,
      "learning_rate": 3.599484348772485e-05,
      "loss": 2.0898,
      "step": 936
    },
    {
      "epoch": 0.3748,
      "grad_norm": 0.4347991539468729,
      "learning_rate": 3.5965747046578466e-05,
      "loss": 2.2007,
      "step": 937
    },
    {
      "epoch": 0.3752,
      "grad_norm": 0.40947427658032554,
      "learning_rate": 3.593663220133895e-05,
      "loss": 2.0977,
      "step": 938
    },
    {
      "epoch": 0.3756,
      "grad_norm": 0.41422363592582845,
      "learning_rate": 3.590749900087049e-05,
      "loss": 2.1011,
      "step": 939
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.42092655773948967,
      "learning_rate": 3.5878347494068084e-05,
      "loss": 2.1543,
      "step": 940
    },
    {
      "epoch": 0.3764,
      "grad_norm": 0.4283103376293616,
      "learning_rate": 3.5849177729857444e-05,
      "loss": 2.1548,
      "step": 941
    },
    {
      "epoch": 0.3768,
      "grad_norm": 0.4261082990524803,
      "learning_rate": 3.581998975719493e-05,
      "loss": 2.0776,
      "step": 942
    },
    {
      "epoch": 0.3772,
      "grad_norm": 0.4175714825215807,
      "learning_rate": 3.5790783625067465e-05,
      "loss": 2.126,
      "step": 943
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.4600485152153453,
      "learning_rate": 3.576155938249243e-05,
      "loss": 2.2271,
      "step": 944
    },
    {
      "epoch": 0.378,
      "grad_norm": 0.43512242260441897,
      "learning_rate": 3.5732317078517654e-05,
      "loss": 2.2417,
      "step": 945
    },
    {
      "epoch": 0.3784,
      "grad_norm": 0.4319781413232757,
      "learning_rate": 3.57030567622212e-05,
      "loss": 2.1509,
      "step": 946
    },
    {
      "epoch": 0.3788,
      "grad_norm": 0.44845742025008906,
      "learning_rate": 3.567377848271143e-05,
      "loss": 2.2124,
      "step": 947
    },
    {
      "epoch": 0.3792,
      "grad_norm": 0.41627564554036034,
      "learning_rate": 3.564448228912682e-05,
      "loss": 2.1646,
      "step": 948
    },
    {
      "epoch": 0.3796,
      "grad_norm": 0.43339061651451594,
      "learning_rate": 3.5615168230635914e-05,
      "loss": 2.1978,
      "step": 949
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.43130119347226425,
      "learning_rate": 3.5585836356437264e-05,
      "loss": 2.1689,
      "step": 950
    },
    {
      "epoch": 0.3804,
      "grad_norm": 0.4035875666106807,
      "learning_rate": 3.5556486715759265e-05,
      "loss": 2.166,
      "step": 951
    },
    {
      "epoch": 0.3808,
      "grad_norm": 0.4376326439189013,
      "learning_rate": 3.552711935786022e-05,
      "loss": 2.1357,
      "step": 952
    },
    {
      "epoch": 0.3812,
      "grad_norm": 0.4257691923473762,
      "learning_rate": 3.549773433202806e-05,
      "loss": 2.1753,
      "step": 953
    },
    {
      "epoch": 0.3816,
      "grad_norm": 0.4098352032649892,
      "learning_rate": 3.546833168758047e-05,
      "loss": 2.1235,
      "step": 954
    },
    {
      "epoch": 0.382,
      "grad_norm": 0.41929132344096715,
      "learning_rate": 3.5438911473864634e-05,
      "loss": 2.1855,
      "step": 955
    },
    {
      "epoch": 0.3824,
      "grad_norm": 0.4240193410240484,
      "learning_rate": 3.5409473740257254e-05,
      "loss": 2.1812,
      "step": 956
    },
    {
      "epoch": 0.3828,
      "grad_norm": 0.4452999400344388,
      "learning_rate": 3.538001853616443e-05,
      "loss": 2.1572,
      "step": 957
    },
    {
      "epoch": 0.3832,
      "grad_norm": 0.41575077361722096,
      "learning_rate": 3.535054591102158e-05,
      "loss": 2.1494,
      "step": 958
    },
    {
      "epoch": 0.3836,
      "grad_norm": 0.4389919105054146,
      "learning_rate": 3.532105591429337e-05,
      "loss": 2.1709,
      "step": 959
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.44404291907430893,
      "learning_rate": 3.52915485954736e-05,
      "loss": 2.1582,
      "step": 960
    },
    {
      "epoch": 0.3844,
      "grad_norm": 0.42550747663350574,
      "learning_rate": 3.526202400408517e-05,
      "loss": 2.1938,
      "step": 961
    },
    {
      "epoch": 0.3848,
      "grad_norm": 0.4470578637690356,
      "learning_rate": 3.5232482189679946e-05,
      "loss": 2.1953,
      "step": 962
    },
    {
      "epoch": 0.3852,
      "grad_norm": 0.4359889999001888,
      "learning_rate": 3.520292320183872e-05,
      "loss": 2.1738,
      "step": 963
    },
    {
      "epoch": 0.3856,
      "grad_norm": 0.43553992327590363,
      "learning_rate": 3.517334709017108e-05,
      "loss": 2.1812,
      "step": 964
    },
    {
      "epoch": 0.386,
      "grad_norm": 0.4398838802982483,
      "learning_rate": 3.514375390431539e-05,
      "loss": 2.2188,
      "step": 965
    },
    {
      "epoch": 0.3864,
      "grad_norm": 0.4633186783165411,
      "learning_rate": 3.511414369393862e-05,
      "loss": 2.1118,
      "step": 966
    },
    {
      "epoch": 0.3868,
      "grad_norm": 0.449682172653329,
      "learning_rate": 3.5084516508736373e-05,
      "loss": 2.1997,
      "step": 967
    },
    {
      "epoch": 0.3872,
      "grad_norm": 0.4516102952322037,
      "learning_rate": 3.505487239843269e-05,
      "loss": 2.1431,
      "step": 968
    },
    {
      "epoch": 0.3876,
      "grad_norm": 0.4454365682406575,
      "learning_rate": 3.502521141278005e-05,
      "loss": 2.2354,
      "step": 969
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.45602844559186506,
      "learning_rate": 3.4995533601559226e-05,
      "loss": 2.1733,
      "step": 970
    },
    {
      "epoch": 0.3884,
      "grad_norm": 0.45743923243628004,
      "learning_rate": 3.496583901457926e-05,
      "loss": 2.1436,
      "step": 971
    },
    {
      "epoch": 0.3888,
      "grad_norm": 0.4553573301634564,
      "learning_rate": 3.4936127701677336e-05,
      "loss": 2.1753,
      "step": 972
    },
    {
      "epoch": 0.3892,
      "grad_norm": 0.4640892592047511,
      "learning_rate": 3.49063997127187e-05,
      "loss": 2.2227,
      "step": 973
    },
    {
      "epoch": 0.3896,
      "grad_norm": 0.4390583451958191,
      "learning_rate": 3.487665509759661e-05,
      "loss": 2.1836,
      "step": 974
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4592861328541613,
      "learning_rate": 3.484689390623218e-05,
      "loss": 2.2886,
      "step": 975
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.4358288064602415,
      "learning_rate": 3.4817116188574416e-05,
      "loss": 2.0742,
      "step": 976
    },
    {
      "epoch": 0.3908,
      "grad_norm": 0.45109275567999674,
      "learning_rate": 3.478732199459999e-05,
      "loss": 2.1763,
      "step": 977
    },
    {
      "epoch": 0.3912,
      "grad_norm": 0.4405196204954439,
      "learning_rate": 3.4757511374313276e-05,
      "loss": 2.1831,
      "step": 978
    },
    {
      "epoch": 0.3916,
      "grad_norm": 0.4587414662495656,
      "learning_rate": 3.47276843777462e-05,
      "loss": 2.1377,
      "step": 979
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.44230119508973187,
      "learning_rate": 3.4697841054958165e-05,
      "loss": 2.2554,
      "step": 980
    },
    {
      "epoch": 0.3924,
      "grad_norm": 0.46120793172389885,
      "learning_rate": 3.466798145603598e-05,
      "loss": 2.2173,
      "step": 981
    },
    {
      "epoch": 0.3928,
      "grad_norm": 0.44672979319486233,
      "learning_rate": 3.463810563109377e-05,
      "loss": 2.1465,
      "step": 982
    },
    {
      "epoch": 0.3932,
      "grad_norm": 0.42233461270976624,
      "learning_rate": 3.4608213630272914e-05,
      "loss": 2.1362,
      "step": 983
    },
    {
      "epoch": 0.3936,
      "grad_norm": 0.4507446450347781,
      "learning_rate": 3.457830550374189e-05,
      "loss": 2.2056,
      "step": 984
    },
    {
      "epoch": 0.394,
      "grad_norm": 0.4466548758582958,
      "learning_rate": 3.45483813016963e-05,
      "loss": 2.1699,
      "step": 985
    },
    {
      "epoch": 0.3944,
      "grad_norm": 0.4550908502679779,
      "learning_rate": 3.451844107435867e-05,
      "loss": 2.1792,
      "step": 986
    },
    {
      "epoch": 0.3948,
      "grad_norm": 0.4401202232518412,
      "learning_rate": 3.448848487197846e-05,
      "loss": 2.1582,
      "step": 987
    },
    {
      "epoch": 0.3952,
      "grad_norm": 0.43256300856799973,
      "learning_rate": 3.4458512744831925e-05,
      "loss": 2.1323,
      "step": 988
    },
    {
      "epoch": 0.3956,
      "grad_norm": 0.4431471084820965,
      "learning_rate": 3.4428524743222056e-05,
      "loss": 2.0908,
      "step": 989
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.4511210876557742,
      "learning_rate": 3.4398520917478476e-05,
      "loss": 2.2373,
      "step": 990
    },
    {
      "epoch": 0.3964,
      "grad_norm": 0.45166707638348014,
      "learning_rate": 3.436850131795738e-05,
      "loss": 2.147,
      "step": 991
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.4458048707188465,
      "learning_rate": 3.4338465995041425e-05,
      "loss": 2.1982,
      "step": 992
    },
    {
      "epoch": 0.3972,
      "grad_norm": 0.47789658268004476,
      "learning_rate": 3.430841499913965e-05,
      "loss": 2.2534,
      "step": 993
    },
    {
      "epoch": 0.3976,
      "grad_norm": 0.4238729097200864,
      "learning_rate": 3.4278348380687416e-05,
      "loss": 2.1416,
      "step": 994
    },
    {
      "epoch": 0.398,
      "grad_norm": 0.40848728516933275,
      "learning_rate": 3.42482661901463e-05,
      "loss": 1.9941,
      "step": 995
    },
    {
      "epoch": 0.3984,
      "grad_norm": 0.4322439593941042,
      "learning_rate": 3.421816847800401e-05,
      "loss": 2.2085,
      "step": 996
    },
    {
      "epoch": 0.3988,
      "grad_norm": 0.42566175678948287,
      "learning_rate": 3.418805529477429e-05,
      "loss": 2.2124,
      "step": 997
    },
    {
      "epoch": 0.3992,
      "grad_norm": 0.45442529288618966,
      "learning_rate": 3.415792669099688e-05,
      "loss": 2.23,
      "step": 998
    },
    {
      "epoch": 0.3996,
      "grad_norm": 0.42217063104150604,
      "learning_rate": 3.412778271723738e-05,
      "loss": 2.0962,
      "step": 999
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.44695783329820227,
      "learning_rate": 3.409762342408719e-05,
      "loss": 2.1543,
      "step": 1000
    },
    {
      "epoch": 0.4004,
      "grad_norm": 0.42549004939600565,
      "learning_rate": 3.406744886216342e-05,
      "loss": 2.1465,
      "step": 1001
    },
    {
      "epoch": 0.4008,
      "grad_norm": 0.4050486020944337,
      "learning_rate": 3.403725908210881e-05,
      "loss": 2.1055,
      "step": 1002
    },
    {
      "epoch": 0.4012,
      "grad_norm": 0.43195368690075014,
      "learning_rate": 3.4007054134591634e-05,
      "loss": 2.146,
      "step": 1003
    },
    {
      "epoch": 0.4016,
      "grad_norm": 0.4261119519785141,
      "learning_rate": 3.397683407030563e-05,
      "loss": 2.2183,
      "step": 1004
    },
    {
      "epoch": 0.402,
      "grad_norm": 0.4253915450025842,
      "learning_rate": 3.3946598939969896e-05,
      "loss": 2.1177,
      "step": 1005
    },
    {
      "epoch": 0.4024,
      "grad_norm": 0.42912157201109014,
      "learning_rate": 3.391634879432884e-05,
      "loss": 2.1519,
      "step": 1006
    },
    {
      "epoch": 0.4028,
      "grad_norm": 0.42222060447189097,
      "learning_rate": 3.388608368415204e-05,
      "loss": 2.2334,
      "step": 1007
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.4247332684906289,
      "learning_rate": 3.38558036602342e-05,
      "loss": 2.1899,
      "step": 1008
    },
    {
      "epoch": 0.4036,
      "grad_norm": 0.4093801580477843,
      "learning_rate": 3.382550877339507e-05,
      "loss": 2.105,
      "step": 1009
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.4396690298977685,
      "learning_rate": 3.379519907447931e-05,
      "loss": 2.2358,
      "step": 1010
    },
    {
      "epoch": 0.4044,
      "grad_norm": 0.41955753029831805,
      "learning_rate": 3.3764874614356495e-05,
      "loss": 2.1968,
      "step": 1011
    },
    {
      "epoch": 0.4048,
      "grad_norm": 0.41275848255300296,
      "learning_rate": 3.373453544392091e-05,
      "loss": 2.105,
      "step": 1012
    },
    {
      "epoch": 0.4052,
      "grad_norm": 0.43474044210437923,
      "learning_rate": 3.3704181614091565e-05,
      "loss": 2.1792,
      "step": 1013
    },
    {
      "epoch": 0.4056,
      "grad_norm": 0.438351537523726,
      "learning_rate": 3.367381317581209e-05,
      "loss": 2.229,
      "step": 1014
    },
    {
      "epoch": 0.406,
      "grad_norm": 0.41636949713403193,
      "learning_rate": 3.3643430180050574e-05,
      "loss": 2.1353,
      "step": 1015
    },
    {
      "epoch": 0.4064,
      "grad_norm": 0.41460586834532526,
      "learning_rate": 3.36130326777996e-05,
      "loss": 2.1401,
      "step": 1016
    },
    {
      "epoch": 0.4068,
      "grad_norm": 0.4644675278809695,
      "learning_rate": 3.358262072007606e-05,
      "loss": 2.2178,
      "step": 1017
    },
    {
      "epoch": 0.4072,
      "grad_norm": 0.44009779946638655,
      "learning_rate": 3.355219435792112e-05,
      "loss": 2.1367,
      "step": 1018
    },
    {
      "epoch": 0.4076,
      "grad_norm": 0.4203630365829232,
      "learning_rate": 3.352175364240013e-05,
      "loss": 2.1641,
      "step": 1019
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.44438251935823553,
      "learning_rate": 3.349129862460251e-05,
      "loss": 2.1875,
      "step": 1020
    },
    {
      "epoch": 0.4084,
      "grad_norm": 0.42900342684208215,
      "learning_rate": 3.34608293556417e-05,
      "loss": 2.1289,
      "step": 1021
    },
    {
      "epoch": 0.4088,
      "grad_norm": 0.4177732215867004,
      "learning_rate": 3.343034588665505e-05,
      "loss": 2.1606,
      "step": 1022
    },
    {
      "epoch": 0.4092,
      "grad_norm": 0.42170337325852675,
      "learning_rate": 3.3399848268803734e-05,
      "loss": 2.2051,
      "step": 1023
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.4305700357953061,
      "learning_rate": 3.336933655327269e-05,
      "loss": 2.2295,
      "step": 1024
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.4326028043869237,
      "learning_rate": 3.333881079127052e-05,
      "loss": 2.0542,
      "step": 1025
    },
    {
      "epoch": 0.4104,
      "grad_norm": 0.4218804732006521,
      "learning_rate": 3.330827103402937e-05,
      "loss": 2.2441,
      "step": 1026
    },
    {
      "epoch": 0.4108,
      "grad_norm": 0.4097045005150615,
      "learning_rate": 3.3277717332804905e-05,
      "loss": 2.1738,
      "step": 1027
    },
    {
      "epoch": 0.4112,
      "grad_norm": 0.43311515865530553,
      "learning_rate": 3.324714973887618e-05,
      "loss": 2.1782,
      "step": 1028
    },
    {
      "epoch": 0.4116,
      "grad_norm": 0.4333371526928613,
      "learning_rate": 3.321656830354557e-05,
      "loss": 2.1934,
      "step": 1029
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.45416039182034634,
      "learning_rate": 3.3185973078138664e-05,
      "loss": 2.1592,
      "step": 1030
    },
    {
      "epoch": 0.4124,
      "grad_norm": 0.4551469809242757,
      "learning_rate": 3.315536411400423e-05,
      "loss": 2.2437,
      "step": 1031
    },
    {
      "epoch": 0.4128,
      "grad_norm": 0.42927297711750184,
      "learning_rate": 3.312474146251407e-05,
      "loss": 2.1494,
      "step": 1032
    },
    {
      "epoch": 0.4132,
      "grad_norm": 0.4495743088804986,
      "learning_rate": 3.309410517506296e-05,
      "loss": 2.1841,
      "step": 1033
    },
    {
      "epoch": 0.4136,
      "grad_norm": 0.4346592808870036,
      "learning_rate": 3.306345530306855e-05,
      "loss": 2.2046,
      "step": 1034
    },
    {
      "epoch": 0.414,
      "grad_norm": 0.46793227396804965,
      "learning_rate": 3.303279189797131e-05,
      "loss": 2.1387,
      "step": 1035
    },
    {
      "epoch": 0.4144,
      "grad_norm": 0.41663443461370225,
      "learning_rate": 3.300211501123442e-05,
      "loss": 2.166,
      "step": 1036
    },
    {
      "epoch": 0.4148,
      "grad_norm": 0.4367383859095847,
      "learning_rate": 3.2971424694343684e-05,
      "loss": 2.0811,
      "step": 1037
    },
    {
      "epoch": 0.4152,
      "grad_norm": 0.4227246484386054,
      "learning_rate": 3.294072099880744e-05,
      "loss": 2.1416,
      "step": 1038
    },
    {
      "epoch": 0.4156,
      "grad_norm": 0.42841784859796644,
      "learning_rate": 3.2910003976156476e-05,
      "loss": 2.1294,
      "step": 1039
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.4159061544863419,
      "learning_rate": 3.287927367794397e-05,
      "loss": 2.1436,
      "step": 1040
    },
    {
      "epoch": 0.4164,
      "grad_norm": 0.41839081624983676,
      "learning_rate": 3.284853015574535e-05,
      "loss": 2.166,
      "step": 1041
    },
    {
      "epoch": 0.4168,
      "grad_norm": 0.43079925316713474,
      "learning_rate": 3.2817773461158274e-05,
      "loss": 2.2051,
      "step": 1042
    },
    {
      "epoch": 0.4172,
      "grad_norm": 0.4238693537341193,
      "learning_rate": 3.278700364580247e-05,
      "loss": 2.1714,
      "step": 1043
    },
    {
      "epoch": 0.4176,
      "grad_norm": 0.4044810065285285,
      "learning_rate": 3.27562207613197e-05,
      "loss": 2.1938,
      "step": 1044
    },
    {
      "epoch": 0.418,
      "grad_norm": 0.41612654543666383,
      "learning_rate": 3.272542485937369e-05,
      "loss": 2.1201,
      "step": 1045
    },
    {
      "epoch": 0.4184,
      "grad_norm": 0.4332324182474974,
      "learning_rate": 3.2694615991649964e-05,
      "loss": 2.2681,
      "step": 1046
    },
    {
      "epoch": 0.4188,
      "grad_norm": 0.4300489973552617,
      "learning_rate": 3.266379420985585e-05,
      "loss": 2.187,
      "step": 1047
    },
    {
      "epoch": 0.4192,
      "grad_norm": 0.41910215936405165,
      "learning_rate": 3.263295956572031e-05,
      "loss": 2.1475,
      "step": 1048
    },
    {
      "epoch": 0.4196,
      "grad_norm": 0.41197882862002505,
      "learning_rate": 3.2602112110993934e-05,
      "loss": 2.165,
      "step": 1049
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.4168408787197803,
      "learning_rate": 3.2571251897448765e-05,
      "loss": 2.2134,
      "step": 1050
    },
    {
      "epoch": 0.4204,
      "grad_norm": 0.41443793383911104,
      "learning_rate": 3.2540378976878325e-05,
      "loss": 2.1421,
      "step": 1051
    },
    {
      "epoch": 0.4208,
      "grad_norm": 0.42428871811607194,
      "learning_rate": 3.25094934010974e-05,
      "loss": 2.0938,
      "step": 1052
    },
    {
      "epoch": 0.4212,
      "grad_norm": 0.40748203166763275,
      "learning_rate": 3.2478595221942043e-05,
      "loss": 2.2002,
      "step": 1053
    },
    {
      "epoch": 0.4216,
      "grad_norm": 0.4328951623283723,
      "learning_rate": 3.244768449126947e-05,
      "loss": 2.1631,
      "step": 1054
    },
    {
      "epoch": 0.422,
      "grad_norm": 0.4135096281040003,
      "learning_rate": 3.241676126095792e-05,
      "loss": 2.0312,
      "step": 1055
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.41891754427461636,
      "learning_rate": 3.238582558290667e-05,
      "loss": 2.0806,
      "step": 1056
    },
    {
      "epoch": 0.4228,
      "grad_norm": 0.44129032927758377,
      "learning_rate": 3.235487750903584e-05,
      "loss": 2.2559,
      "step": 1057
    },
    {
      "epoch": 0.4232,
      "grad_norm": 0.4156868955366057,
      "learning_rate": 3.2323917091286384e-05,
      "loss": 2.1128,
      "step": 1058
    },
    {
      "epoch": 0.4236,
      "grad_norm": 0.43307537493599785,
      "learning_rate": 3.229294438161995e-05,
      "loss": 2.1943,
      "step": 1059
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.4030057424701669,
      "learning_rate": 3.226195943201883e-05,
      "loss": 2.1899,
      "step": 1060
    },
    {
      "epoch": 0.4244,
      "grad_norm": 0.4192622891666446,
      "learning_rate": 3.2230962294485864e-05,
      "loss": 2.2314,
      "step": 1061
    },
    {
      "epoch": 0.4248,
      "grad_norm": 0.3983062187952679,
      "learning_rate": 3.219995302104434e-05,
      "loss": 2.1025,
      "step": 1062
    },
    {
      "epoch": 0.4252,
      "grad_norm": 0.4214114673161536,
      "learning_rate": 3.216893166373789e-05,
      "loss": 2.2402,
      "step": 1063
    },
    {
      "epoch": 0.4256,
      "grad_norm": 0.3997898587936244,
      "learning_rate": 3.2137898274630474e-05,
      "loss": 2.106,
      "step": 1064
    },
    {
      "epoch": 0.426,
      "grad_norm": 0.4287924848200512,
      "learning_rate": 3.210685290580622e-05,
      "loss": 2.1968,
      "step": 1065
    },
    {
      "epoch": 0.4264,
      "grad_norm": 0.42030733697721584,
      "learning_rate": 3.207579560936934e-05,
      "loss": 2.1948,
      "step": 1066
    },
    {
      "epoch": 0.4268,
      "grad_norm": 0.40437038504607137,
      "learning_rate": 3.2044726437444114e-05,
      "loss": 2.1465,
      "step": 1067
    },
    {
      "epoch": 0.4272,
      "grad_norm": 0.4169402827114819,
      "learning_rate": 3.201364544217471e-05,
      "loss": 2.0601,
      "step": 1068
    },
    {
      "epoch": 0.4276,
      "grad_norm": 0.43069990255000007,
      "learning_rate": 3.1982552675725165e-05,
      "loss": 2.1797,
      "step": 1069
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.4049187385502388,
      "learning_rate": 3.1951448190279255e-05,
      "loss": 2.1167,
      "step": 1070
    },
    {
      "epoch": 0.4284,
      "grad_norm": 0.4460751709870904,
      "learning_rate": 3.1920332038040433e-05,
      "loss": 2.1821,
      "step": 1071
    },
    {
      "epoch": 0.4288,
      "grad_norm": 0.4170046523934675,
      "learning_rate": 3.188920427123174e-05,
      "loss": 2.1284,
      "step": 1072
    },
    {
      "epoch": 0.4292,
      "grad_norm": 0.4131490580032082,
      "learning_rate": 3.1858064942095686e-05,
      "loss": 2.1226,
      "step": 1073
    },
    {
      "epoch": 0.4296,
      "grad_norm": 0.4204067697958883,
      "learning_rate": 3.1826914102894225e-05,
      "loss": 2.188,
      "step": 1074
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.42564602126947365,
      "learning_rate": 3.1795751805908573e-05,
      "loss": 2.1943,
      "step": 1075
    },
    {
      "epoch": 0.4304,
      "grad_norm": 0.4281054898190035,
      "learning_rate": 3.1764578103439234e-05,
      "loss": 2.1123,
      "step": 1076
    },
    {
      "epoch": 0.4308,
      "grad_norm": 0.4118787165008805,
      "learning_rate": 3.1733393047805826e-05,
      "loss": 2.1274,
      "step": 1077
    },
    {
      "epoch": 0.4312,
      "grad_norm": 0.4502934173205953,
      "learning_rate": 3.170219669134701e-05,
      "loss": 2.1855,
      "step": 1078
    },
    {
      "epoch": 0.4316,
      "grad_norm": 0.40657594187810703,
      "learning_rate": 3.167098908642044e-05,
      "loss": 2.1582,
      "step": 1079
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.4167113871202721,
      "learning_rate": 3.163977028540263e-05,
      "loss": 2.1426,
      "step": 1080
    },
    {
      "epoch": 0.4324,
      "grad_norm": 0.4299155718674914,
      "learning_rate": 3.160854034068889e-05,
      "loss": 2.1641,
      "step": 1081
    },
    {
      "epoch": 0.4328,
      "grad_norm": 0.4060855697421976,
      "learning_rate": 3.1577299304693246e-05,
      "loss": 2.1367,
      "step": 1082
    },
    {
      "epoch": 0.4332,
      "grad_norm": 0.40889293706521046,
      "learning_rate": 3.15460472298483e-05,
      "loss": 2.0679,
      "step": 1083
    },
    {
      "epoch": 0.4336,
      "grad_norm": 0.42608492699322575,
      "learning_rate": 3.151478416860524e-05,
      "loss": 2.0869,
      "step": 1084
    },
    {
      "epoch": 0.434,
      "grad_norm": 0.41662435680452575,
      "learning_rate": 3.1483510173433626e-05,
      "loss": 2.1533,
      "step": 1085
    },
    {
      "epoch": 0.4344,
      "grad_norm": 0.4223311533825211,
      "learning_rate": 3.145222529682143e-05,
      "loss": 2.1548,
      "step": 1086
    },
    {
      "epoch": 0.4348,
      "grad_norm": 0.41603186694096905,
      "learning_rate": 3.142092959127484e-05,
      "loss": 2.2007,
      "step": 1087
    },
    {
      "epoch": 0.4352,
      "grad_norm": 0.44125703376148645,
      "learning_rate": 3.1389623109318246e-05,
      "loss": 2.1392,
      "step": 1088
    },
    {
      "epoch": 0.4356,
      "grad_norm": 0.4290218935216372,
      "learning_rate": 3.135830590349412e-05,
      "loss": 2.1797,
      "step": 1089
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.4453884493699484,
      "learning_rate": 3.1326978026362904e-05,
      "loss": 2.1338,
      "step": 1090
    },
    {
      "epoch": 0.4364,
      "grad_norm": 0.4417885852389296,
      "learning_rate": 3.129563953050301e-05,
      "loss": 2.1548,
      "step": 1091
    },
    {
      "epoch": 0.4368,
      "grad_norm": 0.45307147476605586,
      "learning_rate": 3.1264290468510604e-05,
      "loss": 2.1221,
      "step": 1092
    },
    {
      "epoch": 0.4372,
      "grad_norm": 0.4360310290312061,
      "learning_rate": 3.123293089299964e-05,
      "loss": 2.2134,
      "step": 1093
    },
    {
      "epoch": 0.4376,
      "grad_norm": 0.4314719203471145,
      "learning_rate": 3.120156085660168e-05,
      "loss": 2.1465,
      "step": 1094
    },
    {
      "epoch": 0.438,
      "grad_norm": 0.4222608562549768,
      "learning_rate": 3.117018041196585e-05,
      "loss": 2.165,
      "step": 1095
    },
    {
      "epoch": 0.4384,
      "grad_norm": 0.4296164077689853,
      "learning_rate": 3.1138789611758776e-05,
      "loss": 2.1553,
      "step": 1096
    },
    {
      "epoch": 0.4388,
      "grad_norm": 0.43104944544089163,
      "learning_rate": 3.110738850866442e-05,
      "loss": 2.2085,
      "step": 1097
    },
    {
      "epoch": 0.4392,
      "grad_norm": 0.45548501970684724,
      "learning_rate": 3.107597715538406e-05,
      "loss": 2.2075,
      "step": 1098
    },
    {
      "epoch": 0.4396,
      "grad_norm": 0.4106946895100192,
      "learning_rate": 3.104455560463617e-05,
      "loss": 2.1484,
      "step": 1099
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.41349335481763855,
      "learning_rate": 3.101312390915634e-05,
      "loss": 2.1104,
      "step": 1100
    },
    {
      "epoch": 0.4404,
      "grad_norm": 0.422838984218334,
      "learning_rate": 3.0981682121697194e-05,
      "loss": 2.1357,
      "step": 1101
    },
    {
      "epoch": 0.4408,
      "grad_norm": 0.4293994290357556,
      "learning_rate": 3.095023029502827e-05,
      "loss": 2.1118,
      "step": 1102
    },
    {
      "epoch": 0.4412,
      "grad_norm": 0.4496809840362276,
      "learning_rate": 3.0918768481935996e-05,
      "loss": 2.2041,
      "step": 1103
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.4359150493961627,
      "learning_rate": 3.0887296735223515e-05,
      "loss": 2.1396,
      "step": 1104
    },
    {
      "epoch": 0.442,
      "grad_norm": 0.45682749649299786,
      "learning_rate": 3.0855815107710666e-05,
      "loss": 2.2031,
      "step": 1105
    },
    {
      "epoch": 0.4424,
      "grad_norm": 0.4311149160910671,
      "learning_rate": 3.082432365223388e-05,
      "loss": 2.2808,
      "step": 1106
    },
    {
      "epoch": 0.4428,
      "grad_norm": 0.4386152934785648,
      "learning_rate": 3.0792822421646063e-05,
      "loss": 2.2578,
      "step": 1107
    },
    {
      "epoch": 0.4432,
      "grad_norm": 0.4285545820400007,
      "learning_rate": 3.0761311468816524e-05,
      "loss": 2.1562,
      "step": 1108
    },
    {
      "epoch": 0.4436,
      "grad_norm": 0.4072678104763214,
      "learning_rate": 3.072979084663091e-05,
      "loss": 2.1626,
      "step": 1109
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.4394430099895765,
      "learning_rate": 3.069826060799109e-05,
      "loss": 2.1758,
      "step": 1110
    },
    {
      "epoch": 0.4444,
      "grad_norm": 0.42295538617243167,
      "learning_rate": 3.066672080581506e-05,
      "loss": 2.2036,
      "step": 1111
    },
    {
      "epoch": 0.4448,
      "grad_norm": 0.47068536655301496,
      "learning_rate": 3.0635171493036874e-05,
      "loss": 2.2407,
      "step": 1112
    },
    {
      "epoch": 0.4452,
      "grad_norm": 0.41740124598154765,
      "learning_rate": 3.060361272260656e-05,
      "loss": 2.0854,
      "step": 1113
    },
    {
      "epoch": 0.4456,
      "grad_norm": 0.4793692410034079,
      "learning_rate": 3.057204454748999e-05,
      "loss": 2.2441,
      "step": 1114
    },
    {
      "epoch": 0.446,
      "grad_norm": 0.4353272792800337,
      "learning_rate": 3.0540467020668864e-05,
      "loss": 2.0913,
      "step": 1115
    },
    {
      "epoch": 0.4464,
      "grad_norm": 0.4393214546257078,
      "learning_rate": 3.050888019514052e-05,
      "loss": 2.1973,
      "step": 1116
    },
    {
      "epoch": 0.4468,
      "grad_norm": 0.502283527729467,
      "learning_rate": 3.047728412391796e-05,
      "loss": 2.2334,
      "step": 1117
    },
    {
      "epoch": 0.4472,
      "grad_norm": 0.43317793418394496,
      "learning_rate": 3.0445678860029657e-05,
      "loss": 2.1265,
      "step": 1118
    },
    {
      "epoch": 0.4476,
      "grad_norm": 0.4391946024073819,
      "learning_rate": 3.0414064456519543e-05,
      "loss": 2.0879,
      "step": 1119
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.4435916935816442,
      "learning_rate": 3.0382440966446875e-05,
      "loss": 2.2388,
      "step": 1120
    },
    {
      "epoch": 0.4484,
      "grad_norm": 0.4565843678026756,
      "learning_rate": 3.0350808442886165e-05,
      "loss": 2.208,
      "step": 1121
    },
    {
      "epoch": 0.4488,
      "grad_norm": 0.42318738420896024,
      "learning_rate": 3.031916693892709e-05,
      "loss": 2.2134,
      "step": 1122
    },
    {
      "epoch": 0.4492,
      "grad_norm": 0.45465651689885483,
      "learning_rate": 3.0287516507674375e-05,
      "loss": 2.1372,
      "step": 1123
    },
    {
      "epoch": 0.4496,
      "grad_norm": 0.45160463225528147,
      "learning_rate": 3.0255857202247773e-05,
      "loss": 2.1938,
      "step": 1124
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4260140424544314,
      "learning_rate": 3.0224189075781884e-05,
      "loss": 2.2197,
      "step": 1125
    },
    {
      "epoch": 0.4504,
      "grad_norm": 0.4517994955469367,
      "learning_rate": 3.0192512181426135e-05,
      "loss": 2.1611,
      "step": 1126
    },
    {
      "epoch": 0.4508,
      "grad_norm": 0.40641266554039157,
      "learning_rate": 3.0160826572344674e-05,
      "loss": 2.1182,
      "step": 1127
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.4270402345961038,
      "learning_rate": 3.0129132301716263e-05,
      "loss": 2.1714,
      "step": 1128
    },
    {
      "epoch": 0.4516,
      "grad_norm": 0.42607738596788236,
      "learning_rate": 3.0097429422734215e-05,
      "loss": 2.1274,
      "step": 1129
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.42582344652913723,
      "learning_rate": 3.0065717988606257e-05,
      "loss": 2.2305,
      "step": 1130
    },
    {
      "epoch": 0.4524,
      "grad_norm": 0.41916874653376507,
      "learning_rate": 3.0033998052554524e-05,
      "loss": 2.2339,
      "step": 1131
    },
    {
      "epoch": 0.4528,
      "grad_norm": 0.40836817950832716,
      "learning_rate": 3.0002269667815376e-05,
      "loss": 2.2036,
      "step": 1132
    },
    {
      "epoch": 0.4532,
      "grad_norm": 0.42562662930888223,
      "learning_rate": 2.9970532887639386e-05,
      "loss": 2.1118,
      "step": 1133
    },
    {
      "epoch": 0.4536,
      "grad_norm": 0.414297888522288,
      "learning_rate": 2.993878776529118e-05,
      "loss": 2.1284,
      "step": 1134
    },
    {
      "epoch": 0.454,
      "grad_norm": 0.4164389058203368,
      "learning_rate": 2.990703435404944e-05,
      "loss": 2.1177,
      "step": 1135
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.4465828519304642,
      "learning_rate": 2.9875272707206702e-05,
      "loss": 2.2363,
      "step": 1136
    },
    {
      "epoch": 0.4548,
      "grad_norm": 0.404639257805214,
      "learning_rate": 2.984350287806935e-05,
      "loss": 2.0684,
      "step": 1137
    },
    {
      "epoch": 0.4552,
      "grad_norm": 0.4315440671271125,
      "learning_rate": 2.9811724919957514e-05,
      "loss": 2.1738,
      "step": 1138
    },
    {
      "epoch": 0.4556,
      "grad_norm": 0.43214570461507834,
      "learning_rate": 2.9779938886204928e-05,
      "loss": 2.2202,
      "step": 1139
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.43080949710988914,
      "learning_rate": 2.9748144830158924e-05,
      "loss": 2.084,
      "step": 1140
    },
    {
      "epoch": 0.4564,
      "grad_norm": 0.4094424590052108,
      "learning_rate": 2.9716342805180264e-05,
      "loss": 2.123,
      "step": 1141
    },
    {
      "epoch": 0.4568,
      "grad_norm": 0.4403890460330844,
      "learning_rate": 2.9684532864643122e-05,
      "loss": 2.3037,
      "step": 1142
    },
    {
      "epoch": 0.4572,
      "grad_norm": 0.4363037937439011,
      "learning_rate": 2.9652715061934906e-05,
      "loss": 2.1899,
      "step": 1143
    },
    {
      "epoch": 0.4576,
      "grad_norm": 0.42343025221012986,
      "learning_rate": 2.962088945045625e-05,
      "loss": 2.1489,
      "step": 1144
    },
    {
      "epoch": 0.458,
      "grad_norm": 0.42252855387980764,
      "learning_rate": 2.9589056083620902e-05,
      "loss": 2.1743,
      "step": 1145
    },
    {
      "epoch": 0.4584,
      "grad_norm": 0.4303451518815322,
      "learning_rate": 2.955721501485561e-05,
      "loss": 2.1953,
      "step": 1146
    },
    {
      "epoch": 0.4588,
      "grad_norm": 0.4049079208058076,
      "learning_rate": 2.9525366297600053e-05,
      "loss": 2.1167,
      "step": 1147
    },
    {
      "epoch": 0.4592,
      "grad_norm": 0.43168088699186535,
      "learning_rate": 2.9493509985306745e-05,
      "loss": 2.1782,
      "step": 1148
    },
    {
      "epoch": 0.4596,
      "grad_norm": 0.4230575944052817,
      "learning_rate": 2.9461646131440945e-05,
      "loss": 2.1948,
      "step": 1149
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.44767352146103495,
      "learning_rate": 2.9429774789480575e-05,
      "loss": 2.1797,
      "step": 1150
    },
    {
      "epoch": 0.4604,
      "grad_norm": 0.4388657944749937,
      "learning_rate": 2.9397896012916115e-05,
      "loss": 2.1299,
      "step": 1151
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.42249253913376295,
      "learning_rate": 2.9366009855250537e-05,
      "loss": 2.209,
      "step": 1152
    },
    {
      "epoch": 0.4612,
      "grad_norm": 0.453058603136451,
      "learning_rate": 2.9334116369999192e-05,
      "loss": 2.1909,
      "step": 1153
    },
    {
      "epoch": 0.4616,
      "grad_norm": 0.4256548528509441,
      "learning_rate": 2.930221561068973e-05,
      "loss": 2.1143,
      "step": 1154
    },
    {
      "epoch": 0.462,
      "grad_norm": 0.4189521203020151,
      "learning_rate": 2.927030763086201e-05,
      "loss": 2.2021,
      "step": 1155
    },
    {
      "epoch": 0.4624,
      "grad_norm": 0.4245516358527038,
      "learning_rate": 2.9238392484068005e-05,
      "loss": 2.1455,
      "step": 1156
    },
    {
      "epoch": 0.4628,
      "grad_norm": 0.43851054469139394,
      "learning_rate": 2.920647022387173e-05,
      "loss": 2.2344,
      "step": 1157
    },
    {
      "epoch": 0.4632,
      "grad_norm": 0.44803371130090336,
      "learning_rate": 2.9174540903849118e-05,
      "loss": 2.1992,
      "step": 1158
    },
    {
      "epoch": 0.4636,
      "grad_norm": 0.44740784562892144,
      "learning_rate": 2.914260457758796e-05,
      "loss": 2.1133,
      "step": 1159
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.4526098998804958,
      "learning_rate": 2.9110661298687824e-05,
      "loss": 2.1479,
      "step": 1160
    },
    {
      "epoch": 0.4644,
      "grad_norm": 0.4349433963742606,
      "learning_rate": 2.9078711120759912e-05,
      "loss": 2.2021,
      "step": 1161
    },
    {
      "epoch": 0.4648,
      "grad_norm": 0.43923938621983327,
      "learning_rate": 2.9046754097427036e-05,
      "loss": 2.0776,
      "step": 1162
    },
    {
      "epoch": 0.4652,
      "grad_norm": 0.44821046462211156,
      "learning_rate": 2.901479028232347e-05,
      "loss": 2.293,
      "step": 1163
    },
    {
      "epoch": 0.4656,
      "grad_norm": 0.43628094779867516,
      "learning_rate": 2.8982819729094917e-05,
      "loss": 2.2129,
      "step": 1164
    },
    {
      "epoch": 0.466,
      "grad_norm": 0.4070216728564025,
      "learning_rate": 2.8950842491398357e-05,
      "loss": 2.1216,
      "step": 1165
    },
    {
      "epoch": 0.4664,
      "grad_norm": 0.45212796386259774,
      "learning_rate": 2.8918858622902023e-05,
      "loss": 2.1885,
      "step": 1166
    },
    {
      "epoch": 0.4668,
      "grad_norm": 0.4144113976219439,
      "learning_rate": 2.888686817728524e-05,
      "loss": 2.1079,
      "step": 1167
    },
    {
      "epoch": 0.4672,
      "grad_norm": 0.4311169889161364,
      "learning_rate": 2.8854871208238393e-05,
      "loss": 2.1255,
      "step": 1168
    },
    {
      "epoch": 0.4676,
      "grad_norm": 0.42350158422183465,
      "learning_rate": 2.882286776946282e-05,
      "loss": 2.1631,
      "step": 1169
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.45510548783444943,
      "learning_rate": 2.8790857914670698e-05,
      "loss": 2.1196,
      "step": 1170
    },
    {
      "epoch": 0.4684,
      "grad_norm": 0.424381613706184,
      "learning_rate": 2.8758841697584997e-05,
      "loss": 2.1069,
      "step": 1171
    },
    {
      "epoch": 0.4688,
      "grad_norm": 0.4296154773091833,
      "learning_rate": 2.8726819171939333e-05,
      "loss": 2.0942,
      "step": 1172
    },
    {
      "epoch": 0.4692,
      "grad_norm": 0.4403722660262899,
      "learning_rate": 2.8694790391477948e-05,
      "loss": 2.1958,
      "step": 1173
    },
    {
      "epoch": 0.4696,
      "grad_norm": 0.43374058782585495,
      "learning_rate": 2.8662755409955544e-05,
      "loss": 2.0845,
      "step": 1174
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.413730650462457,
      "learning_rate": 2.863071428113726e-05,
      "loss": 2.1123,
      "step": 1175
    },
    {
      "epoch": 0.4704,
      "grad_norm": 0.4189151061050549,
      "learning_rate": 2.8598667058798534e-05,
      "loss": 2.1616,
      "step": 1176
    },
    {
      "epoch": 0.4708,
      "grad_norm": 0.4435922074149047,
      "learning_rate": 2.856661379672504e-05,
      "loss": 2.147,
      "step": 1177
    },
    {
      "epoch": 0.4712,
      "grad_norm": 0.4363037395944782,
      "learning_rate": 2.853455454871259e-05,
      "loss": 2.1606,
      "step": 1178
    },
    {
      "epoch": 0.4716,
      "grad_norm": 0.4027098451490322,
      "learning_rate": 2.8502489368567027e-05,
      "loss": 2.1382,
      "step": 1179
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.4047658987982528,
      "learning_rate": 2.8470418310104173e-05,
      "loss": 2.0688,
      "step": 1180
    },
    {
      "epoch": 0.4724,
      "grad_norm": 0.4117365079866179,
      "learning_rate": 2.843834142714969e-05,
      "loss": 2.2471,
      "step": 1181
    },
    {
      "epoch": 0.4728,
      "grad_norm": 0.403105811208905,
      "learning_rate": 2.8406258773539047e-05,
      "loss": 2.1494,
      "step": 1182
    },
    {
      "epoch": 0.4732,
      "grad_norm": 0.414473645130568,
      "learning_rate": 2.837417040311736e-05,
      "loss": 2.3398,
      "step": 1183
    },
    {
      "epoch": 0.4736,
      "grad_norm": 0.40948727446018474,
      "learning_rate": 2.834207636973938e-05,
      "loss": 2.1558,
      "step": 1184
    },
    {
      "epoch": 0.474,
      "grad_norm": 0.4197017587106737,
      "learning_rate": 2.8309976727269332e-05,
      "loss": 2.1357,
      "step": 1185
    },
    {
      "epoch": 0.4744,
      "grad_norm": 0.4188221538817617,
      "learning_rate": 2.827787152958086e-05,
      "loss": 2.2446,
      "step": 1186
    },
    {
      "epoch": 0.4748,
      "grad_norm": 0.4186587749621484,
      "learning_rate": 2.824576083055695e-05,
      "loss": 2.144,
      "step": 1187
    },
    {
      "epoch": 0.4752,
      "grad_norm": 0.4047787014080068,
      "learning_rate": 2.8213644684089803e-05,
      "loss": 2.1123,
      "step": 1188
    },
    {
      "epoch": 0.4756,
      "grad_norm": 0.41425768837730786,
      "learning_rate": 2.8181523144080762e-05,
      "loss": 2.2207,
      "step": 1189
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.42304778490699135,
      "learning_rate": 2.814939626444023e-05,
      "loss": 2.1021,
      "step": 1190
    },
    {
      "epoch": 0.4764,
      "grad_norm": 0.43881765781210663,
      "learning_rate": 2.8117264099087572e-05,
      "loss": 2.144,
      "step": 1191
    },
    {
      "epoch": 0.4768,
      "grad_norm": 0.41511069953035845,
      "learning_rate": 2.8085126701951014e-05,
      "loss": 2.144,
      "step": 1192
    },
    {
      "epoch": 0.4772,
      "grad_norm": 0.40039303430058787,
      "learning_rate": 2.805298412696758e-05,
      "loss": 2.1191,
      "step": 1193
    },
    {
      "epoch": 0.4776,
      "grad_norm": 0.4420660370410975,
      "learning_rate": 2.8020836428082963e-05,
      "loss": 2.209,
      "step": 1194
    },
    {
      "epoch": 0.478,
      "grad_norm": 0.4166991431435499,
      "learning_rate": 2.7988683659251474e-05,
      "loss": 2.1924,
      "step": 1195
    },
    {
      "epoch": 0.4784,
      "grad_norm": 0.444882358445624,
      "learning_rate": 2.7956525874435924e-05,
      "loss": 2.2085,
      "step": 1196
    },
    {
      "epoch": 0.4788,
      "grad_norm": 0.42718826113557645,
      "learning_rate": 2.7924363127607552e-05,
      "loss": 2.2378,
      "step": 1197
    },
    {
      "epoch": 0.4792,
      "grad_norm": 0.4046041665497717,
      "learning_rate": 2.789219547274589e-05,
      "loss": 2.1099,
      "step": 1198
    },
    {
      "epoch": 0.4796,
      "grad_norm": 0.4408815268368668,
      "learning_rate": 2.786002296383877e-05,
      "loss": 2.105,
      "step": 1199
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4432534450276139,
      "learning_rate": 2.782784565488211e-05,
      "loss": 2.0645,
      "step": 1200
    },
    {
      "epoch": 0.4804,
      "grad_norm": 0.4366076447928163,
      "learning_rate": 2.779566359987992e-05,
      "loss": 2.0781,
      "step": 1201
    },
    {
      "epoch": 0.4808,
      "grad_norm": 0.43568124352335724,
      "learning_rate": 2.776347685284415e-05,
      "loss": 2.146,
      "step": 1202
    },
    {
      "epoch": 0.4812,
      "grad_norm": 0.44466488316405994,
      "learning_rate": 2.773128546779466e-05,
      "loss": 2.2476,
      "step": 1203
    },
    {
      "epoch": 0.4816,
      "grad_norm": 0.4123911021331884,
      "learning_rate": 2.769908949875906e-05,
      "loss": 2.1084,
      "step": 1204
    },
    {
      "epoch": 0.482,
      "grad_norm": 0.4533693886857361,
      "learning_rate": 2.766688899977266e-05,
      "loss": 2.1167,
      "step": 1205
    },
    {
      "epoch": 0.4824,
      "grad_norm": 0.4431360939624352,
      "learning_rate": 2.7634684024878406e-05,
      "loss": 2.1367,
      "step": 1206
    },
    {
      "epoch": 0.4828,
      "grad_norm": 0.414348984682453,
      "learning_rate": 2.7602474628126695e-05,
      "loss": 2.0938,
      "step": 1207
    },
    {
      "epoch": 0.4832,
      "grad_norm": 0.41373814933223335,
      "learning_rate": 2.7570260863575402e-05,
      "loss": 2.0771,
      "step": 1208
    },
    {
      "epoch": 0.4836,
      "grad_norm": 0.46361582649137184,
      "learning_rate": 2.7538042785289708e-05,
      "loss": 2.1631,
      "step": 1209
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.4364352862977587,
      "learning_rate": 2.7505820447342028e-05,
      "loss": 2.1465,
      "step": 1210
    },
    {
      "epoch": 0.4844,
      "grad_norm": 0.4360822357765463,
      "learning_rate": 2.747359390381194e-05,
      "loss": 2.1943,
      "step": 1211
    },
    {
      "epoch": 0.4848,
      "grad_norm": 0.44619994556782056,
      "learning_rate": 2.7441363208786076e-05,
      "loss": 2.1284,
      "step": 1212
    },
    {
      "epoch": 0.4852,
      "grad_norm": 0.4349277065780005,
      "learning_rate": 2.7409128416358034e-05,
      "loss": 2.0273,
      "step": 1213
    },
    {
      "epoch": 0.4856,
      "grad_norm": 0.45151157859689606,
      "learning_rate": 2.7376889580628273e-05,
      "loss": 2.1152,
      "step": 1214
    },
    {
      "epoch": 0.486,
      "grad_norm": 0.4038317186912375,
      "learning_rate": 2.7344646755704078e-05,
      "loss": 2.1611,
      "step": 1215
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.45381763961605126,
      "learning_rate": 2.7312399995699383e-05,
      "loss": 2.1167,
      "step": 1216
    },
    {
      "epoch": 0.4868,
      "grad_norm": 0.501210385508517,
      "learning_rate": 2.728014935473477e-05,
      "loss": 2.2324,
      "step": 1217
    },
    {
      "epoch": 0.4872,
      "grad_norm": 0.4197914729826282,
      "learning_rate": 2.7247894886937297e-05,
      "loss": 2.2285,
      "step": 1218
    },
    {
      "epoch": 0.4876,
      "grad_norm": 0.4483788732253965,
      "learning_rate": 2.721563664644046e-05,
      "loss": 2.2104,
      "step": 1219
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.41617471382792764,
      "learning_rate": 2.71833746873841e-05,
      "loss": 2.1396,
      "step": 1220
    },
    {
      "epoch": 0.4884,
      "grad_norm": 0.45182805146696875,
      "learning_rate": 2.7151109063914277e-05,
      "loss": 2.2822,
      "step": 1221
    },
    {
      "epoch": 0.4888,
      "grad_norm": 0.4116570571092118,
      "learning_rate": 2.7118839830183218e-05,
      "loss": 2.1768,
      "step": 1222
    },
    {
      "epoch": 0.4892,
      "grad_norm": 0.3962893527001313,
      "learning_rate": 2.7086567040349193e-05,
      "loss": 2.1099,
      "step": 1223
    },
    {
      "epoch": 0.4896,
      "grad_norm": 0.4309877543937336,
      "learning_rate": 2.7054290748576445e-05,
      "loss": 2.186,
      "step": 1224
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.42744656383767965,
      "learning_rate": 2.7022011009035107e-05,
      "loss": 2.1519,
      "step": 1225
    },
    {
      "epoch": 0.4904,
      "grad_norm": 0.4451428462141731,
      "learning_rate": 2.6989727875901088e-05,
      "loss": 2.1685,
      "step": 1226
    },
    {
      "epoch": 0.4908,
      "grad_norm": 0.40987024768754027,
      "learning_rate": 2.6957441403355994e-05,
      "loss": 2.1172,
      "step": 1227
    },
    {
      "epoch": 0.4912,
      "grad_norm": 0.4557856941502725,
      "learning_rate": 2.692515164558704e-05,
      "loss": 2.2324,
      "step": 1228
    },
    {
      "epoch": 0.4916,
      "grad_norm": 0.4161629415475642,
      "learning_rate": 2.689285865678694e-05,
      "loss": 2.0527,
      "step": 1229
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.43396333245962543,
      "learning_rate": 2.686056249115385e-05,
      "loss": 2.188,
      "step": 1230
    },
    {
      "epoch": 0.4924,
      "grad_norm": 0.42048196525584175,
      "learning_rate": 2.6828263202891246e-05,
      "loss": 2.209,
      "step": 1231
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.4323095921160462,
      "learning_rate": 2.6795960846207852e-05,
      "loss": 2.1646,
      "step": 1232
    },
    {
      "epoch": 0.4932,
      "grad_norm": 0.42542745472860977,
      "learning_rate": 2.676365547531753e-05,
      "loss": 2.2065,
      "step": 1233
    },
    {
      "epoch": 0.4936,
      "grad_norm": 0.40890213732868946,
      "learning_rate": 2.673134714443921e-05,
      "loss": 2.1929,
      "step": 1234
    },
    {
      "epoch": 0.494,
      "grad_norm": 0.40949941524811595,
      "learning_rate": 2.6699035907796792e-05,
      "loss": 2.1196,
      "step": 1235
    },
    {
      "epoch": 0.4944,
      "grad_norm": 0.40375192998943554,
      "learning_rate": 2.6666721819619052e-05,
      "loss": 2.126,
      "step": 1236
    },
    {
      "epoch": 0.4948,
      "grad_norm": 0.4099305696807786,
      "learning_rate": 2.6634404934139547e-05,
      "loss": 2.1338,
      "step": 1237
    },
    {
      "epoch": 0.4952,
      "grad_norm": 0.41033693166815377,
      "learning_rate": 2.6602085305596514e-05,
      "loss": 2.1797,
      "step": 1238
    },
    {
      "epoch": 0.4956,
      "grad_norm": 0.4090343748118217,
      "learning_rate": 2.656976298823284e-05,
      "loss": 2.2231,
      "step": 1239
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.42204555494842716,
      "learning_rate": 2.6537438036295875e-05,
      "loss": 2.1772,
      "step": 1240
    },
    {
      "epoch": 0.4964,
      "grad_norm": 0.42424867531895327,
      "learning_rate": 2.6505110504037413e-05,
      "loss": 2.165,
      "step": 1241
    },
    {
      "epoch": 0.4968,
      "grad_norm": 0.40700673604850307,
      "learning_rate": 2.647278044571358e-05,
      "loss": 2.1699,
      "step": 1242
    },
    {
      "epoch": 0.4972,
      "grad_norm": 0.41758757295689575,
      "learning_rate": 2.6440447915584737e-05,
      "loss": 2.1465,
      "step": 1243
    },
    {
      "epoch": 0.4976,
      "grad_norm": 0.39953904394380013,
      "learning_rate": 2.64081129679154e-05,
      "loss": 2.1499,
      "step": 1244
    },
    {
      "epoch": 0.498,
      "grad_norm": 0.42216720484609627,
      "learning_rate": 2.6375775656974123e-05,
      "loss": 2.1172,
      "step": 1245
    },
    {
      "epoch": 0.4984,
      "grad_norm": 0.43223063704610953,
      "learning_rate": 2.6343436037033457e-05,
      "loss": 2.2202,
      "step": 1246
    },
    {
      "epoch": 0.4988,
      "grad_norm": 0.4037596696317042,
      "learning_rate": 2.6311094162369792e-05,
      "loss": 2.1797,
      "step": 1247
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.3886114293182725,
      "learning_rate": 2.627875008726335e-05,
      "loss": 2.0884,
      "step": 1248
    },
    {
      "epoch": 0.4996,
      "grad_norm": 0.41649914735465693,
      "learning_rate": 2.6246403865997983e-05,
      "loss": 2.1782,
      "step": 1249
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4142482715355453,
      "learning_rate": 2.621405555286121e-05,
      "loss": 2.1841,
      "step": 1250
    },
    {
      "epoch": 0.5004,
      "grad_norm": 0.4081320142459526,
      "learning_rate": 2.6181705202144014e-05,
      "loss": 2.1201,
      "step": 1251
    },
    {
      "epoch": 0.5008,
      "grad_norm": 0.43328985325982916,
      "learning_rate": 2.6149352868140815e-05,
      "loss": 2.1719,
      "step": 1252
    },
    {
      "epoch": 0.5012,
      "grad_norm": 0.42599713446827914,
      "learning_rate": 2.6116998605149372e-05,
      "loss": 2.0693,
      "step": 1253
    },
    {
      "epoch": 0.5016,
      "grad_norm": 0.4226415606255232,
      "learning_rate": 2.608464246747065e-05,
      "loss": 2.1919,
      "step": 1254
    },
    {
      "epoch": 0.502,
      "grad_norm": 0.413304835075756,
      "learning_rate": 2.6052284509408804e-05,
      "loss": 2.144,
      "step": 1255
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.45610084028207365,
      "learning_rate": 2.6019924785270998e-05,
      "loss": 2.1943,
      "step": 1256
    },
    {
      "epoch": 0.5028,
      "grad_norm": 0.4287341673051628,
      "learning_rate": 2.598756334936741e-05,
      "loss": 2.1719,
      "step": 1257
    },
    {
      "epoch": 0.5032,
      "grad_norm": 0.45556415735134237,
      "learning_rate": 2.595520025601104e-05,
      "loss": 2.1943,
      "step": 1258
    },
    {
      "epoch": 0.5036,
      "grad_norm": 0.40137069565669026,
      "learning_rate": 2.5922835559517704e-05,
      "loss": 2.0757,
      "step": 1259
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.4396489785912173,
      "learning_rate": 2.5890469314205897e-05,
      "loss": 2.1309,
      "step": 1260
    },
    {
      "epoch": 0.5044,
      "grad_norm": 0.4254487304887703,
      "learning_rate": 2.585810157439671e-05,
      "loss": 2.1675,
      "step": 1261
    },
    {
      "epoch": 0.5048,
      "grad_norm": 0.4356691665011649,
      "learning_rate": 2.5825732394413753e-05,
      "loss": 2.3062,
      "step": 1262
    },
    {
      "epoch": 0.5052,
      "grad_norm": 0.42598088066687456,
      "learning_rate": 2.579336182858304e-05,
      "loss": 2.0718,
      "step": 1263
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.4162040050441704,
      "learning_rate": 2.576098993123293e-05,
      "loss": 2.1753,
      "step": 1264
    },
    {
      "epoch": 0.506,
      "grad_norm": 0.434699008167416,
      "learning_rate": 2.5728616756693997e-05,
      "loss": 2.1953,
      "step": 1265
    },
    {
      "epoch": 0.5064,
      "grad_norm": 0.4305138339604619,
      "learning_rate": 2.569624235929896e-05,
      "loss": 2.2207,
      "step": 1266
    },
    {
      "epoch": 0.5068,
      "grad_norm": 0.41175075049440785,
      "learning_rate": 2.5663866793382602e-05,
      "loss": 2.1768,
      "step": 1267
    },
    {
      "epoch": 0.5072,
      "grad_norm": 0.41788970821707755,
      "learning_rate": 2.5631490113281664e-05,
      "loss": 2.1455,
      "step": 1268
    },
    {
      "epoch": 0.5076,
      "grad_norm": 0.4082860324949538,
      "learning_rate": 2.559911237333475e-05,
      "loss": 2.0273,
      "step": 1269
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.4336937687453073,
      "learning_rate": 2.556673362788225e-05,
      "loss": 2.2144,
      "step": 1270
    },
    {
      "epoch": 0.5084,
      "grad_norm": 0.41482833639646827,
      "learning_rate": 2.5534353931266242e-05,
      "loss": 2.106,
      "step": 1271
    },
    {
      "epoch": 0.5088,
      "grad_norm": 0.4136867988469553,
      "learning_rate": 2.5501973337830394e-05,
      "loss": 2.1279,
      "step": 1272
    },
    {
      "epoch": 0.5092,
      "grad_norm": 0.40471503571129475,
      "learning_rate": 2.5469591901919882e-05,
      "loss": 2.2065,
      "step": 1273
    },
    {
      "epoch": 0.5096,
      "grad_norm": 0.4111225676949338,
      "learning_rate": 2.543720967788129e-05,
      "loss": 2.1191,
      "step": 1274
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4153841512414083,
      "learning_rate": 2.540482672006254e-05,
      "loss": 2.1675,
      "step": 1275
    },
    {
      "epoch": 0.5104,
      "grad_norm": 0.41706870968421483,
      "learning_rate": 2.5372443082812774e-05,
      "loss": 2.1631,
      "step": 1276
    },
    {
      "epoch": 0.5108,
      "grad_norm": 0.4026097762464446,
      "learning_rate": 2.5340058820482276e-05,
      "loss": 2.1455,
      "step": 1277
    },
    {
      "epoch": 0.5112,
      "grad_norm": 0.40735967323649525,
      "learning_rate": 2.530767398742238e-05,
      "loss": 2.0522,
      "step": 1278
    },
    {
      "epoch": 0.5116,
      "grad_norm": 0.4252893387606506,
      "learning_rate": 2.527528863798539e-05,
      "loss": 2.2593,
      "step": 1279
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.4178151574429315,
      "learning_rate": 2.5242902826524434e-05,
      "loss": 2.209,
      "step": 1280
    },
    {
      "epoch": 0.5124,
      "grad_norm": 0.41822520633655785,
      "learning_rate": 2.521051660739348e-05,
      "loss": 2.2603,
      "step": 1281
    },
    {
      "epoch": 0.5128,
      "grad_norm": 0.41753335712781964,
      "learning_rate": 2.5178130034947127e-05,
      "loss": 2.1948,
      "step": 1282
    },
    {
      "epoch": 0.5132,
      "grad_norm": 0.42648049767101154,
      "learning_rate": 2.5145743163540585e-05,
      "loss": 2.1758,
      "step": 1283
    },
    {
      "epoch": 0.5136,
      "grad_norm": 0.422999420141783,
      "learning_rate": 2.511335604752958e-05,
      "loss": 2.1406,
      "step": 1284
    },
    {
      "epoch": 0.514,
      "grad_norm": 0.4068209214056748,
      "learning_rate": 2.5080968741270223e-05,
      "loss": 2.1133,
      "step": 1285
    },
    {
      "epoch": 0.5144,
      "grad_norm": 0.43998327199810855,
      "learning_rate": 2.5048581299118963e-05,
      "loss": 2.2026,
      "step": 1286
    },
    {
      "epoch": 0.5148,
      "grad_norm": 0.43570791978564755,
      "learning_rate": 2.5016193775432463e-05,
      "loss": 2.1724,
      "step": 1287
    },
    {
      "epoch": 0.5152,
      "grad_norm": 0.41508312765363314,
      "learning_rate": 2.498380622456754e-05,
      "loss": 2.0645,
      "step": 1288
    },
    {
      "epoch": 0.5156,
      "grad_norm": 0.39987695371340476,
      "learning_rate": 2.495141870088104e-05,
      "loss": 2.1016,
      "step": 1289
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.422812255381727,
      "learning_rate": 2.4919031258729786e-05,
      "loss": 2.041,
      "step": 1290
    },
    {
      "epoch": 0.5164,
      "grad_norm": 0.4268621235040712,
      "learning_rate": 2.488664395247043e-05,
      "loss": 2.1089,
      "step": 1291
    },
    {
      "epoch": 0.5168,
      "grad_norm": 0.401221082300085,
      "learning_rate": 2.4854256836459425e-05,
      "loss": 2.0884,
      "step": 1292
    },
    {
      "epoch": 0.5172,
      "grad_norm": 0.42503524026061945,
      "learning_rate": 2.482186996505288e-05,
      "loss": 2.228,
      "step": 1293
    },
    {
      "epoch": 0.5176,
      "grad_norm": 0.4176892332375514,
      "learning_rate": 2.4789483392606524e-05,
      "loss": 2.168,
      "step": 1294
    },
    {
      "epoch": 0.518,
      "grad_norm": 0.4110844557365147,
      "learning_rate": 2.4757097173475572e-05,
      "loss": 2.1875,
      "step": 1295
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.4285936037462358,
      "learning_rate": 2.4724711362014625e-05,
      "loss": 2.2173,
      "step": 1296
    },
    {
      "epoch": 0.5188,
      "grad_norm": 0.4234123301955325,
      "learning_rate": 2.4692326012577618e-05,
      "loss": 2.1533,
      "step": 1297
    },
    {
      "epoch": 0.5192,
      "grad_norm": 0.4123000212061202,
      "learning_rate": 2.4659941179517723e-05,
      "loss": 2.1899,
      "step": 1298
    },
    {
      "epoch": 0.5196,
      "grad_norm": 0.41207987336033425,
      "learning_rate": 2.4627556917187232e-05,
      "loss": 2.166,
      "step": 1299
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.40681561587212034,
      "learning_rate": 2.4595173279937464e-05,
      "loss": 2.2417,
      "step": 1300
    },
    {
      "epoch": 0.5204,
      "grad_norm": 0.40244137139468655,
      "learning_rate": 2.456279032211872e-05,
      "loss": 2.2114,
      "step": 1301
    },
    {
      "epoch": 0.5208,
      "grad_norm": 0.41094205447057147,
      "learning_rate": 2.4530408098080127e-05,
      "loss": 2.1177,
      "step": 1302
    },
    {
      "epoch": 0.5212,
      "grad_norm": 0.4059381978742116,
      "learning_rate": 2.449802666216961e-05,
      "loss": 2.2051,
      "step": 1303
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.40456072849759833,
      "learning_rate": 2.4465646068733763e-05,
      "loss": 2.168,
      "step": 1304
    },
    {
      "epoch": 0.522,
      "grad_norm": 0.40045702987972615,
      "learning_rate": 2.443326637211775e-05,
      "loss": 2.0977,
      "step": 1305
    },
    {
      "epoch": 0.5224,
      "grad_norm": 0.39978681771482133,
      "learning_rate": 2.4400887626665254e-05,
      "loss": 2.1841,
      "step": 1306
    },
    {
      "epoch": 0.5228,
      "grad_norm": 0.4052627988301322,
      "learning_rate": 2.4368509886718335e-05,
      "loss": 2.0757,
      "step": 1307
    },
    {
      "epoch": 0.5232,
      "grad_norm": 0.4230414441767353,
      "learning_rate": 2.4336133206617403e-05,
      "loss": 2.2178,
      "step": 1308
    },
    {
      "epoch": 0.5236,
      "grad_norm": 0.40716156002352843,
      "learning_rate": 2.4303757640701046e-05,
      "loss": 2.1899,
      "step": 1309
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.44312503700104267,
      "learning_rate": 2.4271383243306016e-05,
      "loss": 2.1802,
      "step": 1310
    },
    {
      "epoch": 0.5244,
      "grad_norm": 0.4086603123488376,
      "learning_rate": 2.423901006876707e-05,
      "loss": 2.1758,
      "step": 1311
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.42211952321203966,
      "learning_rate": 2.4206638171416958e-05,
      "loss": 2.1333,
      "step": 1312
    },
    {
      "epoch": 0.5252,
      "grad_norm": 0.41248949928945233,
      "learning_rate": 2.4174267605586253e-05,
      "loss": 2.1465,
      "step": 1313
    },
    {
      "epoch": 0.5256,
      "grad_norm": 0.4143644949652912,
      "learning_rate": 2.4141898425603296e-05,
      "loss": 2.2188,
      "step": 1314
    },
    {
      "epoch": 0.526,
      "grad_norm": 0.41344367267904875,
      "learning_rate": 2.410953068579411e-05,
      "loss": 2.0811,
      "step": 1315
    },
    {
      "epoch": 0.5264,
      "grad_norm": 0.3936601766850907,
      "learning_rate": 2.4077164440482295e-05,
      "loss": 2.0693,
      "step": 1316
    },
    {
      "epoch": 0.5268,
      "grad_norm": 0.40188216393494586,
      "learning_rate": 2.4044799743988965e-05,
      "loss": 2.1338,
      "step": 1317
    },
    {
      "epoch": 0.5272,
      "grad_norm": 0.40686680626003235,
      "learning_rate": 2.4012436650632593e-05,
      "loss": 2.0986,
      "step": 1318
    },
    {
      "epoch": 0.5276,
      "grad_norm": 0.4435587100651973,
      "learning_rate": 2.3980075214729004e-05,
      "loss": 2.1787,
      "step": 1319
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.4151332483576592,
      "learning_rate": 2.3947715490591206e-05,
      "loss": 2.1782,
      "step": 1320
    },
    {
      "epoch": 0.5284,
      "grad_norm": 0.4029604567417803,
      "learning_rate": 2.391535753252935e-05,
      "loss": 2.1899,
      "step": 1321
    },
    {
      "epoch": 0.5288,
      "grad_norm": 0.3948527638695523,
      "learning_rate": 2.3883001394850633e-05,
      "loss": 2.1499,
      "step": 1322
    },
    {
      "epoch": 0.5292,
      "grad_norm": 0.40289565850035114,
      "learning_rate": 2.385064713185919e-05,
      "loss": 2.1006,
      "step": 1323
    },
    {
      "epoch": 0.5296,
      "grad_norm": 0.39829780985015617,
      "learning_rate": 2.3818294797855995e-05,
      "loss": 2.1475,
      "step": 1324
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.39094087542042794,
      "learning_rate": 2.3785944447138802e-05,
      "loss": 2.1416,
      "step": 1325
    },
    {
      "epoch": 0.5304,
      "grad_norm": 0.3900097176265404,
      "learning_rate": 2.3753596134002016e-05,
      "loss": 2.1758,
      "step": 1326
    },
    {
      "epoch": 0.5308,
      "grad_norm": 0.39766033560867087,
      "learning_rate": 2.372124991273666e-05,
      "loss": 2.0811,
      "step": 1327
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.3998105749399994,
      "learning_rate": 2.3688905837630214e-05,
      "loss": 2.1001,
      "step": 1328
    },
    {
      "epoch": 0.5316,
      "grad_norm": 0.41567821002224475,
      "learning_rate": 2.3656563962966555e-05,
      "loss": 2.2134,
      "step": 1329
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.40601015494761944,
      "learning_rate": 2.362422434302588e-05,
      "loss": 2.1377,
      "step": 1330
    },
    {
      "epoch": 0.5324,
      "grad_norm": 0.4058785878566212,
      "learning_rate": 2.3591887032084607e-05,
      "loss": 2.1904,
      "step": 1331
    },
    {
      "epoch": 0.5328,
      "grad_norm": 0.4060393419700488,
      "learning_rate": 2.355955208441527e-05,
      "loss": 2.0918,
      "step": 1332
    },
    {
      "epoch": 0.5332,
      "grad_norm": 0.42456914089018694,
      "learning_rate": 2.3527219554286427e-05,
      "loss": 2.2305,
      "step": 1333
    },
    {
      "epoch": 0.5336,
      "grad_norm": 0.4111173551641906,
      "learning_rate": 2.34948894959626e-05,
      "loss": 2.166,
      "step": 1334
    },
    {
      "epoch": 0.534,
      "grad_norm": 0.42344029619424933,
      "learning_rate": 2.3462561963704134e-05,
      "loss": 2.1313,
      "step": 1335
    },
    {
      "epoch": 0.5344,
      "grad_norm": 0.4188508331463883,
      "learning_rate": 2.3430237011767167e-05,
      "loss": 2.1411,
      "step": 1336
    },
    {
      "epoch": 0.5348,
      "grad_norm": 0.4304922489228515,
      "learning_rate": 2.3397914694403492e-05,
      "loss": 2.1792,
      "step": 1337
    },
    {
      "epoch": 0.5352,
      "grad_norm": 0.4077861721792693,
      "learning_rate": 2.3365595065860466e-05,
      "loss": 2.0869,
      "step": 1338
    },
    {
      "epoch": 0.5356,
      "grad_norm": 0.3952935610957796,
      "learning_rate": 2.3333278180380964e-05,
      "loss": 2.2437,
      "step": 1339
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.40463384637838645,
      "learning_rate": 2.3300964092203207e-05,
      "loss": 2.103,
      "step": 1340
    },
    {
      "epoch": 0.5364,
      "grad_norm": 0.4180109827400462,
      "learning_rate": 2.3268652855560795e-05,
      "loss": 2.2334,
      "step": 1341
    },
    {
      "epoch": 0.5368,
      "grad_norm": 0.4023099966357927,
      "learning_rate": 2.3236344524682477e-05,
      "loss": 2.1963,
      "step": 1342
    },
    {
      "epoch": 0.5372,
      "grad_norm": 0.407607405900493,
      "learning_rate": 2.320403915379216e-05,
      "loss": 2.144,
      "step": 1343
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.39886202969030876,
      "learning_rate": 2.3171736797108756e-05,
      "loss": 2.2041,
      "step": 1344
    },
    {
      "epoch": 0.538,
      "grad_norm": 0.39965384815259125,
      "learning_rate": 2.3139437508846155e-05,
      "loss": 2.1519,
      "step": 1345
    },
    {
      "epoch": 0.5384,
      "grad_norm": 0.3953709842875128,
      "learning_rate": 2.3107141343213068e-05,
      "loss": 2.0469,
      "step": 1346
    },
    {
      "epoch": 0.5388,
      "grad_norm": 0.4295130783148389,
      "learning_rate": 2.307484835441297e-05,
      "loss": 2.2339,
      "step": 1347
    },
    {
      "epoch": 0.5392,
      "grad_norm": 0.4005913968671486,
      "learning_rate": 2.304255859664401e-05,
      "loss": 2.1831,
      "step": 1348
    },
    {
      "epoch": 0.5396,
      "grad_norm": 0.42458506994695283,
      "learning_rate": 2.301027212409891e-05,
      "loss": 2.1982,
      "step": 1349
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3906704010404515,
      "learning_rate": 2.29779889909649e-05,
      "loss": 2.0449,
      "step": 1350
    },
    {
      "epoch": 0.5404,
      "grad_norm": 0.4146903363325969,
      "learning_rate": 2.294570925142356e-05,
      "loss": 2.2119,
      "step": 1351
    },
    {
      "epoch": 0.5408,
      "grad_norm": 0.4030456641690356,
      "learning_rate": 2.291343295965082e-05,
      "loss": 2.1162,
      "step": 1352
    },
    {
      "epoch": 0.5412,
      "grad_norm": 0.39566595020090106,
      "learning_rate": 2.288116016981679e-05,
      "loss": 2.1421,
      "step": 1353
    },
    {
      "epoch": 0.5416,
      "grad_norm": 0.42176306037849204,
      "learning_rate": 2.284889093608572e-05,
      "loss": 2.1904,
      "step": 1354
    },
    {
      "epoch": 0.542,
      "grad_norm": 0.4044864371143259,
      "learning_rate": 2.2816625312615903e-05,
      "loss": 2.0986,
      "step": 1355
    },
    {
      "epoch": 0.5424,
      "grad_norm": 0.41149752657113187,
      "learning_rate": 2.2784363353559542e-05,
      "loss": 2.1572,
      "step": 1356
    },
    {
      "epoch": 0.5428,
      "grad_norm": 0.4033086767424624,
      "learning_rate": 2.275210511306271e-05,
      "loss": 2.0649,
      "step": 1357
    },
    {
      "epoch": 0.5432,
      "grad_norm": 0.41081328863653466,
      "learning_rate": 2.2719850645265233e-05,
      "loss": 2.0728,
      "step": 1358
    },
    {
      "epoch": 0.5436,
      "grad_norm": 0.40900118831732907,
      "learning_rate": 2.268760000430062e-05,
      "loss": 2.2148,
      "step": 1359
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.4197148044022323,
      "learning_rate": 2.2655353244295928e-05,
      "loss": 2.1558,
      "step": 1360
    },
    {
      "epoch": 0.5444,
      "grad_norm": 0.41600780532866904,
      "learning_rate": 2.2623110419371736e-05,
      "loss": 2.0874,
      "step": 1361
    },
    {
      "epoch": 0.5448,
      "grad_norm": 0.39895865669840047,
      "learning_rate": 2.259087158364198e-05,
      "loss": 2.1094,
      "step": 1362
    },
    {
      "epoch": 0.5452,
      "grad_norm": 0.40374440127866407,
      "learning_rate": 2.2558636791213926e-05,
      "loss": 2.126,
      "step": 1363
    },
    {
      "epoch": 0.5456,
      "grad_norm": 0.40397661434896115,
      "learning_rate": 2.2526406096188063e-05,
      "loss": 2.127,
      "step": 1364
    },
    {
      "epoch": 0.546,
      "grad_norm": 0.4065213465483498,
      "learning_rate": 2.2494179552657978e-05,
      "loss": 2.1465,
      "step": 1365
    },
    {
      "epoch": 0.5464,
      "grad_norm": 0.4022618322692252,
      "learning_rate": 2.2461957214710298e-05,
      "loss": 2.1235,
      "step": 1366
    },
    {
      "epoch": 0.5468,
      "grad_norm": 0.4043788514623052,
      "learning_rate": 2.2429739136424603e-05,
      "loss": 2.1729,
      "step": 1367
    },
    {
      "epoch": 0.5472,
      "grad_norm": 0.4003406260307868,
      "learning_rate": 2.2397525371873307e-05,
      "loss": 2.0376,
      "step": 1368
    },
    {
      "epoch": 0.5476,
      "grad_norm": 0.39765953648571745,
      "learning_rate": 2.23653159751216e-05,
      "loss": 2.1938,
      "step": 1369
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.41171644792012857,
      "learning_rate": 2.2333111000227342e-05,
      "loss": 2.1216,
      "step": 1370
    },
    {
      "epoch": 0.5484,
      "grad_norm": 0.3969831478966996,
      "learning_rate": 2.2300910501240948e-05,
      "loss": 2.1548,
      "step": 1371
    },
    {
      "epoch": 0.5488,
      "grad_norm": 0.3959234227237347,
      "learning_rate": 2.2268714532205343e-05,
      "loss": 2.123,
      "step": 1372
    },
    {
      "epoch": 0.5492,
      "grad_norm": 0.42131183869189953,
      "learning_rate": 2.2236523147155846e-05,
      "loss": 2.2637,
      "step": 1373
    },
    {
      "epoch": 0.5496,
      "grad_norm": 0.41330007926163237,
      "learning_rate": 2.220433640012009e-05,
      "loss": 2.1123,
      "step": 1374
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.42345679131720243,
      "learning_rate": 2.2172154345117894e-05,
      "loss": 2.1235,
      "step": 1375
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.4058501448591144,
      "learning_rate": 2.213997703616124e-05,
      "loss": 2.1045,
      "step": 1376
    },
    {
      "epoch": 0.5508,
      "grad_norm": 0.4078683409729499,
      "learning_rate": 2.2107804527254106e-05,
      "loss": 2.1865,
      "step": 1377
    },
    {
      "epoch": 0.5512,
      "grad_norm": 0.42114174355195955,
      "learning_rate": 2.2075636872392454e-05,
      "loss": 2.168,
      "step": 1378
    },
    {
      "epoch": 0.5516,
      "grad_norm": 0.41031754262828213,
      "learning_rate": 2.2043474125564078e-05,
      "loss": 2.2173,
      "step": 1379
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.41488167219649136,
      "learning_rate": 2.201131634074853e-05,
      "loss": 2.2031,
      "step": 1380
    },
    {
      "epoch": 0.5524,
      "grad_norm": 0.40934873995251314,
      "learning_rate": 2.1979163571917046e-05,
      "loss": 2.1279,
      "step": 1381
    },
    {
      "epoch": 0.5528,
      "grad_norm": 0.4091781907614845,
      "learning_rate": 2.194701587303242e-05,
      "loss": 2.1436,
      "step": 1382
    },
    {
      "epoch": 0.5532,
      "grad_norm": 0.40159027692888477,
      "learning_rate": 2.191487329804899e-05,
      "loss": 2.1367,
      "step": 1383
    },
    {
      "epoch": 0.5536,
      "grad_norm": 0.41171653847202166,
      "learning_rate": 2.188273590091243e-05,
      "loss": 2.1055,
      "step": 1384
    },
    {
      "epoch": 0.554,
      "grad_norm": 0.4108092140146634,
      "learning_rate": 2.1850603735559778e-05,
      "loss": 2.0132,
      "step": 1385
    },
    {
      "epoch": 0.5544,
      "grad_norm": 0.4092337582636399,
      "learning_rate": 2.1818476855919247e-05,
      "loss": 2.189,
      "step": 1386
    },
    {
      "epoch": 0.5548,
      "grad_norm": 0.4000043325764934,
      "learning_rate": 2.1786355315910196e-05,
      "loss": 2.1797,
      "step": 1387
    },
    {
      "epoch": 0.5552,
      "grad_norm": 0.42190462600693407,
      "learning_rate": 2.1754239169443052e-05,
      "loss": 2.2217,
      "step": 1388
    },
    {
      "epoch": 0.5556,
      "grad_norm": 0.3896477279633234,
      "learning_rate": 2.172212847041914e-05,
      "loss": 2.085,
      "step": 1389
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.4298694670491417,
      "learning_rate": 2.169002327273068e-05,
      "loss": 2.0762,
      "step": 1390
    },
    {
      "epoch": 0.5564,
      "grad_norm": 0.41420618811502213,
      "learning_rate": 2.165792363026062e-05,
      "loss": 2.1631,
      "step": 1391
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.41062041479225536,
      "learning_rate": 2.1625829596882642e-05,
      "loss": 2.2158,
      "step": 1392
    },
    {
      "epoch": 0.5572,
      "grad_norm": 0.4102647571761048,
      "learning_rate": 2.1593741226460962e-05,
      "loss": 2.0762,
      "step": 1393
    },
    {
      "epoch": 0.5576,
      "grad_norm": 0.4263075110580088,
      "learning_rate": 2.156165857285032e-05,
      "loss": 2.2222,
      "step": 1394
    },
    {
      "epoch": 0.558,
      "grad_norm": 0.4034007451266944,
      "learning_rate": 2.152958168989584e-05,
      "loss": 2.1763,
      "step": 1395
    },
    {
      "epoch": 0.5584,
      "grad_norm": 0.41756419080503104,
      "learning_rate": 2.1497510631432975e-05,
      "loss": 2.1924,
      "step": 1396
    },
    {
      "epoch": 0.5588,
      "grad_norm": 0.4124476002940089,
      "learning_rate": 2.146544545128742e-05,
      "loss": 2.1812,
      "step": 1397
    },
    {
      "epoch": 0.5592,
      "grad_norm": 0.4149008916823803,
      "learning_rate": 2.1433386203274964e-05,
      "loss": 2.1162,
      "step": 1398
    },
    {
      "epoch": 0.5596,
      "grad_norm": 0.4197543669843657,
      "learning_rate": 2.1401332941201468e-05,
      "loss": 2.1724,
      "step": 1399
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4161860379704833,
      "learning_rate": 2.136928571886275e-05,
      "loss": 2.1602,
      "step": 1400
    },
    {
      "epoch": 0.5604,
      "grad_norm": 0.39975974459779534,
      "learning_rate": 2.133724459004446e-05,
      "loss": 2.1611,
      "step": 1401
    },
    {
      "epoch": 0.5608,
      "grad_norm": 0.4187100133993347,
      "learning_rate": 2.1305209608522058e-05,
      "loss": 2.1401,
      "step": 1402
    },
    {
      "epoch": 0.5612,
      "grad_norm": 0.41119394896011136,
      "learning_rate": 2.1273180828060673e-05,
      "loss": 2.0864,
      "step": 1403
    },
    {
      "epoch": 0.5616,
      "grad_norm": 0.4108574311580412,
      "learning_rate": 2.1241158302415012e-05,
      "loss": 2.0547,
      "step": 1404
    },
    {
      "epoch": 0.562,
      "grad_norm": 0.4065517025559642,
      "learning_rate": 2.12091420853293e-05,
      "loss": 2.1226,
      "step": 1405
    },
    {
      "epoch": 0.5624,
      "grad_norm": 0.44354769316421183,
      "learning_rate": 2.1177132230537186e-05,
      "loss": 2.1294,
      "step": 1406
    },
    {
      "epoch": 0.5628,
      "grad_norm": 0.39027534261455477,
      "learning_rate": 2.114512879176161e-05,
      "loss": 2.0664,
      "step": 1407
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.43285735337212955,
      "learning_rate": 2.1113131822714764e-05,
      "loss": 2.1279,
      "step": 1408
    },
    {
      "epoch": 0.5636,
      "grad_norm": 0.4024892681922905,
      "learning_rate": 2.1081141377097987e-05,
      "loss": 2.1636,
      "step": 1409
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.4117956873379093,
      "learning_rate": 2.1049157508601642e-05,
      "loss": 2.2349,
      "step": 1410
    },
    {
      "epoch": 0.5644,
      "grad_norm": 0.42684182423424544,
      "learning_rate": 2.1017180270905085e-05,
      "loss": 2.1455,
      "step": 1411
    },
    {
      "epoch": 0.5648,
      "grad_norm": 0.3968701744938292,
      "learning_rate": 2.0985209717676534e-05,
      "loss": 2.1396,
      "step": 1412
    },
    {
      "epoch": 0.5652,
      "grad_norm": 0.40627514572154844,
      "learning_rate": 2.0953245902572973e-05,
      "loss": 2.1963,
      "step": 1413
    },
    {
      "epoch": 0.5656,
      "grad_norm": 0.40001845832903393,
      "learning_rate": 2.09212888792401e-05,
      "loss": 2.0884,
      "step": 1414
    },
    {
      "epoch": 0.566,
      "grad_norm": 0.3982709526719194,
      "learning_rate": 2.0889338701312185e-05,
      "loss": 2.1436,
      "step": 1415
    },
    {
      "epoch": 0.5664,
      "grad_norm": 0.3932216785256299,
      "learning_rate": 2.0857395422412042e-05,
      "loss": 2.1157,
      "step": 1416
    },
    {
      "epoch": 0.5668,
      "grad_norm": 0.40094162057530813,
      "learning_rate": 2.082545909615089e-05,
      "loss": 2.104,
      "step": 1417
    },
    {
      "epoch": 0.5672,
      "grad_norm": 0.404100516103502,
      "learning_rate": 2.0793529776128283e-05,
      "loss": 2.0874,
      "step": 1418
    },
    {
      "epoch": 0.5676,
      "grad_norm": 0.4114072709826392,
      "learning_rate": 2.0761607515931994e-05,
      "loss": 2.1338,
      "step": 1419
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.38900029502784156,
      "learning_rate": 2.072969236913799e-05,
      "loss": 2.0762,
      "step": 1420
    },
    {
      "epoch": 0.5684,
      "grad_norm": 0.39841273613586314,
      "learning_rate": 2.0697784389310278e-05,
      "loss": 2.1196,
      "step": 1421
    },
    {
      "epoch": 0.5688,
      "grad_norm": 0.43260318130244296,
      "learning_rate": 2.0665883630000814e-05,
      "loss": 2.186,
      "step": 1422
    },
    {
      "epoch": 0.5692,
      "grad_norm": 0.39704884033174165,
      "learning_rate": 2.0633990144749473e-05,
      "loss": 2.1187,
      "step": 1423
    },
    {
      "epoch": 0.5696,
      "grad_norm": 0.4089841500902978,
      "learning_rate": 2.0602103987083884e-05,
      "loss": 2.1709,
      "step": 1424
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4094621775333073,
      "learning_rate": 2.0570225210519434e-05,
      "loss": 2.2056,
      "step": 1425
    },
    {
      "epoch": 0.5704,
      "grad_norm": 0.4160767233045228,
      "learning_rate": 2.053835386855906e-05,
      "loss": 2.1636,
      "step": 1426
    },
    {
      "epoch": 0.5708,
      "grad_norm": 0.4128987937379764,
      "learning_rate": 2.0506490014693264e-05,
      "loss": 2.104,
      "step": 1427
    },
    {
      "epoch": 0.5712,
      "grad_norm": 0.39929254169971495,
      "learning_rate": 2.0474633702399953e-05,
      "loss": 2.1519,
      "step": 1428
    },
    {
      "epoch": 0.5716,
      "grad_norm": 0.3991871112258309,
      "learning_rate": 2.0442784985144386e-05,
      "loss": 2.1094,
      "step": 1429
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.399884228752088,
      "learning_rate": 2.04109439163791e-05,
      "loss": 2.1455,
      "step": 1430
    },
    {
      "epoch": 0.5724,
      "grad_norm": 0.40532790539453967,
      "learning_rate": 2.037911054954375e-05,
      "loss": 2.2329,
      "step": 1431
    },
    {
      "epoch": 0.5728,
      "grad_norm": 0.40424261234399017,
      "learning_rate": 2.034728493806511e-05,
      "loss": 2.1978,
      "step": 1432
    },
    {
      "epoch": 0.5732,
      "grad_norm": 0.3890466039254192,
      "learning_rate": 2.031546713535688e-05,
      "loss": 2.1528,
      "step": 1433
    },
    {
      "epoch": 0.5736,
      "grad_norm": 0.4055341709113926,
      "learning_rate": 2.0283657194819732e-05,
      "loss": 2.0933,
      "step": 1434
    },
    {
      "epoch": 0.574,
      "grad_norm": 0.40598497165901704,
      "learning_rate": 2.025185516984108e-05,
      "loss": 2.1631,
      "step": 1435
    },
    {
      "epoch": 0.5744,
      "grad_norm": 0.5353149888950637,
      "learning_rate": 2.022006111379508e-05,
      "loss": 2.1406,
      "step": 1436
    },
    {
      "epoch": 0.5748,
      "grad_norm": 0.4130680295168911,
      "learning_rate": 2.01882750800425e-05,
      "loss": 2.126,
      "step": 1437
    },
    {
      "epoch": 0.5752,
      "grad_norm": 0.38978108912821385,
      "learning_rate": 2.015649712193065e-05,
      "loss": 2.1211,
      "step": 1438
    },
    {
      "epoch": 0.5756,
      "grad_norm": 0.40175936300595216,
      "learning_rate": 2.0124727292793304e-05,
      "loss": 2.1274,
      "step": 1439
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.40471110952726397,
      "learning_rate": 2.0092965645950564e-05,
      "loss": 2.1924,
      "step": 1440
    },
    {
      "epoch": 0.5764,
      "grad_norm": 0.3964534290099444,
      "learning_rate": 2.006121223470882e-05,
      "loss": 2.0918,
      "step": 1441
    },
    {
      "epoch": 0.5768,
      "grad_norm": 0.4043101138669204,
      "learning_rate": 2.0029467112360626e-05,
      "loss": 2.0806,
      "step": 1442
    },
    {
      "epoch": 0.5772,
      "grad_norm": 0.39742658288717614,
      "learning_rate": 1.9997730332184626e-05,
      "loss": 2.2251,
      "step": 1443
    },
    {
      "epoch": 0.5776,
      "grad_norm": 0.39223830672119997,
      "learning_rate": 1.9966001947445482e-05,
      "loss": 2.084,
      "step": 1444
    },
    {
      "epoch": 0.578,
      "grad_norm": 0.4152752505555652,
      "learning_rate": 1.9934282011393753e-05,
      "loss": 2.2173,
      "step": 1445
    },
    {
      "epoch": 0.5784,
      "grad_norm": 0.4036679924413976,
      "learning_rate": 1.99025705772658e-05,
      "loss": 2.1689,
      "step": 1446
    },
    {
      "epoch": 0.5788,
      "grad_norm": 0.41877305548256527,
      "learning_rate": 1.9870867698283736e-05,
      "loss": 2.1201,
      "step": 1447
    },
    {
      "epoch": 0.5792,
      "grad_norm": 0.4027886092842061,
      "learning_rate": 1.983917342765533e-05,
      "loss": 2.1948,
      "step": 1448
    },
    {
      "epoch": 0.5796,
      "grad_norm": 0.4149884266916173,
      "learning_rate": 1.980748781857387e-05,
      "loss": 2.2202,
      "step": 1449
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.41834919306751567,
      "learning_rate": 1.9775810924218125e-05,
      "loss": 2.1514,
      "step": 1450
    },
    {
      "epoch": 0.5804,
      "grad_norm": 0.4039277687222689,
      "learning_rate": 1.974414279775224e-05,
      "loss": 2.0444,
      "step": 1451
    },
    {
      "epoch": 0.5808,
      "grad_norm": 0.4083643803159104,
      "learning_rate": 1.9712483492325624e-05,
      "loss": 2.0991,
      "step": 1452
    },
    {
      "epoch": 0.5812,
      "grad_norm": 0.4175989281989645,
      "learning_rate": 1.968083306107292e-05,
      "loss": 2.1792,
      "step": 1453
    },
    {
      "epoch": 0.5816,
      "grad_norm": 0.4118244909216569,
      "learning_rate": 1.9649191557113837e-05,
      "loss": 2.0894,
      "step": 1454
    },
    {
      "epoch": 0.582,
      "grad_norm": 0.39294177782338047,
      "learning_rate": 1.9617559033553128e-05,
      "loss": 1.978,
      "step": 1455
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.39918555450429105,
      "learning_rate": 1.958593554348047e-05,
      "loss": 2.166,
      "step": 1456
    },
    {
      "epoch": 0.5828,
      "grad_norm": 0.4084487292179339,
      "learning_rate": 1.955432113997035e-05,
      "loss": 2.1377,
      "step": 1457
    },
    {
      "epoch": 0.5832,
      "grad_norm": 0.3934743718165702,
      "learning_rate": 1.9522715876082047e-05,
      "loss": 2.0337,
      "step": 1458
    },
    {
      "epoch": 0.5836,
      "grad_norm": 0.3948072510042328,
      "learning_rate": 1.949111980485948e-05,
      "loss": 2.1089,
      "step": 1459
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.403716756422066,
      "learning_rate": 1.945953297933115e-05,
      "loss": 2.1328,
      "step": 1460
    },
    {
      "epoch": 0.5844,
      "grad_norm": 0.39531825312676,
      "learning_rate": 1.9427955452510013e-05,
      "loss": 2.167,
      "step": 1461
    },
    {
      "epoch": 0.5848,
      "grad_norm": 0.39119441162419305,
      "learning_rate": 1.9396387277393445e-05,
      "loss": 2.1875,
      "step": 1462
    },
    {
      "epoch": 0.5852,
      "grad_norm": 0.387697700556707,
      "learning_rate": 1.936482850696313e-05,
      "loss": 2.1343,
      "step": 1463
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.39901592250310064,
      "learning_rate": 1.933327919418495e-05,
      "loss": 2.2056,
      "step": 1464
    },
    {
      "epoch": 0.586,
      "grad_norm": 0.41541167666471324,
      "learning_rate": 1.9301739392008923e-05,
      "loss": 2.126,
      "step": 1465
    },
    {
      "epoch": 0.5864,
      "grad_norm": 0.3966054189502813,
      "learning_rate": 1.9270209153369093e-05,
      "loss": 2.1382,
      "step": 1466
    },
    {
      "epoch": 0.5868,
      "grad_norm": 0.41416034952676617,
      "learning_rate": 1.923868853118348e-05,
      "loss": 2.2856,
      "step": 1467
    },
    {
      "epoch": 0.5872,
      "grad_norm": 0.3933703425271238,
      "learning_rate": 1.9207177578353946e-05,
      "loss": 2.1685,
      "step": 1468
    },
    {
      "epoch": 0.5876,
      "grad_norm": 0.38560710622105776,
      "learning_rate": 1.917567634776613e-05,
      "loss": 2.0566,
      "step": 1469
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.4101731131382983,
      "learning_rate": 1.9144184892289337e-05,
      "loss": 2.1396,
      "step": 1470
    },
    {
      "epoch": 0.5884,
      "grad_norm": 0.40051632137304616,
      "learning_rate": 1.9112703264776488e-05,
      "loss": 2.0664,
      "step": 1471
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.3873820494244266,
      "learning_rate": 1.908123151806401e-05,
      "loss": 2.0562,
      "step": 1472
    },
    {
      "epoch": 0.5892,
      "grad_norm": 0.4155098999112596,
      "learning_rate": 1.904976970497173e-05,
      "loss": 2.1211,
      "step": 1473
    },
    {
      "epoch": 0.5896,
      "grad_norm": 0.4133982469038989,
      "learning_rate": 1.9018317878302815e-05,
      "loss": 2.1821,
      "step": 1474
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4033118766385781,
      "learning_rate": 1.8986876090843667e-05,
      "loss": 2.2275,
      "step": 1475
    },
    {
      "epoch": 0.5904,
      "grad_norm": 0.4248880474151793,
      "learning_rate": 1.895544439536383e-05,
      "loss": 2.0762,
      "step": 1476
    },
    {
      "epoch": 0.5908,
      "grad_norm": 0.4046665731401488,
      "learning_rate": 1.892402284461594e-05,
      "loss": 2.0986,
      "step": 1477
    },
    {
      "epoch": 0.5912,
      "grad_norm": 0.41679255603843995,
      "learning_rate": 1.8892611491335586e-05,
      "loss": 2.2075,
      "step": 1478
    },
    {
      "epoch": 0.5916,
      "grad_norm": 0.3960843269240198,
      "learning_rate": 1.886121038824123e-05,
      "loss": 2.1914,
      "step": 1479
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.3969832978722455,
      "learning_rate": 1.882981958803414e-05,
      "loss": 2.1118,
      "step": 1480
    },
    {
      "epoch": 0.5924,
      "grad_norm": 0.38551470380712366,
      "learning_rate": 1.8798439143398327e-05,
      "loss": 2.1362,
      "step": 1481
    },
    {
      "epoch": 0.5928,
      "grad_norm": 0.4121913398875121,
      "learning_rate": 1.8767069107000364e-05,
      "loss": 2.1318,
      "step": 1482
    },
    {
      "epoch": 0.5932,
      "grad_norm": 0.39051688767019976,
      "learning_rate": 1.8735709531489402e-05,
      "loss": 2.1187,
      "step": 1483
    },
    {
      "epoch": 0.5936,
      "grad_norm": 0.3900201113673113,
      "learning_rate": 1.8704360469497e-05,
      "loss": 2.0156,
      "step": 1484
    },
    {
      "epoch": 0.594,
      "grad_norm": 0.43122760974575275,
      "learning_rate": 1.8673021973637095e-05,
      "loss": 2.1919,
      "step": 1485
    },
    {
      "epoch": 0.5944,
      "grad_norm": 0.39081239357190173,
      "learning_rate": 1.8641694096505887e-05,
      "loss": 2.1875,
      "step": 1486
    },
    {
      "epoch": 0.5948,
      "grad_norm": 0.39849851858763446,
      "learning_rate": 1.861037689068176e-05,
      "loss": 2.0806,
      "step": 1487
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.40210517439658444,
      "learning_rate": 1.8579070408725165e-05,
      "loss": 2.1084,
      "step": 1488
    },
    {
      "epoch": 0.5956,
      "grad_norm": 0.4099452366058703,
      "learning_rate": 1.854777470317858e-05,
      "loss": 2.1499,
      "step": 1489
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.42359162686346363,
      "learning_rate": 1.8516489826566376e-05,
      "loss": 2.2153,
      "step": 1490
    },
    {
      "epoch": 0.5964,
      "grad_norm": 0.4148270769206577,
      "learning_rate": 1.8485215831394766e-05,
      "loss": 2.1626,
      "step": 1491
    },
    {
      "epoch": 0.5968,
      "grad_norm": 0.3908563558516389,
      "learning_rate": 1.84539527701517e-05,
      "loss": 2.0952,
      "step": 1492
    },
    {
      "epoch": 0.5972,
      "grad_norm": 0.4020882137118851,
      "learning_rate": 1.8422700695306763e-05,
      "loss": 2.2285,
      "step": 1493
    },
    {
      "epoch": 0.5976,
      "grad_norm": 0.42200007027228637,
      "learning_rate": 1.8391459659311106e-05,
      "loss": 2.1299,
      "step": 1494
    },
    {
      "epoch": 0.598,
      "grad_norm": 0.38759116493390217,
      "learning_rate": 1.836022971459737e-05,
      "loss": 2.0815,
      "step": 1495
    },
    {
      "epoch": 0.5984,
      "grad_norm": 0.42532016013178664,
      "learning_rate": 1.8329010913579563e-05,
      "loss": 2.123,
      "step": 1496
    },
    {
      "epoch": 0.5988,
      "grad_norm": 0.41921874325822334,
      "learning_rate": 1.8297803308652993e-05,
      "loss": 2.1172,
      "step": 1497
    },
    {
      "epoch": 0.5992,
      "grad_norm": 0.41243000310275485,
      "learning_rate": 1.8266606952194187e-05,
      "loss": 2.2017,
      "step": 1498
    },
    {
      "epoch": 0.5996,
      "grad_norm": 0.4069405668204684,
      "learning_rate": 1.823542189656077e-05,
      "loss": 2.2231,
      "step": 1499
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.40278425409603813,
      "learning_rate": 1.820424819409143e-05,
      "loss": 2.127,
      "step": 1500
    },
    {
      "epoch": 0.6004,
      "grad_norm": 0.4127877457704146,
      "learning_rate": 1.8173085897105784e-05,
      "loss": 2.1973,
      "step": 1501
    },
    {
      "epoch": 0.6008,
      "grad_norm": 0.4326207607959265,
      "learning_rate": 1.814193505790432e-05,
      "loss": 2.1118,
      "step": 1502
    },
    {
      "epoch": 0.6012,
      "grad_norm": 0.41372879149869446,
      "learning_rate": 1.811079572876827e-05,
      "loss": 2.1318,
      "step": 1503
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.4103282331943927,
      "learning_rate": 1.8079667961959566e-05,
      "loss": 2.1978,
      "step": 1504
    },
    {
      "epoch": 0.602,
      "grad_norm": 0.40635707408664556,
      "learning_rate": 1.804855180972075e-05,
      "loss": 2.2197,
      "step": 1505
    },
    {
      "epoch": 0.6024,
      "grad_norm": 0.4042861414739069,
      "learning_rate": 1.8017447324274837e-05,
      "loss": 2.1538,
      "step": 1506
    },
    {
      "epoch": 0.6028,
      "grad_norm": 0.4168489836196407,
      "learning_rate": 1.7986354557825296e-05,
      "loss": 2.1235,
      "step": 1507
    },
    {
      "epoch": 0.6032,
      "grad_norm": 0.3990320710190378,
      "learning_rate": 1.7955273562555892e-05,
      "loss": 2.123,
      "step": 1508
    },
    {
      "epoch": 0.6036,
      "grad_norm": 0.4061566370882158,
      "learning_rate": 1.792420439063066e-05,
      "loss": 2.1372,
      "step": 1509
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.4234602696007087,
      "learning_rate": 1.7893147094193786e-05,
      "loss": 2.0854,
      "step": 1510
    },
    {
      "epoch": 0.6044,
      "grad_norm": 0.39474117835335953,
      "learning_rate": 1.7862101725369528e-05,
      "loss": 2.0459,
      "step": 1511
    },
    {
      "epoch": 0.6048,
      "grad_norm": 0.4041909987599971,
      "learning_rate": 1.7831068336262114e-05,
      "loss": 2.167,
      "step": 1512
    },
    {
      "epoch": 0.6052,
      "grad_norm": 0.41894479828580805,
      "learning_rate": 1.7800046978955664e-05,
      "loss": 2.1606,
      "step": 1513
    },
    {
      "epoch": 0.6056,
      "grad_norm": 0.39076456073055854,
      "learning_rate": 1.7769037705514135e-05,
      "loss": 2.0581,
      "step": 1514
    },
    {
      "epoch": 0.606,
      "grad_norm": 0.4192025401732415,
      "learning_rate": 1.7738040567981166e-05,
      "loss": 2.1719,
      "step": 1515
    },
    {
      "epoch": 0.6064,
      "grad_norm": 0.4375789793706522,
      "learning_rate": 1.7707055618380058e-05,
      "loss": 2.2261,
      "step": 1516
    },
    {
      "epoch": 0.6068,
      "grad_norm": 0.41120322433257,
      "learning_rate": 1.7676082908713625e-05,
      "loss": 2.2041,
      "step": 1517
    },
    {
      "epoch": 0.6072,
      "grad_norm": 0.4452424279056641,
      "learning_rate": 1.764512249096416e-05,
      "loss": 2.1665,
      "step": 1518
    },
    {
      "epoch": 0.6076,
      "grad_norm": 0.42489155127528566,
      "learning_rate": 1.7614174417093332e-05,
      "loss": 2.1172,
      "step": 1519
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.41386496627281955,
      "learning_rate": 1.7583238739042086e-05,
      "loss": 2.1479,
      "step": 1520
    },
    {
      "epoch": 0.6084,
      "grad_norm": 0.4035986010458094,
      "learning_rate": 1.7552315508730545e-05,
      "loss": 2.0811,
      "step": 1521
    },
    {
      "epoch": 0.6088,
      "grad_norm": 0.42424619136962316,
      "learning_rate": 1.7521404778057966e-05,
      "loss": 2.1841,
      "step": 1522
    },
    {
      "epoch": 0.6092,
      "grad_norm": 0.40326054060887406,
      "learning_rate": 1.7490506598902602e-05,
      "loss": 2.1245,
      "step": 1523
    },
    {
      "epoch": 0.6096,
      "grad_norm": 0.41832168792930524,
      "learning_rate": 1.7459621023121677e-05,
      "loss": 2.1084,
      "step": 1524
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4020207918425736,
      "learning_rate": 1.7428748102551237e-05,
      "loss": 2.1157,
      "step": 1525
    },
    {
      "epoch": 0.6104,
      "grad_norm": 0.41714810420026527,
      "learning_rate": 1.7397887889006082e-05,
      "loss": 2.1904,
      "step": 1526
    },
    {
      "epoch": 0.6108,
      "grad_norm": 0.406898701109282,
      "learning_rate": 1.7367040434279695e-05,
      "loss": 2.1616,
      "step": 1527
    },
    {
      "epoch": 0.6112,
      "grad_norm": 0.41416135399679677,
      "learning_rate": 1.7336205790144157e-05,
      "loss": 2.189,
      "step": 1528
    },
    {
      "epoch": 0.6116,
      "grad_norm": 0.4156193941959795,
      "learning_rate": 1.730538400835004e-05,
      "loss": 2.1963,
      "step": 1529
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.3914945327332709,
      "learning_rate": 1.7274575140626318e-05,
      "loss": 2.1152,
      "step": 1530
    },
    {
      "epoch": 0.6124,
      "grad_norm": 0.3871059660580419,
      "learning_rate": 1.7243779238680307e-05,
      "loss": 2.0791,
      "step": 1531
    },
    {
      "epoch": 0.6128,
      "grad_norm": 0.40547538890099516,
      "learning_rate": 1.721299635419754e-05,
      "loss": 2.0894,
      "step": 1532
    },
    {
      "epoch": 0.6132,
      "grad_norm": 0.4057952351657911,
      "learning_rate": 1.7182226538841735e-05,
      "loss": 2.1719,
      "step": 1533
    },
    {
      "epoch": 0.6136,
      "grad_norm": 0.422067350074332,
      "learning_rate": 1.7151469844254654e-05,
      "loss": 2.1992,
      "step": 1534
    },
    {
      "epoch": 0.614,
      "grad_norm": 0.38832430500485876,
      "learning_rate": 1.712072632205604e-05,
      "loss": 2.0767,
      "step": 1535
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.41220554863866693,
      "learning_rate": 1.708999602384353e-05,
      "loss": 2.2041,
      "step": 1536
    },
    {
      "epoch": 0.6148,
      "grad_norm": 0.4015955007470916,
      "learning_rate": 1.7059279001192562e-05,
      "loss": 2.1802,
      "step": 1537
    },
    {
      "epoch": 0.6152,
      "grad_norm": 0.40588577525749076,
      "learning_rate": 1.702857530565632e-05,
      "loss": 2.1011,
      "step": 1538
    },
    {
      "epoch": 0.6156,
      "grad_norm": 0.38721150987462605,
      "learning_rate": 1.6997884988765583e-05,
      "loss": 2.0376,
      "step": 1539
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.4060541225656886,
      "learning_rate": 1.6967208102028697e-05,
      "loss": 2.2134,
      "step": 1540
    },
    {
      "epoch": 0.6164,
      "grad_norm": 0.4129184705619714,
      "learning_rate": 1.6936544696931455e-05,
      "loss": 2.1279,
      "step": 1541
    },
    {
      "epoch": 0.6168,
      "grad_norm": 0.399536703246081,
      "learning_rate": 1.690589482493705e-05,
      "loss": 2.1611,
      "step": 1542
    },
    {
      "epoch": 0.6172,
      "grad_norm": 0.4159751023309957,
      "learning_rate": 1.6875258537485935e-05,
      "loss": 2.1138,
      "step": 1543
    },
    {
      "epoch": 0.6176,
      "grad_norm": 0.4148840972585929,
      "learning_rate": 1.684463588599577e-05,
      "loss": 2.1377,
      "step": 1544
    },
    {
      "epoch": 0.618,
      "grad_norm": 0.389525887863926,
      "learning_rate": 1.6814026921861335e-05,
      "loss": 2.1602,
      "step": 1545
    },
    {
      "epoch": 0.6184,
      "grad_norm": 0.41902267705753077,
      "learning_rate": 1.6783431696454434e-05,
      "loss": 2.1162,
      "step": 1546
    },
    {
      "epoch": 0.6188,
      "grad_norm": 0.4188158186485137,
      "learning_rate": 1.6752850261123825e-05,
      "loss": 2.1548,
      "step": 1547
    },
    {
      "epoch": 0.6192,
      "grad_norm": 0.394203983071721,
      "learning_rate": 1.6722282667195098e-05,
      "loss": 2.1279,
      "step": 1548
    },
    {
      "epoch": 0.6196,
      "grad_norm": 0.4097949362963049,
      "learning_rate": 1.669172896597064e-05,
      "loss": 2.1567,
      "step": 1549
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.4193974877144886,
      "learning_rate": 1.666118920872949e-05,
      "loss": 2.1372,
      "step": 1550
    },
    {
      "epoch": 0.6204,
      "grad_norm": 0.41833111910482274,
      "learning_rate": 1.6630663446727306e-05,
      "loss": 2.0859,
      "step": 1551
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.4021761193435345,
      "learning_rate": 1.6600151731196272e-05,
      "loss": 2.1475,
      "step": 1552
    },
    {
      "epoch": 0.6212,
      "grad_norm": 0.42950907387014764,
      "learning_rate": 1.656965411334496e-05,
      "loss": 2.2266,
      "step": 1553
    },
    {
      "epoch": 0.6216,
      "grad_norm": 0.4306894238878838,
      "learning_rate": 1.6539170644358302e-05,
      "loss": 2.1509,
      "step": 1554
    },
    {
      "epoch": 0.622,
      "grad_norm": 0.39601100380360144,
      "learning_rate": 1.6508701375397487e-05,
      "loss": 2.1548,
      "step": 1555
    },
    {
      "epoch": 0.6224,
      "grad_norm": 0.3859550045015694,
      "learning_rate": 1.647824635759987e-05,
      "loss": 2.1411,
      "step": 1556
    },
    {
      "epoch": 0.6228,
      "grad_norm": 0.39612767926498543,
      "learning_rate": 1.6447805642078878e-05,
      "loss": 2.126,
      "step": 1557
    },
    {
      "epoch": 0.6232,
      "grad_norm": 0.3981641587798694,
      "learning_rate": 1.641737927992395e-05,
      "loss": 2.0547,
      "step": 1558
    },
    {
      "epoch": 0.6236,
      "grad_norm": 0.3992668343337292,
      "learning_rate": 1.638696732220041e-05,
      "loss": 2.0977,
      "step": 1559
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.42518210896204534,
      "learning_rate": 1.635656981994943e-05,
      "loss": 2.2065,
      "step": 1560
    },
    {
      "epoch": 0.6244,
      "grad_norm": 0.4064078564259174,
      "learning_rate": 1.6326186824187918e-05,
      "loss": 2.1699,
      "step": 1561
    },
    {
      "epoch": 0.6248,
      "grad_norm": 0.3996828709968678,
      "learning_rate": 1.6295818385908434e-05,
      "loss": 2.1348,
      "step": 1562
    },
    {
      "epoch": 0.6252,
      "grad_norm": 0.38593983019267086,
      "learning_rate": 1.6265464556079095e-05,
      "loss": 2.0923,
      "step": 1563
    },
    {
      "epoch": 0.6256,
      "grad_norm": 0.3983524936598066,
      "learning_rate": 1.6235125385643518e-05,
      "loss": 2.063,
      "step": 1564
    },
    {
      "epoch": 0.626,
      "grad_norm": 0.4193672880188322,
      "learning_rate": 1.6204800925520685e-05,
      "loss": 2.0918,
      "step": 1565
    },
    {
      "epoch": 0.6264,
      "grad_norm": 0.4018618108606535,
      "learning_rate": 1.6174491226604933e-05,
      "loss": 2.2168,
      "step": 1566
    },
    {
      "epoch": 0.6268,
      "grad_norm": 0.4007019087560595,
      "learning_rate": 1.6144196339765806e-05,
      "loss": 2.1958,
      "step": 1567
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.4120230081463469,
      "learning_rate": 1.611391631584797e-05,
      "loss": 2.1392,
      "step": 1568
    },
    {
      "epoch": 0.6276,
      "grad_norm": 0.39317327569184435,
      "learning_rate": 1.608365120567116e-05,
      "loss": 2.1548,
      "step": 1569
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.41175297366146707,
      "learning_rate": 1.60534010600301e-05,
      "loss": 2.2397,
      "step": 1570
    },
    {
      "epoch": 0.6284,
      "grad_norm": 0.4049940849017306,
      "learning_rate": 1.6023165929694378e-05,
      "loss": 2.1567,
      "step": 1571
    },
    {
      "epoch": 0.6288,
      "grad_norm": 0.3915493713101845,
      "learning_rate": 1.5992945865408372e-05,
      "loss": 2.0225,
      "step": 1572
    },
    {
      "epoch": 0.6292,
      "grad_norm": 0.4002650311562231,
      "learning_rate": 1.59627409178912e-05,
      "loss": 2.1475,
      "step": 1573
    },
    {
      "epoch": 0.6296,
      "grad_norm": 0.39612515870038284,
      "learning_rate": 1.5932551137836584e-05,
      "loss": 2.0786,
      "step": 1574
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4178476015125286,
      "learning_rate": 1.5902376575912815e-05,
      "loss": 2.1982,
      "step": 1575
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.40465670095977324,
      "learning_rate": 1.5872217282762624e-05,
      "loss": 2.2314,
      "step": 1576
    },
    {
      "epoch": 0.6308,
      "grad_norm": 0.411144231457664,
      "learning_rate": 1.5842073309003126e-05,
      "loss": 2.1714,
      "step": 1577
    },
    {
      "epoch": 0.6312,
      "grad_norm": 0.38969603664393,
      "learning_rate": 1.5811944705225717e-05,
      "loss": 2.1113,
      "step": 1578
    },
    {
      "epoch": 0.6316,
      "grad_norm": 0.4246811518948538,
      "learning_rate": 1.5781831521995994e-05,
      "loss": 2.1777,
      "step": 1579
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.4216727326556992,
      "learning_rate": 1.5751733809853704e-05,
      "loss": 2.2095,
      "step": 1580
    },
    {
      "epoch": 0.6324,
      "grad_norm": 0.4035917276524524,
      "learning_rate": 1.5721651619312586e-05,
      "loss": 2.2148,
      "step": 1581
    },
    {
      "epoch": 0.6328,
      "grad_norm": 0.3914678564300818,
      "learning_rate": 1.5691585000860358e-05,
      "loss": 2.0957,
      "step": 1582
    },
    {
      "epoch": 0.6332,
      "grad_norm": 0.38454247037667544,
      "learning_rate": 1.5661534004958587e-05,
      "loss": 2.0635,
      "step": 1583
    },
    {
      "epoch": 0.6336,
      "grad_norm": 0.4014726381766742,
      "learning_rate": 1.5631498682042624e-05,
      "loss": 2.1631,
      "step": 1584
    },
    {
      "epoch": 0.634,
      "grad_norm": 0.3801769549414645,
      "learning_rate": 1.5601479082521526e-05,
      "loss": 2.1006,
      "step": 1585
    },
    {
      "epoch": 0.6344,
      "grad_norm": 0.38382198100885734,
      "learning_rate": 1.557147525677795e-05,
      "loss": 2.1216,
      "step": 1586
    },
    {
      "epoch": 0.6348,
      "grad_norm": 0.4093038828753529,
      "learning_rate": 1.554148725516808e-05,
      "loss": 2.1899,
      "step": 1587
    },
    {
      "epoch": 0.6352,
      "grad_norm": 0.3957858841705679,
      "learning_rate": 1.5511515128021542e-05,
      "loss": 2.146,
      "step": 1588
    },
    {
      "epoch": 0.6356,
      "grad_norm": 0.4045580606476471,
      "learning_rate": 1.5481558925641338e-05,
      "loss": 2.2051,
      "step": 1589
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.4028447351525402,
      "learning_rate": 1.545161869830371e-05,
      "loss": 2.2344,
      "step": 1590
    },
    {
      "epoch": 0.6364,
      "grad_norm": 0.40429823564430895,
      "learning_rate": 1.5421694496258117e-05,
      "loss": 2.1143,
      "step": 1591
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.4077815073591833,
      "learning_rate": 1.5391786369727095e-05,
      "loss": 2.1831,
      "step": 1592
    },
    {
      "epoch": 0.6372,
      "grad_norm": 0.40808847922189856,
      "learning_rate": 1.5361894368906223e-05,
      "loss": 2.0947,
      "step": 1593
    },
    {
      "epoch": 0.6376,
      "grad_norm": 0.3911850070880919,
      "learning_rate": 1.5332018543964024e-05,
      "loss": 2.1045,
      "step": 1594
    },
    {
      "epoch": 0.638,
      "grad_norm": 0.405116549827639,
      "learning_rate": 1.5302158945041838e-05,
      "loss": 2.1021,
      "step": 1595
    },
    {
      "epoch": 0.6384,
      "grad_norm": 0.39483161167125613,
      "learning_rate": 1.5272315622253802e-05,
      "loss": 2.0581,
      "step": 1596
    },
    {
      "epoch": 0.6388,
      "grad_norm": 0.392164011501405,
      "learning_rate": 1.524248862568673e-05,
      "loss": 2.1709,
      "step": 1597
    },
    {
      "epoch": 0.6392,
      "grad_norm": 0.38010242005231926,
      "learning_rate": 1.521267800540001e-05,
      "loss": 2.105,
      "step": 1598
    },
    {
      "epoch": 0.6396,
      "grad_norm": 0.3999773566737622,
      "learning_rate": 1.5182883811425591e-05,
      "loss": 2.1196,
      "step": 1599
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3808599126954418,
      "learning_rate": 1.5153106093767827e-05,
      "loss": 2.063,
      "step": 1600
    },
    {
      "epoch": 0.6404,
      "grad_norm": 0.3937946315514962,
      "learning_rate": 1.5123344902403405e-05,
      "loss": 2.2109,
      "step": 1601
    },
    {
      "epoch": 0.6408,
      "grad_norm": 0.3919000079389581,
      "learning_rate": 1.5093600287281301e-05,
      "loss": 2.0874,
      "step": 1602
    },
    {
      "epoch": 0.6412,
      "grad_norm": 0.3947143668021749,
      "learning_rate": 1.5063872298322668e-05,
      "loss": 2.0459,
      "step": 1603
    },
    {
      "epoch": 0.6416,
      "grad_norm": 0.38956715151509963,
      "learning_rate": 1.5034160985420743e-05,
      "loss": 2.1396,
      "step": 1604
    },
    {
      "epoch": 0.642,
      "grad_norm": 0.3939264179768272,
      "learning_rate": 1.5004466398440775e-05,
      "loss": 2.0972,
      "step": 1605
    },
    {
      "epoch": 0.6424,
      "grad_norm": 0.40942669964025613,
      "learning_rate": 1.4974788587219963e-05,
      "loss": 2.1445,
      "step": 1606
    },
    {
      "epoch": 0.6428,
      "grad_norm": 0.3844461038266476,
      "learning_rate": 1.494512760156731e-05,
      "loss": 2.1006,
      "step": 1607
    },
    {
      "epoch": 0.6432,
      "grad_norm": 0.41160445077745716,
      "learning_rate": 1.4915483491263629e-05,
      "loss": 2.2251,
      "step": 1608
    },
    {
      "epoch": 0.6436,
      "grad_norm": 0.41086970018479363,
      "learning_rate": 1.4885856306061383e-05,
      "loss": 2.2139,
      "step": 1609
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.39258286400991416,
      "learning_rate": 1.4856246095684622e-05,
      "loss": 2.1289,
      "step": 1610
    },
    {
      "epoch": 0.6444,
      "grad_norm": 0.4062885386049504,
      "learning_rate": 1.4826652909828931e-05,
      "loss": 2.1758,
      "step": 1611
    },
    {
      "epoch": 0.6448,
      "grad_norm": 0.3839149505061822,
      "learning_rate": 1.4797076798161286e-05,
      "loss": 2.0742,
      "step": 1612
    },
    {
      "epoch": 0.6452,
      "grad_norm": 0.3882939179546175,
      "learning_rate": 1.4767517810320058e-05,
      "loss": 2.1548,
      "step": 1613
    },
    {
      "epoch": 0.6456,
      "grad_norm": 0.3964852518973631,
      "learning_rate": 1.4737975995914838e-05,
      "loss": 2.2207,
      "step": 1614
    },
    {
      "epoch": 0.646,
      "grad_norm": 0.39930420855150256,
      "learning_rate": 1.4708451404526407e-05,
      "loss": 2.1255,
      "step": 1615
    },
    {
      "epoch": 0.6464,
      "grad_norm": 0.3857530022958788,
      "learning_rate": 1.4678944085706635e-05,
      "loss": 2.1572,
      "step": 1616
    },
    {
      "epoch": 0.6468,
      "grad_norm": 0.40528289112683924,
      "learning_rate": 1.4649454088978421e-05,
      "loss": 2.1685,
      "step": 1617
    },
    {
      "epoch": 0.6472,
      "grad_norm": 0.4016758367293066,
      "learning_rate": 1.4619981463835574e-05,
      "loss": 2.1797,
      "step": 1618
    },
    {
      "epoch": 0.6476,
      "grad_norm": 0.40305516773897754,
      "learning_rate": 1.4590526259742748e-05,
      "loss": 2.1128,
      "step": 1619
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.3862345811128115,
      "learning_rate": 1.4561088526135375e-05,
      "loss": 2.062,
      "step": 1620
    },
    {
      "epoch": 0.6484,
      "grad_norm": 0.39110219583066547,
      "learning_rate": 1.4531668312419533e-05,
      "loss": 2.103,
      "step": 1621
    },
    {
      "epoch": 0.6488,
      "grad_norm": 0.3882398584736952,
      "learning_rate": 1.4502265667971931e-05,
      "loss": 2.1899,
      "step": 1622
    },
    {
      "epoch": 0.6492,
      "grad_norm": 0.40071412525680755,
      "learning_rate": 1.447288064213979e-05,
      "loss": 2.1255,
      "step": 1623
    },
    {
      "epoch": 0.6496,
      "grad_norm": 0.39482879387277703,
      "learning_rate": 1.4443513284240734e-05,
      "loss": 2.126,
      "step": 1624
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3858919399063589,
      "learning_rate": 1.4414163643562755e-05,
      "loss": 2.0566,
      "step": 1625
    },
    {
      "epoch": 0.6504,
      "grad_norm": 0.39595994515942745,
      "learning_rate": 1.4384831769364088e-05,
      "loss": 2.0317,
      "step": 1626
    },
    {
      "epoch": 0.6508,
      "grad_norm": 0.39891354302106197,
      "learning_rate": 1.4355517710873184e-05,
      "loss": 2.1133,
      "step": 1627
    },
    {
      "epoch": 0.6512,
      "grad_norm": 0.4072280613812687,
      "learning_rate": 1.4326221517288573e-05,
      "loss": 2.1475,
      "step": 1628
    },
    {
      "epoch": 0.6516,
      "grad_norm": 0.4211866156099883,
      "learning_rate": 1.4296943237778809e-05,
      "loss": 2.1704,
      "step": 1629
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.41070181552168317,
      "learning_rate": 1.4267682921482356e-05,
      "loss": 2.1484,
      "step": 1630
    },
    {
      "epoch": 0.6524,
      "grad_norm": 0.4034392750948092,
      "learning_rate": 1.4238440617507563e-05,
      "loss": 2.1235,
      "step": 1631
    },
    {
      "epoch": 0.6528,
      "grad_norm": 0.38625108001560765,
      "learning_rate": 1.4209216374932544e-05,
      "loss": 2.0791,
      "step": 1632
    },
    {
      "epoch": 0.6532,
      "grad_norm": 0.4005579964411523,
      "learning_rate": 1.4180010242805081e-05,
      "loss": 2.1543,
      "step": 1633
    },
    {
      "epoch": 0.6536,
      "grad_norm": 0.3846914223744635,
      "learning_rate": 1.415082227014257e-05,
      "loss": 2.1045,
      "step": 1634
    },
    {
      "epoch": 0.654,
      "grad_norm": 0.38481241296026275,
      "learning_rate": 1.412165250593192e-05,
      "loss": 2.1055,
      "step": 1635
    },
    {
      "epoch": 0.6544,
      "grad_norm": 0.40830079306746664,
      "learning_rate": 1.409250099912951e-05,
      "loss": 2.1802,
      "step": 1636
    },
    {
      "epoch": 0.6548,
      "grad_norm": 0.3904991174416613,
      "learning_rate": 1.4063367798661053e-05,
      "loss": 2.1519,
      "step": 1637
    },
    {
      "epoch": 0.6552,
      "grad_norm": 0.39459381247400965,
      "learning_rate": 1.4034252953421545e-05,
      "loss": 2.1499,
      "step": 1638
    },
    {
      "epoch": 0.6556,
      "grad_norm": 0.3974068482689912,
      "learning_rate": 1.4005156512275158e-05,
      "loss": 2.1431,
      "step": 1639
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.39182206675601183,
      "learning_rate": 1.3976078524055203e-05,
      "loss": 2.1626,
      "step": 1640
    },
    {
      "epoch": 0.6564,
      "grad_norm": 0.3925470098878285,
      "learning_rate": 1.3947019037564018e-05,
      "loss": 2.1221,
      "step": 1641
    },
    {
      "epoch": 0.6568,
      "grad_norm": 0.38945548711961586,
      "learning_rate": 1.3917978101572877e-05,
      "loss": 2.0708,
      "step": 1642
    },
    {
      "epoch": 0.6572,
      "grad_norm": 0.41201080673121626,
      "learning_rate": 1.3888955764821915e-05,
      "loss": 2.2119,
      "step": 1643
    },
    {
      "epoch": 0.6576,
      "grad_norm": 0.40847072307907506,
      "learning_rate": 1.3859952076020055e-05,
      "loss": 2.2134,
      "step": 1644
    },
    {
      "epoch": 0.658,
      "grad_norm": 0.3789110027156621,
      "learning_rate": 1.3830967083844942e-05,
      "loss": 2.1602,
      "step": 1645
    },
    {
      "epoch": 0.6584,
      "grad_norm": 0.3899652846929874,
      "learning_rate": 1.380200083694283e-05,
      "loss": 2.0869,
      "step": 1646
    },
    {
      "epoch": 0.6588,
      "grad_norm": 0.3908207719798237,
      "learning_rate": 1.3773053383928509e-05,
      "loss": 2.0542,
      "step": 1647
    },
    {
      "epoch": 0.6592,
      "grad_norm": 0.3903175619186371,
      "learning_rate": 1.3744124773385208e-05,
      "loss": 2.1157,
      "step": 1648
    },
    {
      "epoch": 0.6596,
      "grad_norm": 0.3944626716946792,
      "learning_rate": 1.3715215053864571e-05,
      "loss": 2.1592,
      "step": 1649
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.37803461562896473,
      "learning_rate": 1.368632427388653e-05,
      "loss": 2.0571,
      "step": 1650
    },
    {
      "epoch": 0.6604,
      "grad_norm": 0.4073807805483148,
      "learning_rate": 1.3657452481939199e-05,
      "loss": 2.1675,
      "step": 1651
    },
    {
      "epoch": 0.6608,
      "grad_norm": 0.3842508398643417,
      "learning_rate": 1.3628599726478847e-05,
      "loss": 2.1187,
      "step": 1652
    },
    {
      "epoch": 0.6612,
      "grad_norm": 0.37892646737731805,
      "learning_rate": 1.3599766055929786e-05,
      "loss": 2.1206,
      "step": 1653
    },
    {
      "epoch": 0.6616,
      "grad_norm": 0.39612290618683665,
      "learning_rate": 1.35709515186843e-05,
      "loss": 2.1284,
      "step": 1654
    },
    {
      "epoch": 0.662,
      "grad_norm": 0.38737047436177346,
      "learning_rate": 1.3542156163102582e-05,
      "loss": 2.1338,
      "step": 1655
    },
    {
      "epoch": 0.6624,
      "grad_norm": 0.4068239744563443,
      "learning_rate": 1.3513380037512596e-05,
      "loss": 2.1406,
      "step": 1656
    },
    {
      "epoch": 0.6628,
      "grad_norm": 0.3971277333746567,
      "learning_rate": 1.3484623190210045e-05,
      "loss": 2.0962,
      "step": 1657
    },
    {
      "epoch": 0.6632,
      "grad_norm": 0.39888651551347987,
      "learning_rate": 1.345588566945829e-05,
      "loss": 2.0752,
      "step": 1658
    },
    {
      "epoch": 0.6636,
      "grad_norm": 0.419434254870182,
      "learning_rate": 1.3427167523488236e-05,
      "loss": 2.1416,
      "step": 1659
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.3907103755672072,
      "learning_rate": 1.3398468800498293e-05,
      "loss": 2.1772,
      "step": 1660
    },
    {
      "epoch": 0.6644,
      "grad_norm": 0.42201028557772546,
      "learning_rate": 1.3369789548654248e-05,
      "loss": 2.124,
      "step": 1661
    },
    {
      "epoch": 0.6648,
      "grad_norm": 0.4268885454337762,
      "learning_rate": 1.334112981608922e-05,
      "loss": 2.2227,
      "step": 1662
    },
    {
      "epoch": 0.6652,
      "grad_norm": 0.3971976027375008,
      "learning_rate": 1.3312489650903576e-05,
      "loss": 2.1538,
      "step": 1663
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.38362843945332376,
      "learning_rate": 1.3283869101164842e-05,
      "loss": 2.0947,
      "step": 1664
    },
    {
      "epoch": 0.666,
      "grad_norm": 0.4014700733403094,
      "learning_rate": 1.3255268214907613e-05,
      "loss": 2.1006,
      "step": 1665
    },
    {
      "epoch": 0.6664,
      "grad_norm": 0.4043385870092543,
      "learning_rate": 1.3226687040133472e-05,
      "loss": 2.1802,
      "step": 1666
    },
    {
      "epoch": 0.6668,
      "grad_norm": 0.3745486990319699,
      "learning_rate": 1.3198125624810958e-05,
      "loss": 2.0781,
      "step": 1667
    },
    {
      "epoch": 0.6672,
      "grad_norm": 0.4326346383803859,
      "learning_rate": 1.31695840168754e-05,
      "loss": 2.2002,
      "step": 1668
    },
    {
      "epoch": 0.6676,
      "grad_norm": 0.38782734417236325,
      "learning_rate": 1.3141062264228926e-05,
      "loss": 2.2021,
      "step": 1669
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.3933197780495643,
      "learning_rate": 1.3112560414740315e-05,
      "loss": 2.0957,
      "step": 1670
    },
    {
      "epoch": 0.6684,
      "grad_norm": 0.40764344260346497,
      "learning_rate": 1.308407851624494e-05,
      "loss": 2.1392,
      "step": 1671
    },
    {
      "epoch": 0.6688,
      "grad_norm": 0.3986987242553882,
      "learning_rate": 1.3055616616544714e-05,
      "loss": 2.1606,
      "step": 1672
    },
    {
      "epoch": 0.6692,
      "grad_norm": 0.40059317175545534,
      "learning_rate": 1.3027174763407946e-05,
      "loss": 2.1367,
      "step": 1673
    },
    {
      "epoch": 0.6696,
      "grad_norm": 0.38411342370557533,
      "learning_rate": 1.2998753004569353e-05,
      "loss": 2.0605,
      "step": 1674
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.4069258913083927,
      "learning_rate": 1.2970351387729873e-05,
      "loss": 2.0874,
      "step": 1675
    },
    {
      "epoch": 0.6704,
      "grad_norm": 0.39660342446495495,
      "learning_rate": 1.2941969960556685e-05,
      "loss": 2.1309,
      "step": 1676
    },
    {
      "epoch": 0.6708,
      "grad_norm": 0.39122329298919184,
      "learning_rate": 1.2913608770683044e-05,
      "loss": 2.1084,
      "step": 1677
    },
    {
      "epoch": 0.6712,
      "grad_norm": 0.39184731217560165,
      "learning_rate": 1.2885267865708279e-05,
      "loss": 2.1553,
      "step": 1678
    },
    {
      "epoch": 0.6716,
      "grad_norm": 0.40569981234725344,
      "learning_rate": 1.2856947293197642e-05,
      "loss": 2.1426,
      "step": 1679
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.3937761527063747,
      "learning_rate": 1.2828647100682261e-05,
      "loss": 2.166,
      "step": 1680
    },
    {
      "epoch": 0.6724,
      "grad_norm": 0.3907389592405349,
      "learning_rate": 1.2800367335659094e-05,
      "loss": 2.1313,
      "step": 1681
    },
    {
      "epoch": 0.6728,
      "grad_norm": 0.40525269265845965,
      "learning_rate": 1.2772108045590775e-05,
      "loss": 2.1113,
      "step": 1682
    },
    {
      "epoch": 0.6732,
      "grad_norm": 0.39229234958701936,
      "learning_rate": 1.2743869277905606e-05,
      "loss": 2.0571,
      "step": 1683
    },
    {
      "epoch": 0.6736,
      "grad_norm": 0.3897613616957863,
      "learning_rate": 1.2715651079997417e-05,
      "loss": 2.2153,
      "step": 1684
    },
    {
      "epoch": 0.674,
      "grad_norm": 0.37784146811151914,
      "learning_rate": 1.2687453499225545e-05,
      "loss": 2.0527,
      "step": 1685
    },
    {
      "epoch": 0.6744,
      "grad_norm": 0.37862277575828807,
      "learning_rate": 1.2659276582914703e-05,
      "loss": 2.0405,
      "step": 1686
    },
    {
      "epoch": 0.6748,
      "grad_norm": 0.39112713473449157,
      "learning_rate": 1.2631120378354918e-05,
      "loss": 2.1631,
      "step": 1687
    },
    {
      "epoch": 0.6752,
      "grad_norm": 0.39797193202997294,
      "learning_rate": 1.2602984932801487e-05,
      "loss": 2.1274,
      "step": 1688
    },
    {
      "epoch": 0.6756,
      "grad_norm": 0.40724919623750444,
      "learning_rate": 1.2574870293474824e-05,
      "loss": 2.1157,
      "step": 1689
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.4083678923376488,
      "learning_rate": 1.2546776507560468e-05,
      "loss": 2.1631,
      "step": 1690
    },
    {
      "epoch": 0.6764,
      "grad_norm": 0.3908652004226403,
      "learning_rate": 1.2518703622208916e-05,
      "loss": 2.0537,
      "step": 1691
    },
    {
      "epoch": 0.6768,
      "grad_norm": 0.395308351230924,
      "learning_rate": 1.2490651684535626e-05,
      "loss": 2.1045,
      "step": 1692
    },
    {
      "epoch": 0.6772,
      "grad_norm": 0.40857743835181654,
      "learning_rate": 1.2462620741620864e-05,
      "loss": 2.2061,
      "step": 1693
    },
    {
      "epoch": 0.6776,
      "grad_norm": 0.3845226472708312,
      "learning_rate": 1.2434610840509698e-05,
      "loss": 2.0596,
      "step": 1694
    },
    {
      "epoch": 0.678,
      "grad_norm": 0.38541567515060765,
      "learning_rate": 1.2406622028211844e-05,
      "loss": 2.0767,
      "step": 1695
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.39817973274396457,
      "learning_rate": 1.2378654351701637e-05,
      "loss": 2.1392,
      "step": 1696
    },
    {
      "epoch": 0.6788,
      "grad_norm": 0.40131340767167906,
      "learning_rate": 1.2350707857917959e-05,
      "loss": 2.1895,
      "step": 1697
    },
    {
      "epoch": 0.6792,
      "grad_norm": 0.40757495900968777,
      "learning_rate": 1.2322782593764103e-05,
      "loss": 2.1646,
      "step": 1698
    },
    {
      "epoch": 0.6796,
      "grad_norm": 0.3919861852207942,
      "learning_rate": 1.2294878606107774e-05,
      "loss": 2.0957,
      "step": 1699
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4082669450395105,
      "learning_rate": 1.2266995941780934e-05,
      "loss": 2.1177,
      "step": 1700
    },
    {
      "epoch": 0.6804,
      "grad_norm": 0.4035734477305548,
      "learning_rate": 1.2239134647579764e-05,
      "loss": 2.1943,
      "step": 1701
    },
    {
      "epoch": 0.6808,
      "grad_norm": 0.4285476715735555,
      "learning_rate": 1.2211294770264593e-05,
      "loss": 2.2227,
      "step": 1702
    },
    {
      "epoch": 0.6812,
      "grad_norm": 0.40859601599125356,
      "learning_rate": 1.2183476356559805e-05,
      "loss": 2.1953,
      "step": 1703
    },
    {
      "epoch": 0.6816,
      "grad_norm": 0.41233526989716335,
      "learning_rate": 1.215567945315375e-05,
      "loss": 2.1792,
      "step": 1704
    },
    {
      "epoch": 0.682,
      "grad_norm": 0.3901996969830923,
      "learning_rate": 1.2127904106698666e-05,
      "loss": 2.1602,
      "step": 1705
    },
    {
      "epoch": 0.6824,
      "grad_norm": 0.397249290507218,
      "learning_rate": 1.2100150363810635e-05,
      "loss": 2.1548,
      "step": 1706
    },
    {
      "epoch": 0.6828,
      "grad_norm": 0.4053561551983068,
      "learning_rate": 1.2072418271069489e-05,
      "loss": 2.0972,
      "step": 1707
    },
    {
      "epoch": 0.6832,
      "grad_norm": 0.39903900549827426,
      "learning_rate": 1.2044707875018685e-05,
      "loss": 1.9771,
      "step": 1708
    },
    {
      "epoch": 0.6836,
      "grad_norm": 0.40029124157909823,
      "learning_rate": 1.20170192221653e-05,
      "loss": 2.0684,
      "step": 1709
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.3892821383191589,
      "learning_rate": 1.1989352358979888e-05,
      "loss": 2.103,
      "step": 1710
    },
    {
      "epoch": 0.6844,
      "grad_norm": 0.38904933856612894,
      "learning_rate": 1.1961707331896469e-05,
      "loss": 2.1558,
      "step": 1711
    },
    {
      "epoch": 0.6848,
      "grad_norm": 0.3865418575811738,
      "learning_rate": 1.19340841873124e-05,
      "loss": 2.0781,
      "step": 1712
    },
    {
      "epoch": 0.6852,
      "grad_norm": 0.4204748605412788,
      "learning_rate": 1.1906482971588303e-05,
      "loss": 2.2026,
      "step": 1713
    },
    {
      "epoch": 0.6856,
      "grad_norm": 0.39844750052833955,
      "learning_rate": 1.1878903731048005e-05,
      "loss": 2.0884,
      "step": 1714
    },
    {
      "epoch": 0.686,
      "grad_norm": 0.39113131797283324,
      "learning_rate": 1.1851346511978425e-05,
      "loss": 2.1069,
      "step": 1715
    },
    {
      "epoch": 0.6864,
      "grad_norm": 0.3865917290614358,
      "learning_rate": 1.1823811360629592e-05,
      "loss": 2.0664,
      "step": 1716
    },
    {
      "epoch": 0.6868,
      "grad_norm": 0.3854567432552532,
      "learning_rate": 1.1796298323214427e-05,
      "loss": 2.1372,
      "step": 1717
    },
    {
      "epoch": 0.6872,
      "grad_norm": 0.39438789029348514,
      "learning_rate": 1.176880744590877e-05,
      "loss": 2.1099,
      "step": 1718
    },
    {
      "epoch": 0.6876,
      "grad_norm": 0.3959393713868286,
      "learning_rate": 1.1741338774851245e-05,
      "loss": 2.1519,
      "step": 1719
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.3872451460693978,
      "learning_rate": 1.1713892356143239e-05,
      "loss": 2.1797,
      "step": 1720
    },
    {
      "epoch": 0.6884,
      "grad_norm": 0.39476051963194836,
      "learning_rate": 1.1686468235848782e-05,
      "loss": 2.1201,
      "step": 1721
    },
    {
      "epoch": 0.6888,
      "grad_norm": 0.39180511148744873,
      "learning_rate": 1.1659066459994473e-05,
      "loss": 2.1787,
      "step": 1722
    },
    {
      "epoch": 0.6892,
      "grad_norm": 0.4001542473163802,
      "learning_rate": 1.1631687074569403e-05,
      "loss": 2.1147,
      "step": 1723
    },
    {
      "epoch": 0.6896,
      "grad_norm": 0.4013793422450107,
      "learning_rate": 1.1604330125525079e-05,
      "loss": 2.1191,
      "step": 1724
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.37608527696336386,
      "learning_rate": 1.1576995658775405e-05,
      "loss": 2.1074,
      "step": 1725
    },
    {
      "epoch": 0.6904,
      "grad_norm": 0.4262048523188577,
      "learning_rate": 1.1549683720196491e-05,
      "loss": 2.3447,
      "step": 1726
    },
    {
      "epoch": 0.6908,
      "grad_norm": 0.38152463859187213,
      "learning_rate": 1.1522394355626668e-05,
      "loss": 2.1069,
      "step": 1727
    },
    {
      "epoch": 0.6912,
      "grad_norm": 0.4031527071326589,
      "learning_rate": 1.1495127610866355e-05,
      "loss": 2.1919,
      "step": 1728
    },
    {
      "epoch": 0.6916,
      "grad_norm": 0.4022894265130378,
      "learning_rate": 1.1467883531678042e-05,
      "loss": 2.1558,
      "step": 1729
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.36996479736586757,
      "learning_rate": 1.1440662163786167e-05,
      "loss": 2.0972,
      "step": 1730
    },
    {
      "epoch": 0.6924,
      "grad_norm": 0.3750813548204386,
      "learning_rate": 1.141346355287704e-05,
      "loss": 2.1675,
      "step": 1731
    },
    {
      "epoch": 0.6928,
      "grad_norm": 0.3912077335262899,
      "learning_rate": 1.1386287744598775e-05,
      "loss": 2.1416,
      "step": 1732
    },
    {
      "epoch": 0.6932,
      "grad_norm": 0.37955509783474045,
      "learning_rate": 1.135913478456124e-05,
      "loss": 2.0322,
      "step": 1733
    },
    {
      "epoch": 0.6936,
      "grad_norm": 0.3884468529814328,
      "learning_rate": 1.1332004718335925e-05,
      "loss": 2.2002,
      "step": 1734
    },
    {
      "epoch": 0.694,
      "grad_norm": 0.3904381320535932,
      "learning_rate": 1.1304897591455928e-05,
      "loss": 2.1343,
      "step": 1735
    },
    {
      "epoch": 0.6944,
      "grad_norm": 0.38168750971757537,
      "learning_rate": 1.1277813449415827e-05,
      "loss": 2.126,
      "step": 1736
    },
    {
      "epoch": 0.6948,
      "grad_norm": 0.4052694657308422,
      "learning_rate": 1.1250752337671618e-05,
      "loss": 2.1807,
      "step": 1737
    },
    {
      "epoch": 0.6952,
      "grad_norm": 0.38480758770009293,
      "learning_rate": 1.1223714301640664e-05,
      "loss": 2.1069,
      "step": 1738
    },
    {
      "epoch": 0.6956,
      "grad_norm": 0.39757226389500777,
      "learning_rate": 1.1196699386701597e-05,
      "loss": 2.0635,
      "step": 1739
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.37905032899052377,
      "learning_rate": 1.1169707638194238e-05,
      "loss": 2.0762,
      "step": 1740
    },
    {
      "epoch": 0.6964,
      "grad_norm": 0.3794582385082393,
      "learning_rate": 1.1142739101419508e-05,
      "loss": 2.0815,
      "step": 1741
    },
    {
      "epoch": 0.6968,
      "grad_norm": 0.3850939637643782,
      "learning_rate": 1.1115793821639415e-05,
      "loss": 2.1045,
      "step": 1742
    },
    {
      "epoch": 0.6972,
      "grad_norm": 0.38568709497407666,
      "learning_rate": 1.108887184407689e-05,
      "loss": 2.1055,
      "step": 1743
    },
    {
      "epoch": 0.6976,
      "grad_norm": 0.37573896407136775,
      "learning_rate": 1.106197321391579e-05,
      "loss": 2.0591,
      "step": 1744
    },
    {
      "epoch": 0.698,
      "grad_norm": 0.41129376199319934,
      "learning_rate": 1.103509797630077e-05,
      "loss": 2.1621,
      "step": 1745
    },
    {
      "epoch": 0.6984,
      "grad_norm": 0.3726946786354061,
      "learning_rate": 1.1008246176337211e-05,
      "loss": 2.0337,
      "step": 1746
    },
    {
      "epoch": 0.6988,
      "grad_norm": 0.39965647628424167,
      "learning_rate": 1.0981417859091201e-05,
      "loss": 2.1797,
      "step": 1747
    },
    {
      "epoch": 0.6992,
      "grad_norm": 0.4070549229488965,
      "learning_rate": 1.0954613069589361e-05,
      "loss": 2.167,
      "step": 1748
    },
    {
      "epoch": 0.6996,
      "grad_norm": 0.38755522805384257,
      "learning_rate": 1.0927831852818882e-05,
      "loss": 2.0986,
      "step": 1749
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4015712798300186,
      "learning_rate": 1.0901074253727336e-05,
      "loss": 2.0078,
      "step": 1750
    },
    {
      "epoch": 0.7004,
      "grad_norm": 0.378610026397555,
      "learning_rate": 1.0874340317222709e-05,
      "loss": 2.0454,
      "step": 1751
    },
    {
      "epoch": 0.7008,
      "grad_norm": 0.3887914428072999,
      "learning_rate": 1.0847630088173228e-05,
      "loss": 2.1226,
      "step": 1752
    },
    {
      "epoch": 0.7012,
      "grad_norm": 0.40819922210368775,
      "learning_rate": 1.082094361140737e-05,
      "loss": 2.1226,
      "step": 1753
    },
    {
      "epoch": 0.7016,
      "grad_norm": 0.38879931974468696,
      "learning_rate": 1.0794280931713724e-05,
      "loss": 2.063,
      "step": 1754
    },
    {
      "epoch": 0.702,
      "grad_norm": 0.381692101902276,
      "learning_rate": 1.0767642093840932e-05,
      "loss": 2.0996,
      "step": 1755
    },
    {
      "epoch": 0.7024,
      "grad_norm": 0.37522885322219773,
      "learning_rate": 1.0741027142497655e-05,
      "loss": 2.126,
      "step": 1756
    },
    {
      "epoch": 0.7028,
      "grad_norm": 0.3995353212783117,
      "learning_rate": 1.071443612235243e-05,
      "loss": 2.2061,
      "step": 1757
    },
    {
      "epoch": 0.7032,
      "grad_norm": 0.3773681511514403,
      "learning_rate": 1.0687869078033662e-05,
      "loss": 2.082,
      "step": 1758
    },
    {
      "epoch": 0.7036,
      "grad_norm": 0.38799040750691116,
      "learning_rate": 1.0661326054129481e-05,
      "loss": 2.0977,
      "step": 1759
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.3799774025552471,
      "learning_rate": 1.0634807095187737e-05,
      "loss": 2.0913,
      "step": 1760
    },
    {
      "epoch": 0.7044,
      "grad_norm": 0.3860714882089478,
      "learning_rate": 1.060831224571587e-05,
      "loss": 2.1196,
      "step": 1761
    },
    {
      "epoch": 0.7048,
      "grad_norm": 0.4044366949573386,
      "learning_rate": 1.0581841550180852e-05,
      "loss": 2.0649,
      "step": 1762
    },
    {
      "epoch": 0.7052,
      "grad_norm": 0.4170416893256213,
      "learning_rate": 1.0555395053009143e-05,
      "loss": 2.1562,
      "step": 1763
    },
    {
      "epoch": 0.7056,
      "grad_norm": 0.38261088039014046,
      "learning_rate": 1.0528972798586556e-05,
      "loss": 2.0029,
      "step": 1764
    },
    {
      "epoch": 0.706,
      "grad_norm": 0.37893105189078774,
      "learning_rate": 1.0502574831258259e-05,
      "loss": 2.1304,
      "step": 1765
    },
    {
      "epoch": 0.7064,
      "grad_norm": 0.3762804340731901,
      "learning_rate": 1.0476201195328609e-05,
      "loss": 2.0327,
      "step": 1766
    },
    {
      "epoch": 0.7068,
      "grad_norm": 0.3982189682557236,
      "learning_rate": 1.0449851935061172e-05,
      "loss": 2.1152,
      "step": 1767
    },
    {
      "epoch": 0.7072,
      "grad_norm": 0.3997612950953163,
      "learning_rate": 1.0423527094678568e-05,
      "loss": 2.2402,
      "step": 1768
    },
    {
      "epoch": 0.7076,
      "grad_norm": 0.38422700036358964,
      "learning_rate": 1.0397226718362465e-05,
      "loss": 2.1133,
      "step": 1769
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.40552543194774343,
      "learning_rate": 1.0370950850253449e-05,
      "loss": 2.2002,
      "step": 1770
    },
    {
      "epoch": 0.7084,
      "grad_norm": 0.39271400723606265,
      "learning_rate": 1.034469953445097e-05,
      "loss": 2.1484,
      "step": 1771
    },
    {
      "epoch": 0.7088,
      "grad_norm": 0.37796411114702844,
      "learning_rate": 1.0318472815013297e-05,
      "loss": 2.085,
      "step": 1772
    },
    {
      "epoch": 0.7092,
      "grad_norm": 0.39631027719845763,
      "learning_rate": 1.0292270735957388e-05,
      "loss": 2.1221,
      "step": 1773
    },
    {
      "epoch": 0.7096,
      "grad_norm": 0.3921346562151896,
      "learning_rate": 1.0266093341258875e-05,
      "loss": 2.1509,
      "step": 1774
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.40104140372597524,
      "learning_rate": 1.0239940674851941e-05,
      "loss": 2.1602,
      "step": 1775
    },
    {
      "epoch": 0.7104,
      "grad_norm": 0.389931833867585,
      "learning_rate": 1.0213812780629264e-05,
      "loss": 2.2319,
      "step": 1776
    },
    {
      "epoch": 0.7108,
      "grad_norm": 0.4041879381255814,
      "learning_rate": 1.0187709702441969e-05,
      "loss": 2.1284,
      "step": 1777
    },
    {
      "epoch": 0.7112,
      "grad_norm": 0.38418895919594453,
      "learning_rate": 1.016163148409952e-05,
      "loss": 2.0288,
      "step": 1778
    },
    {
      "epoch": 0.7116,
      "grad_norm": 0.3963121827986719,
      "learning_rate": 1.0135578169369654e-05,
      "loss": 2.1333,
      "step": 1779
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.386694228990906,
      "learning_rate": 1.0109549801978305e-05,
      "loss": 2.0713,
      "step": 1780
    },
    {
      "epoch": 0.7124,
      "grad_norm": 0.4007535383954483,
      "learning_rate": 1.0083546425609546e-05,
      "loss": 2.1655,
      "step": 1781
    },
    {
      "epoch": 0.7128,
      "grad_norm": 0.384066786930899,
      "learning_rate": 1.0057568083905516e-05,
      "loss": 2.0205,
      "step": 1782
    },
    {
      "epoch": 0.7132,
      "grad_norm": 0.38952022950418086,
      "learning_rate": 1.0031614820466332e-05,
      "loss": 2.1787,
      "step": 1783
    },
    {
      "epoch": 0.7136,
      "grad_norm": 0.3725843290801196,
      "learning_rate": 1.0005686678850015e-05,
      "loss": 2.1772,
      "step": 1784
    },
    {
      "epoch": 0.714,
      "grad_norm": 0.3894032378884946,
      "learning_rate": 9.979783702572412e-06,
      "loss": 2.1191,
      "step": 1785
    },
    {
      "epoch": 0.7144,
      "grad_norm": 0.395073884583244,
      "learning_rate": 9.953905935107165e-06,
      "loss": 2.1777,
      "step": 1786
    },
    {
      "epoch": 0.7148,
      "grad_norm": 0.3848413686983789,
      "learning_rate": 9.928053419885596e-06,
      "loss": 2.084,
      "step": 1787
    },
    {
      "epoch": 0.7152,
      "grad_norm": 0.3823337639615191,
      "learning_rate": 9.902226200296632e-06,
      "loss": 2.1221,
      "step": 1788
    },
    {
      "epoch": 0.7156,
      "grad_norm": 0.38543810456162564,
      "learning_rate": 9.876424319686758e-06,
      "loss": 2.1284,
      "step": 1789
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.39927644881833907,
      "learning_rate": 9.850647821359918e-06,
      "loss": 2.3228,
      "step": 1790
    },
    {
      "epoch": 0.7164,
      "grad_norm": 0.39133241270929214,
      "learning_rate": 9.824896748577475e-06,
      "loss": 2.1699,
      "step": 1791
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.38937045676708554,
      "learning_rate": 9.799171144558119e-06,
      "loss": 2.1587,
      "step": 1792
    },
    {
      "epoch": 0.7172,
      "grad_norm": 0.3965066651308378,
      "learning_rate": 9.773471052477783e-06,
      "loss": 2.1494,
      "step": 1793
    },
    {
      "epoch": 0.7176,
      "grad_norm": 0.3864010390575523,
      "learning_rate": 9.747796515469578e-06,
      "loss": 2.1538,
      "step": 1794
    },
    {
      "epoch": 0.718,
      "grad_norm": 0.3781595984754456,
      "learning_rate": 9.722147576623743e-06,
      "loss": 2.0767,
      "step": 1795
    },
    {
      "epoch": 0.7184,
      "grad_norm": 0.3873922096334172,
      "learning_rate": 9.696524278987554e-06,
      "loss": 2.1958,
      "step": 1796
    },
    {
      "epoch": 0.7188,
      "grad_norm": 0.3816527462129764,
      "learning_rate": 9.670926665565236e-06,
      "loss": 2.1519,
      "step": 1797
    },
    {
      "epoch": 0.7192,
      "grad_norm": 0.39945754856225263,
      "learning_rate": 9.64535477931792e-06,
      "loss": 2.0996,
      "step": 1798
    },
    {
      "epoch": 0.7196,
      "grad_norm": 0.3852853443566026,
      "learning_rate": 9.619808663163544e-06,
      "loss": 2.0664,
      "step": 1799
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3811392249293702,
      "learning_rate": 9.594288359976817e-06,
      "loss": 2.0767,
      "step": 1800
    },
    {
      "epoch": 0.7204,
      "grad_norm": 0.39970790238562903,
      "learning_rate": 9.568793912589121e-06,
      "loss": 2.1304,
      "step": 1801
    },
    {
      "epoch": 0.7208,
      "grad_norm": 0.3915416296966335,
      "learning_rate": 9.543325363788436e-06,
      "loss": 2.0381,
      "step": 1802
    },
    {
      "epoch": 0.7212,
      "grad_norm": 0.38504339504123586,
      "learning_rate": 9.51788275631926e-06,
      "loss": 2.146,
      "step": 1803
    },
    {
      "epoch": 0.7216,
      "grad_norm": 0.4008922036243204,
      "learning_rate": 9.492466132882586e-06,
      "loss": 2.1084,
      "step": 1804
    },
    {
      "epoch": 0.722,
      "grad_norm": 0.3951948866488851,
      "learning_rate": 9.467075536135787e-06,
      "loss": 2.0464,
      "step": 1805
    },
    {
      "epoch": 0.7224,
      "grad_norm": 0.3862730104489712,
      "learning_rate": 9.441711008692538e-06,
      "loss": 2.0913,
      "step": 1806
    },
    {
      "epoch": 0.7228,
      "grad_norm": 0.3884069137928527,
      "learning_rate": 9.41637259312278e-06,
      "loss": 2.0835,
      "step": 1807
    },
    {
      "epoch": 0.7232,
      "grad_norm": 0.3943470490076456,
      "learning_rate": 9.391060331952608e-06,
      "loss": 2.1235,
      "step": 1808
    },
    {
      "epoch": 0.7236,
      "grad_norm": 0.3968820615237652,
      "learning_rate": 9.36577426766425e-06,
      "loss": 2.0933,
      "step": 1809
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.4020416889761336,
      "learning_rate": 9.340514442695952e-06,
      "loss": 2.2134,
      "step": 1810
    },
    {
      "epoch": 0.7244,
      "grad_norm": 0.39625148858892606,
      "learning_rate": 9.315280899441926e-06,
      "loss": 2.1279,
      "step": 1811
    },
    {
      "epoch": 0.7248,
      "grad_norm": 0.3894336645235267,
      "learning_rate": 9.290073680252257e-06,
      "loss": 2.1265,
      "step": 1812
    },
    {
      "epoch": 0.7252,
      "grad_norm": 0.4022745730407448,
      "learning_rate": 9.264892827432872e-06,
      "loss": 2.1328,
      "step": 1813
    },
    {
      "epoch": 0.7256,
      "grad_norm": 0.3958276616045102,
      "learning_rate": 9.23973838324545e-06,
      "loss": 2.1753,
      "step": 1814
    },
    {
      "epoch": 0.726,
      "grad_norm": 0.3861068262202507,
      "learning_rate": 9.214610389907327e-06,
      "loss": 2.0737,
      "step": 1815
    },
    {
      "epoch": 0.7264,
      "grad_norm": 0.3813623133914576,
      "learning_rate": 9.189508889591456e-06,
      "loss": 2.1299,
      "step": 1816
    },
    {
      "epoch": 0.7268,
      "grad_norm": 0.3843018622415095,
      "learning_rate": 9.164433924426316e-06,
      "loss": 2.0625,
      "step": 1817
    },
    {
      "epoch": 0.7272,
      "grad_norm": 0.3884591911029973,
      "learning_rate": 9.139385536495873e-06,
      "loss": 2.1865,
      "step": 1818
    },
    {
      "epoch": 0.7276,
      "grad_norm": 0.37767919656022647,
      "learning_rate": 9.114363767839479e-06,
      "loss": 2.0845,
      "step": 1819
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.3796729111998414,
      "learning_rate": 9.0893686604518e-06,
      "loss": 2.0508,
      "step": 1820
    },
    {
      "epoch": 0.7284,
      "grad_norm": 0.3894993727250871,
      "learning_rate": 9.064400256282757e-06,
      "loss": 2.0356,
      "step": 1821
    },
    {
      "epoch": 0.7288,
      "grad_norm": 0.40403382043305197,
      "learning_rate": 9.039458597237477e-06,
      "loss": 2.1782,
      "step": 1822
    },
    {
      "epoch": 0.7292,
      "grad_norm": 0.3981480851373299,
      "learning_rate": 9.01454372517616e-06,
      "loss": 2.0913,
      "step": 1823
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.4007341754751401,
      "learning_rate": 8.989655681914094e-06,
      "loss": 2.2114,
      "step": 1824
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3909677419707814,
      "learning_rate": 8.964794509221508e-06,
      "loss": 2.1958,
      "step": 1825
    },
    {
      "epoch": 0.7304,
      "grad_norm": 0.40177754818635847,
      "learning_rate": 8.939960248823534e-06,
      "loss": 2.2437,
      "step": 1826
    },
    {
      "epoch": 0.7308,
      "grad_norm": 0.41472913040521475,
      "learning_rate": 8.91515294240015e-06,
      "loss": 2.1489,
      "step": 1827
    },
    {
      "epoch": 0.7312,
      "grad_norm": 0.3946494527672622,
      "learning_rate": 8.890372631586108e-06,
      "loss": 2.0938,
      "step": 1828
    },
    {
      "epoch": 0.7316,
      "grad_norm": 0.3785478696202225,
      "learning_rate": 8.86561935797082e-06,
      "loss": 2.1533,
      "step": 1829
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.37336324346773936,
      "learning_rate": 8.840893163098331e-06,
      "loss": 2.1079,
      "step": 1830
    },
    {
      "epoch": 0.7324,
      "grad_norm": 0.39807491914070875,
      "learning_rate": 8.81619408846726e-06,
      "loss": 2.2227,
      "step": 1831
    },
    {
      "epoch": 0.7328,
      "grad_norm": 0.38913839364917796,
      "learning_rate": 8.791522175530684e-06,
      "loss": 2.1426,
      "step": 1832
    },
    {
      "epoch": 0.7332,
      "grad_norm": 0.3827910791470182,
      "learning_rate": 8.766877465696113e-06,
      "loss": 2.0596,
      "step": 1833
    },
    {
      "epoch": 0.7336,
      "grad_norm": 0.38428276921235643,
      "learning_rate": 8.742260000325377e-06,
      "loss": 2.0225,
      "step": 1834
    },
    {
      "epoch": 0.734,
      "grad_norm": 0.38167386034905754,
      "learning_rate": 8.71766982073462e-06,
      "loss": 2.0986,
      "step": 1835
    },
    {
      "epoch": 0.7344,
      "grad_norm": 0.37197977570390706,
      "learning_rate": 8.69310696819415e-06,
      "loss": 2.0947,
      "step": 1836
    },
    {
      "epoch": 0.7348,
      "grad_norm": 0.385150674346394,
      "learning_rate": 8.668571483928428e-06,
      "loss": 2.1128,
      "step": 1837
    },
    {
      "epoch": 0.7352,
      "grad_norm": 0.3900501552392867,
      "learning_rate": 8.644063409115998e-06,
      "loss": 2.1216,
      "step": 1838
    },
    {
      "epoch": 0.7356,
      "grad_norm": 0.3930117386608535,
      "learning_rate": 8.61958278488937e-06,
      "loss": 2.1758,
      "step": 1839
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.3733983435800901,
      "learning_rate": 8.595129652335019e-06,
      "loss": 2.1479,
      "step": 1840
    },
    {
      "epoch": 0.7364,
      "grad_norm": 0.39687548581197973,
      "learning_rate": 8.570704052493239e-06,
      "loss": 2.1255,
      "step": 1841
    },
    {
      "epoch": 0.7368,
      "grad_norm": 0.3654561812043444,
      "learning_rate": 8.546306026358164e-06,
      "loss": 2.0864,
      "step": 1842
    },
    {
      "epoch": 0.7372,
      "grad_norm": 0.3813399551614305,
      "learning_rate": 8.5219356148776e-06,
      "loss": 2.1499,
      "step": 1843
    },
    {
      "epoch": 0.7376,
      "grad_norm": 0.389755498868791,
      "learning_rate": 8.497592858953047e-06,
      "loss": 2.0801,
      "step": 1844
    },
    {
      "epoch": 0.738,
      "grad_norm": 0.39036954701566623,
      "learning_rate": 8.47327779943957e-06,
      "loss": 2.1587,
      "step": 1845
    },
    {
      "epoch": 0.7384,
      "grad_norm": 0.3952901456442129,
      "learning_rate": 8.44899047714574e-06,
      "loss": 2.2085,
      "step": 1846
    },
    {
      "epoch": 0.7388,
      "grad_norm": 0.37708397569143964,
      "learning_rate": 8.424730932833613e-06,
      "loss": 2.1436,
      "step": 1847
    },
    {
      "epoch": 0.7392,
      "grad_norm": 0.37929329447962806,
      "learning_rate": 8.400499207218582e-06,
      "loss": 2.1538,
      "step": 1848
    },
    {
      "epoch": 0.7396,
      "grad_norm": 0.3830333429510761,
      "learning_rate": 8.376295340969384e-06,
      "loss": 2.0684,
      "step": 1849
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.38696796179513365,
      "learning_rate": 8.352119374707978e-06,
      "loss": 2.0972,
      "step": 1850
    },
    {
      "epoch": 0.7404,
      "grad_norm": 0.4002580478012322,
      "learning_rate": 8.3279713490095e-06,
      "loss": 2.1572,
      "step": 1851
    },
    {
      "epoch": 0.7408,
      "grad_norm": 0.3910215528880651,
      "learning_rate": 8.303851304402207e-06,
      "loss": 2.0698,
      "step": 1852
    },
    {
      "epoch": 0.7412,
      "grad_norm": 0.3832715581627067,
      "learning_rate": 8.279759281367389e-06,
      "loss": 2.1562,
      "step": 1853
    },
    {
      "epoch": 0.7416,
      "grad_norm": 0.376623529774043,
      "learning_rate": 8.255695320339296e-06,
      "loss": 2.1289,
      "step": 1854
    },
    {
      "epoch": 0.742,
      "grad_norm": 0.38482046096708517,
      "learning_rate": 8.23165946170509e-06,
      "loss": 2.1211,
      "step": 1855
    },
    {
      "epoch": 0.7424,
      "grad_norm": 0.3741219039153118,
      "learning_rate": 8.207651745804758e-06,
      "loss": 2.1895,
      "step": 1856
    },
    {
      "epoch": 0.7428,
      "grad_norm": 0.3776261086666924,
      "learning_rate": 8.183672212931068e-06,
      "loss": 2.1162,
      "step": 1857
    },
    {
      "epoch": 0.7432,
      "grad_norm": 0.3806712282613305,
      "learning_rate": 8.159720903329493e-06,
      "loss": 2.1416,
      "step": 1858
    },
    {
      "epoch": 0.7436,
      "grad_norm": 0.3884120956914185,
      "learning_rate": 8.135797857198116e-06,
      "loss": 2.2061,
      "step": 1859
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.3747503479329202,
      "learning_rate": 8.111903114687591e-06,
      "loss": 2.2363,
      "step": 1860
    },
    {
      "epoch": 0.7444,
      "grad_norm": 0.3925302400859148,
      "learning_rate": 8.08803671590108e-06,
      "loss": 2.1904,
      "step": 1861
    },
    {
      "epoch": 0.7448,
      "grad_norm": 0.3724638612736714,
      "learning_rate": 8.064198700894176e-06,
      "loss": 2.1187,
      "step": 1862
    },
    {
      "epoch": 0.7452,
      "grad_norm": 0.38152574441282655,
      "learning_rate": 8.040389109674826e-06,
      "loss": 2.103,
      "step": 1863
    },
    {
      "epoch": 0.7456,
      "grad_norm": 0.38208926313058483,
      "learning_rate": 8.016607982203268e-06,
      "loss": 2.125,
      "step": 1864
    },
    {
      "epoch": 0.746,
      "grad_norm": 0.3802959443803465,
      "learning_rate": 7.992855358391967e-06,
      "loss": 2.231,
      "step": 1865
    },
    {
      "epoch": 0.7464,
      "grad_norm": 0.3751947197595907,
      "learning_rate": 7.969131278105571e-06,
      "loss": 2.1021,
      "step": 1866
    },
    {
      "epoch": 0.7468,
      "grad_norm": 0.3816784322361727,
      "learning_rate": 7.945435781160815e-06,
      "loss": 2.1509,
      "step": 1867
    },
    {
      "epoch": 0.7472,
      "grad_norm": 0.37680302040684804,
      "learning_rate": 7.921768907326447e-06,
      "loss": 2.1558,
      "step": 1868
    },
    {
      "epoch": 0.7476,
      "grad_norm": 0.40022744971005947,
      "learning_rate": 7.898130696323177e-06,
      "loss": 2.0859,
      "step": 1869
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.3902480098238687,
      "learning_rate": 7.87452118782363e-06,
      "loss": 2.1157,
      "step": 1870
    },
    {
      "epoch": 0.7484,
      "grad_norm": 0.3784711342367781,
      "learning_rate": 7.850940421452252e-06,
      "loss": 2.1187,
      "step": 1871
    },
    {
      "epoch": 0.7488,
      "grad_norm": 0.3713165104299666,
      "learning_rate": 7.827388436785236e-06,
      "loss": 2.1084,
      "step": 1872
    },
    {
      "epoch": 0.7492,
      "grad_norm": 0.38419657376745137,
      "learning_rate": 7.803865273350477e-06,
      "loss": 2.125,
      "step": 1873
    },
    {
      "epoch": 0.7496,
      "grad_norm": 0.37306422698591973,
      "learning_rate": 7.780370970627498e-06,
      "loss": 2.1675,
      "step": 1874
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.378011785421618,
      "learning_rate": 7.756905568047393e-06,
      "loss": 2.1812,
      "step": 1875
    },
    {
      "epoch": 0.7504,
      "grad_norm": 0.3812416591234789,
      "learning_rate": 7.733469104992753e-06,
      "loss": 2.1099,
      "step": 1876
    },
    {
      "epoch": 0.7508,
      "grad_norm": 0.3795328297127274,
      "learning_rate": 7.710061620797585e-06,
      "loss": 2.104,
      "step": 1877
    },
    {
      "epoch": 0.7512,
      "grad_norm": 0.36280242954313907,
      "learning_rate": 7.686683154747257e-06,
      "loss": 2.0791,
      "step": 1878
    },
    {
      "epoch": 0.7516,
      "grad_norm": 0.3761576899714602,
      "learning_rate": 7.663333746078452e-06,
      "loss": 2.1099,
      "step": 1879
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.3800964263549746,
      "learning_rate": 7.640013433979093e-06,
      "loss": 2.0923,
      "step": 1880
    },
    {
      "epoch": 0.7524,
      "grad_norm": 0.3860613498141556,
      "learning_rate": 7.616722257588243e-06,
      "loss": 2.1655,
      "step": 1881
    },
    {
      "epoch": 0.7528,
      "grad_norm": 0.391755385954046,
      "learning_rate": 7.593460255996077e-06,
      "loss": 2.2056,
      "step": 1882
    },
    {
      "epoch": 0.7532,
      "grad_norm": 0.3696959258684484,
      "learning_rate": 7.570227468243798e-06,
      "loss": 2.1177,
      "step": 1883
    },
    {
      "epoch": 0.7536,
      "grad_norm": 0.37530100715166576,
      "learning_rate": 7.5470239333235965e-06,
      "loss": 2.0557,
      "step": 1884
    },
    {
      "epoch": 0.754,
      "grad_norm": 0.3790770682983469,
      "learning_rate": 7.523849690178567e-06,
      "loss": 2.1167,
      "step": 1885
    },
    {
      "epoch": 0.7544,
      "grad_norm": 0.3834150977481504,
      "learning_rate": 7.500704777702619e-06,
      "loss": 2.1738,
      "step": 1886
    },
    {
      "epoch": 0.7548,
      "grad_norm": 0.38054878935139924,
      "learning_rate": 7.477589234740446e-06,
      "loss": 2.0942,
      "step": 1887
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.3848561742650356,
      "learning_rate": 7.454503100087462e-06,
      "loss": 2.2671,
      "step": 1888
    },
    {
      "epoch": 0.7556,
      "grad_norm": 0.39445944846912545,
      "learning_rate": 7.431446412489723e-06,
      "loss": 2.1064,
      "step": 1889
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.3742295086285137,
      "learning_rate": 7.408419210643847e-06,
      "loss": 2.1792,
      "step": 1890
    },
    {
      "epoch": 0.7564,
      "grad_norm": 0.38077550908947383,
      "learning_rate": 7.385421533196976e-06,
      "loss": 2.082,
      "step": 1891
    },
    {
      "epoch": 0.7568,
      "grad_norm": 0.3818913195324202,
      "learning_rate": 7.362453418746692e-06,
      "loss": 2.1631,
      "step": 1892
    },
    {
      "epoch": 0.7572,
      "grad_norm": 0.3721452443555616,
      "learning_rate": 7.339514905840975e-06,
      "loss": 2.1592,
      "step": 1893
    },
    {
      "epoch": 0.7576,
      "grad_norm": 0.3897639834483888,
      "learning_rate": 7.316606032978124e-06,
      "loss": 2.2373,
      "step": 1894
    },
    {
      "epoch": 0.758,
      "grad_norm": 0.3841458609850713,
      "learning_rate": 7.293726838606674e-06,
      "loss": 2.0928,
      "step": 1895
    },
    {
      "epoch": 0.7584,
      "grad_norm": 0.38017944331668496,
      "learning_rate": 7.270877361125358e-06,
      "loss": 2.1396,
      "step": 1896
    },
    {
      "epoch": 0.7588,
      "grad_norm": 0.3759843706405232,
      "learning_rate": 7.248057638883052e-06,
      "loss": 2.1313,
      "step": 1897
    },
    {
      "epoch": 0.7592,
      "grad_norm": 0.38895751876228135,
      "learning_rate": 7.225267710178662e-06,
      "loss": 2.2095,
      "step": 1898
    },
    {
      "epoch": 0.7596,
      "grad_norm": 0.38954010663135513,
      "learning_rate": 7.2025076132611196e-06,
      "loss": 2.1631,
      "step": 1899
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.37688151210440013,
      "learning_rate": 7.179777386329276e-06,
      "loss": 2.1191,
      "step": 1900
    },
    {
      "epoch": 0.7604,
      "grad_norm": 0.3760999681790913,
      "learning_rate": 7.157077067531834e-06,
      "loss": 2.1958,
      "step": 1901
    },
    {
      "epoch": 0.7608,
      "grad_norm": 0.3956830809654275,
      "learning_rate": 7.13440669496733e-06,
      "loss": 2.2061,
      "step": 1902
    },
    {
      "epoch": 0.7612,
      "grad_norm": 0.3765426061843053,
      "learning_rate": 7.11176630668404e-06,
      "loss": 2.1772,
      "step": 1903
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.37367613580677306,
      "learning_rate": 7.089155940679893e-06,
      "loss": 2.1309,
      "step": 1904
    },
    {
      "epoch": 0.762,
      "grad_norm": 0.37836623292894533,
      "learning_rate": 7.066575634902436e-06,
      "loss": 2.1953,
      "step": 1905
    },
    {
      "epoch": 0.7624,
      "grad_norm": 0.37070992121150487,
      "learning_rate": 7.044025427248793e-06,
      "loss": 2.0928,
      "step": 1906
    },
    {
      "epoch": 0.7628,
      "grad_norm": 0.3782040131014002,
      "learning_rate": 7.0215053555655305e-06,
      "loss": 2.168,
      "step": 1907
    },
    {
      "epoch": 0.7632,
      "grad_norm": 0.3874695650762311,
      "learning_rate": 6.999015457648678e-06,
      "loss": 2.1304,
      "step": 1908
    },
    {
      "epoch": 0.7636,
      "grad_norm": 0.38123266516638193,
      "learning_rate": 6.976555771243601e-06,
      "loss": 2.126,
      "step": 1909
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.3832106592820327,
      "learning_rate": 6.9541263340449496e-06,
      "loss": 2.2471,
      "step": 1910
    },
    {
      "epoch": 0.7644,
      "grad_norm": 0.37469379923057233,
      "learning_rate": 6.93172718369664e-06,
      "loss": 2.0596,
      "step": 1911
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.37201249007372555,
      "learning_rate": 6.909358357791726e-06,
      "loss": 1.9995,
      "step": 1912
    },
    {
      "epoch": 0.7652,
      "grad_norm": 0.3760859017655203,
      "learning_rate": 6.8870198938723875e-06,
      "loss": 2.1548,
      "step": 1913
    },
    {
      "epoch": 0.7656,
      "grad_norm": 0.3872670752502471,
      "learning_rate": 6.864711829429826e-06,
      "loss": 2.1216,
      "step": 1914
    },
    {
      "epoch": 0.766,
      "grad_norm": 0.3851087518340576,
      "learning_rate": 6.842434201904255e-06,
      "loss": 2.085,
      "step": 1915
    },
    {
      "epoch": 0.7664,
      "grad_norm": 0.3884656346339144,
      "learning_rate": 6.82018704868477e-06,
      "loss": 2.1089,
      "step": 1916
    },
    {
      "epoch": 0.7668,
      "grad_norm": 0.3819697190981866,
      "learning_rate": 6.797970407109333e-06,
      "loss": 2.1904,
      "step": 1917
    },
    {
      "epoch": 0.7672,
      "grad_norm": 0.3734902363454278,
      "learning_rate": 6.775784314464717e-06,
      "loss": 2.0571,
      "step": 1918
    },
    {
      "epoch": 0.7676,
      "grad_norm": 0.38118277042456444,
      "learning_rate": 6.753628807986389e-06,
      "loss": 2.2524,
      "step": 1919
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.3848024668220421,
      "learning_rate": 6.731503924858518e-06,
      "loss": 2.21,
      "step": 1920
    },
    {
      "epoch": 0.7684,
      "grad_norm": 0.3706597795961235,
      "learning_rate": 6.709409702213845e-06,
      "loss": 2.0957,
      "step": 1921
    },
    {
      "epoch": 0.7688,
      "grad_norm": 0.39295397630313483,
      "learning_rate": 6.68734617713368e-06,
      "loss": 2.1777,
      "step": 1922
    },
    {
      "epoch": 0.7692,
      "grad_norm": 0.38268732746169054,
      "learning_rate": 6.665313386647789e-06,
      "loss": 2.1152,
      "step": 1923
    },
    {
      "epoch": 0.7696,
      "grad_norm": 0.39003308711801277,
      "learning_rate": 6.643311367734381e-06,
      "loss": 2.2026,
      "step": 1924
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3782851002841872,
      "learning_rate": 6.621340157319997e-06,
      "loss": 2.1724,
      "step": 1925
    },
    {
      "epoch": 0.7704,
      "grad_norm": 0.3730905692281843,
      "learning_rate": 6.59939979227947e-06,
      "loss": 2.0488,
      "step": 1926
    },
    {
      "epoch": 0.7708,
      "grad_norm": 0.36821543077283275,
      "learning_rate": 6.577490309435896e-06,
      "loss": 2.0957,
      "step": 1927
    },
    {
      "epoch": 0.7712,
      "grad_norm": 0.381494908697265,
      "learning_rate": 6.5556117455605e-06,
      "loss": 2.2358,
      "step": 1928
    },
    {
      "epoch": 0.7716,
      "grad_norm": 0.3726377723166518,
      "learning_rate": 6.53376413737265e-06,
      "loss": 2.1011,
      "step": 1929
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.36584218564001786,
      "learning_rate": 6.511947521539738e-06,
      "loss": 2.042,
      "step": 1930
    },
    {
      "epoch": 0.7724,
      "grad_norm": 0.36513612951503616,
      "learning_rate": 6.490161934677139e-06,
      "loss": 2.0908,
      "step": 1931
    },
    {
      "epoch": 0.7728,
      "grad_norm": 0.3779489501187007,
      "learning_rate": 6.468407413348162e-06,
      "loss": 2.1562,
      "step": 1932
    },
    {
      "epoch": 0.7732,
      "grad_norm": 0.3787585778162009,
      "learning_rate": 6.446683994063993e-06,
      "loss": 2.1748,
      "step": 1933
    },
    {
      "epoch": 0.7736,
      "grad_norm": 0.3834634059215117,
      "learning_rate": 6.424991713283584e-06,
      "loss": 2.2339,
      "step": 1934
    },
    {
      "epoch": 0.774,
      "grad_norm": 0.383220042551438,
      "learning_rate": 6.403330607413643e-06,
      "loss": 2.147,
      "step": 1935
    },
    {
      "epoch": 0.7744,
      "grad_norm": 0.3833893331389792,
      "learning_rate": 6.381700712808567e-06,
      "loss": 2.1968,
      "step": 1936
    },
    {
      "epoch": 0.7748,
      "grad_norm": 0.392325112912716,
      "learning_rate": 6.360102065770346e-06,
      "loss": 2.1826,
      "step": 1937
    },
    {
      "epoch": 0.7752,
      "grad_norm": 0.37596084309768374,
      "learning_rate": 6.338534702548557e-06,
      "loss": 2.2144,
      "step": 1938
    },
    {
      "epoch": 0.7756,
      "grad_norm": 0.3707351646136205,
      "learning_rate": 6.316998659340248e-06,
      "loss": 2.0229,
      "step": 1939
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.37828850897136024,
      "learning_rate": 6.295493972289904e-06,
      "loss": 2.1484,
      "step": 1940
    },
    {
      "epoch": 0.7764,
      "grad_norm": 0.36498926449633773,
      "learning_rate": 6.274020677489395e-06,
      "loss": 2.0479,
      "step": 1941
    },
    {
      "epoch": 0.7768,
      "grad_norm": 0.36393874151219124,
      "learning_rate": 6.252578810977907e-06,
      "loss": 2.02,
      "step": 1942
    },
    {
      "epoch": 0.7772,
      "grad_norm": 0.37116422208117883,
      "learning_rate": 6.2311684087418665e-06,
      "loss": 2.0908,
      "step": 1943
    },
    {
      "epoch": 0.7776,
      "grad_norm": 0.3872076795152448,
      "learning_rate": 6.209789506714897e-06,
      "loss": 2.1338,
      "step": 1944
    },
    {
      "epoch": 0.778,
      "grad_norm": 0.3835163928629289,
      "learning_rate": 6.188442140777742e-06,
      "loss": 2.2114,
      "step": 1945
    },
    {
      "epoch": 0.7784,
      "grad_norm": 0.3700601149241194,
      "learning_rate": 6.1671263467582566e-06,
      "loss": 2.1372,
      "step": 1946
    },
    {
      "epoch": 0.7788,
      "grad_norm": 0.38668198768254364,
      "learning_rate": 6.1458421604312695e-06,
      "loss": 2.21,
      "step": 1947
    },
    {
      "epoch": 0.7792,
      "grad_norm": 0.3728656376858881,
      "learning_rate": 6.124589617518575e-06,
      "loss": 2.1206,
      "step": 1948
    },
    {
      "epoch": 0.7796,
      "grad_norm": 0.3753959821026065,
      "learning_rate": 6.103368753688848e-06,
      "loss": 2.0762,
      "step": 1949
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.36528851571193405,
      "learning_rate": 6.082179604557617e-06,
      "loss": 2.0679,
      "step": 1950
    },
    {
      "epoch": 0.7804,
      "grad_norm": 0.3771176720913316,
      "learning_rate": 6.061022205687175e-06,
      "loss": 2.1079,
      "step": 1951
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.3898548125840145,
      "learning_rate": 6.039896592586522e-06,
      "loss": 2.207,
      "step": 1952
    },
    {
      "epoch": 0.7812,
      "grad_norm": 0.3886123953200304,
      "learning_rate": 6.018802800711307e-06,
      "loss": 2.1343,
      "step": 1953
    },
    {
      "epoch": 0.7816,
      "grad_norm": 0.3666868057784607,
      "learning_rate": 5.997740865463769e-06,
      "loss": 2.1758,
      "step": 1954
    },
    {
      "epoch": 0.782,
      "grad_norm": 0.379210683696802,
      "learning_rate": 5.9767108221927216e-06,
      "loss": 2.2725,
      "step": 1955
    },
    {
      "epoch": 0.7824,
      "grad_norm": 0.36428266522600183,
      "learning_rate": 5.955712706193406e-06,
      "loss": 2.0498,
      "step": 1956
    },
    {
      "epoch": 0.7828,
      "grad_norm": 0.37646471833655837,
      "learning_rate": 5.934746552707498e-06,
      "loss": 2.1577,
      "step": 1957
    },
    {
      "epoch": 0.7832,
      "grad_norm": 0.37025923854502824,
      "learning_rate": 5.913812396923018e-06,
      "loss": 2.0586,
      "step": 1958
    },
    {
      "epoch": 0.7836,
      "grad_norm": 0.36848712747926127,
      "learning_rate": 5.892910273974306e-06,
      "loss": 2.061,
      "step": 1959
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.36494457469690006,
      "learning_rate": 5.872040218941929e-06,
      "loss": 2.0894,
      "step": 1960
    },
    {
      "epoch": 0.7844,
      "grad_norm": 0.3680465037885723,
      "learning_rate": 5.851202266852631e-06,
      "loss": 2.0879,
      "step": 1961
    },
    {
      "epoch": 0.7848,
      "grad_norm": 0.3882553787650748,
      "learning_rate": 5.830396452679279e-06,
      "loss": 2.1855,
      "step": 1962
    },
    {
      "epoch": 0.7852,
      "grad_norm": 0.37081290647081633,
      "learning_rate": 5.809622811340787e-06,
      "loss": 2.1162,
      "step": 1963
    },
    {
      "epoch": 0.7856,
      "grad_norm": 0.37647254266213703,
      "learning_rate": 5.788881377702113e-06,
      "loss": 2.1245,
      "step": 1964
    },
    {
      "epoch": 0.786,
      "grad_norm": 0.3787871188300641,
      "learning_rate": 5.768172186574122e-06,
      "loss": 2.0537,
      "step": 1965
    },
    {
      "epoch": 0.7864,
      "grad_norm": 0.39079371325247786,
      "learning_rate": 5.747495272713576e-06,
      "loss": 2.1782,
      "step": 1966
    },
    {
      "epoch": 0.7868,
      "grad_norm": 0.38271994480003313,
      "learning_rate": 5.726850670823067e-06,
      "loss": 2.1943,
      "step": 1967
    },
    {
      "epoch": 0.7872,
      "grad_norm": 0.36832344376253784,
      "learning_rate": 5.7062384155509575e-06,
      "loss": 2.1382,
      "step": 1968
    },
    {
      "epoch": 0.7876,
      "grad_norm": 0.37984501056276393,
      "learning_rate": 5.685658541491329e-06,
      "loss": 2.1514,
      "step": 1969
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.37694784894652555,
      "learning_rate": 5.665111083183905e-06,
      "loss": 2.1792,
      "step": 1970
    },
    {
      "epoch": 0.7884,
      "grad_norm": 0.3732400617698364,
      "learning_rate": 5.644596075114003e-06,
      "loss": 2.0737,
      "step": 1971
    },
    {
      "epoch": 0.7888,
      "grad_norm": 0.37435584728873617,
      "learning_rate": 5.624113551712495e-06,
      "loss": 2.1313,
      "step": 1972
    },
    {
      "epoch": 0.7892,
      "grad_norm": 0.3794300529410517,
      "learning_rate": 5.603663547355712e-06,
      "loss": 2.1382,
      "step": 1973
    },
    {
      "epoch": 0.7896,
      "grad_norm": 0.3776115501987995,
      "learning_rate": 5.58324609636543e-06,
      "loss": 2.106,
      "step": 1974
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.37553887355241045,
      "learning_rate": 5.562861233008774e-06,
      "loss": 2.1338,
      "step": 1975
    },
    {
      "epoch": 0.7904,
      "grad_norm": 0.37249713754158703,
      "learning_rate": 5.542508991498169e-06,
      "loss": 2.0869,
      "step": 1976
    },
    {
      "epoch": 0.7908,
      "grad_norm": 0.3764323715640433,
      "learning_rate": 5.5221894059913155e-06,
      "loss": 2.1343,
      "step": 1977
    },
    {
      "epoch": 0.7912,
      "grad_norm": 0.38280095902963907,
      "learning_rate": 5.501902510591084e-06,
      "loss": 2.2407,
      "step": 1978
    },
    {
      "epoch": 0.7916,
      "grad_norm": 0.3795499974721084,
      "learning_rate": 5.481648339345499e-06,
      "loss": 2.1255,
      "step": 1979
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.377463365446996,
      "learning_rate": 5.46142692624764e-06,
      "loss": 2.0806,
      "step": 1980
    },
    {
      "epoch": 0.7924,
      "grad_norm": 0.38670658608225306,
      "learning_rate": 5.441238305235635e-06,
      "loss": 2.1602,
      "step": 1981
    },
    {
      "epoch": 0.7928,
      "grad_norm": 0.3773456443131433,
      "learning_rate": 5.421082510192546e-06,
      "loss": 2.1885,
      "step": 1982
    },
    {
      "epoch": 0.7932,
      "grad_norm": 0.3717156821938912,
      "learning_rate": 5.400959574946371e-06,
      "loss": 2.0815,
      "step": 1983
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.3725026128168528,
      "learning_rate": 5.380869533269944e-06,
      "loss": 2.084,
      "step": 1984
    },
    {
      "epoch": 0.794,
      "grad_norm": 0.37799599029818487,
      "learning_rate": 5.360812418880884e-06,
      "loss": 2.1602,
      "step": 1985
    },
    {
      "epoch": 0.7944,
      "grad_norm": 0.3840159298632796,
      "learning_rate": 5.340788265441573e-06,
      "loss": 2.2012,
      "step": 1986
    },
    {
      "epoch": 0.7948,
      "grad_norm": 0.3717862903806878,
      "learning_rate": 5.3207971065590445e-06,
      "loss": 2.0254,
      "step": 1987
    },
    {
      "epoch": 0.7952,
      "grad_norm": 0.3857137519101544,
      "learning_rate": 5.300838975784983e-06,
      "loss": 2.1738,
      "step": 1988
    },
    {
      "epoch": 0.7956,
      "grad_norm": 0.37394130855567587,
      "learning_rate": 5.28091390661562e-06,
      "loss": 2.1533,
      "step": 1989
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.3658272641523285,
      "learning_rate": 5.261021932491714e-06,
      "loss": 2.0522,
      "step": 1990
    },
    {
      "epoch": 0.7964,
      "grad_norm": 0.3740067683006874,
      "learning_rate": 5.241163086798473e-06,
      "loss": 2.1011,
      "step": 1991
    },
    {
      "epoch": 0.7968,
      "grad_norm": 0.3734665876177317,
      "learning_rate": 5.221337402865492e-06,
      "loss": 2.1348,
      "step": 1992
    },
    {
      "epoch": 0.7972,
      "grad_norm": 0.36331191506849236,
      "learning_rate": 5.2015449139667414e-06,
      "loss": 2.0791,
      "step": 1993
    },
    {
      "epoch": 0.7976,
      "grad_norm": 0.3676402815980159,
      "learning_rate": 5.181785653320442e-06,
      "loss": 2.105,
      "step": 1994
    },
    {
      "epoch": 0.798,
      "grad_norm": 0.3837451847378657,
      "learning_rate": 5.162059654089083e-06,
      "loss": 2.1973,
      "step": 1995
    },
    {
      "epoch": 0.7984,
      "grad_norm": 0.3787232103032452,
      "learning_rate": 5.142366949379293e-06,
      "loss": 2.1968,
      "step": 1996
    },
    {
      "epoch": 0.7988,
      "grad_norm": 0.3789558510917065,
      "learning_rate": 5.122707572241861e-06,
      "loss": 2.1348,
      "step": 1997
    },
    {
      "epoch": 0.7992,
      "grad_norm": 0.3734616762582333,
      "learning_rate": 5.103081555671604e-06,
      "loss": 2.0659,
      "step": 1998
    },
    {
      "epoch": 0.7996,
      "grad_norm": 0.36118426163623835,
      "learning_rate": 5.08348893260738e-06,
      "loss": 2.0874,
      "step": 1999
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3776541340466109,
      "learning_rate": 5.063929735931985e-06,
      "loss": 2.2261,
      "step": 2000
    },
    {
      "epoch": 0.8004,
      "grad_norm": 0.3640107567859002,
      "learning_rate": 5.0444039984721055e-06,
      "loss": 2.0557,
      "step": 2001
    },
    {
      "epoch": 0.8008,
      "grad_norm": 0.3762164750242816,
      "learning_rate": 5.024911752998304e-06,
      "loss": 2.1089,
      "step": 2002
    },
    {
      "epoch": 0.8012,
      "grad_norm": 0.364904817488954,
      "learning_rate": 5.0054530322249e-06,
      "loss": 2.0732,
      "step": 2003
    },
    {
      "epoch": 0.8016,
      "grad_norm": 0.38013847710425475,
      "learning_rate": 4.986027868809967e-06,
      "loss": 2.1665,
      "step": 2004
    },
    {
      "epoch": 0.802,
      "grad_norm": 0.3857734911681079,
      "learning_rate": 4.966636295355253e-06,
      "loss": 2.2222,
      "step": 2005
    },
    {
      "epoch": 0.8024,
      "grad_norm": 0.39834191069407165,
      "learning_rate": 4.9472783444061255e-06,
      "loss": 1.9858,
      "step": 2006
    },
    {
      "epoch": 0.8028,
      "grad_norm": 0.36611276021842193,
      "learning_rate": 4.927954048451527e-06,
      "loss": 2.106,
      "step": 2007
    },
    {
      "epoch": 0.8032,
      "grad_norm": 0.3834993904350031,
      "learning_rate": 4.90866343992393e-06,
      "loss": 2.2036,
      "step": 2008
    },
    {
      "epoch": 0.8036,
      "grad_norm": 0.37343578547914275,
      "learning_rate": 4.889406551199247e-06,
      "loss": 2.1416,
      "step": 2009
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.3731795250069197,
      "learning_rate": 4.870183414596794e-06,
      "loss": 2.1655,
      "step": 2010
    },
    {
      "epoch": 0.8044,
      "grad_norm": 0.36618468714501706,
      "learning_rate": 4.850994062379271e-06,
      "loss": 2.1211,
      "step": 2011
    },
    {
      "epoch": 0.8048,
      "grad_norm": 0.3702430529323665,
      "learning_rate": 4.8318385267526415e-06,
      "loss": 2.0933,
      "step": 2012
    },
    {
      "epoch": 0.8052,
      "grad_norm": 0.37245397816421927,
      "learning_rate": 4.812716839866144e-06,
      "loss": 2.1621,
      "step": 2013
    },
    {
      "epoch": 0.8056,
      "grad_norm": 0.37223553071842863,
      "learning_rate": 4.793629033812186e-06,
      "loss": 2.1118,
      "step": 2014
    },
    {
      "epoch": 0.806,
      "grad_norm": 0.37169286455799666,
      "learning_rate": 4.7745751406263165e-06,
      "loss": 2.1353,
      "step": 2015
    },
    {
      "epoch": 0.8064,
      "grad_norm": 0.3751708699756962,
      "learning_rate": 4.755555192287173e-06,
      "loss": 2.1191,
      "step": 2016
    },
    {
      "epoch": 0.8068,
      "grad_norm": 0.3642503615505487,
      "learning_rate": 4.7365692207164275e-06,
      "loss": 2.0566,
      "step": 2017
    },
    {
      "epoch": 0.8072,
      "grad_norm": 0.3770068012587172,
      "learning_rate": 4.717617257778717e-06,
      "loss": 2.1216,
      "step": 2018
    },
    {
      "epoch": 0.8076,
      "grad_norm": 0.3824039836701709,
      "learning_rate": 4.698699335281601e-06,
      "loss": 2.1294,
      "step": 2019
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.3712734049440809,
      "learning_rate": 4.679815484975505e-06,
      "loss": 2.1143,
      "step": 2020
    },
    {
      "epoch": 0.8084,
      "grad_norm": 0.3770690512413519,
      "learning_rate": 4.6609657385536884e-06,
      "loss": 2.2246,
      "step": 2021
    },
    {
      "epoch": 0.8088,
      "grad_norm": 0.37514367555006944,
      "learning_rate": 4.642150127652165e-06,
      "loss": 2.1382,
      "step": 2022
    },
    {
      "epoch": 0.8092,
      "grad_norm": 0.3739794215443333,
      "learning_rate": 4.623368683849644e-06,
      "loss": 2.1333,
      "step": 2023
    },
    {
      "epoch": 0.8096,
      "grad_norm": 0.3749256067874677,
      "learning_rate": 4.604621438667503e-06,
      "loss": 2.1187,
      "step": 2024
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.37664270081885715,
      "learning_rate": 4.585908423569724e-06,
      "loss": 2.1602,
      "step": 2025
    },
    {
      "epoch": 0.8104,
      "grad_norm": 0.3648299884382593,
      "learning_rate": 4.567229669962847e-06,
      "loss": 2.0835,
      "step": 2026
    },
    {
      "epoch": 0.8108,
      "grad_norm": 0.38029636127328675,
      "learning_rate": 4.548585209195891e-06,
      "loss": 2.1333,
      "step": 2027
    },
    {
      "epoch": 0.8112,
      "grad_norm": 0.3829309844530174,
      "learning_rate": 4.529975072560333e-06,
      "loss": 2.2173,
      "step": 2028
    },
    {
      "epoch": 0.8116,
      "grad_norm": 0.38112056851150977,
      "learning_rate": 4.511399291290033e-06,
      "loss": 2.1514,
      "step": 2029
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.38131818479370894,
      "learning_rate": 4.492857896561204e-06,
      "loss": 2.1738,
      "step": 2030
    },
    {
      "epoch": 0.8124,
      "grad_norm": 0.388983547812371,
      "learning_rate": 4.474350919492351e-06,
      "loss": 2.0542,
      "step": 2031
    },
    {
      "epoch": 0.8128,
      "grad_norm": 0.3746743492943584,
      "learning_rate": 4.455878391144197e-06,
      "loss": 2.1323,
      "step": 2032
    },
    {
      "epoch": 0.8132,
      "grad_norm": 0.36560542090092935,
      "learning_rate": 4.437440342519652e-06,
      "loss": 2.0894,
      "step": 2033
    },
    {
      "epoch": 0.8136,
      "grad_norm": 0.38103037234357584,
      "learning_rate": 4.419036804563773e-06,
      "loss": 2.1201,
      "step": 2034
    },
    {
      "epoch": 0.814,
      "grad_norm": 0.3728713837666926,
      "learning_rate": 4.4006678081636884e-06,
      "loss": 2.1123,
      "step": 2035
    },
    {
      "epoch": 0.8144,
      "grad_norm": 0.36992431299583567,
      "learning_rate": 4.382333384148554e-06,
      "loss": 2.1514,
      "step": 2036
    },
    {
      "epoch": 0.8148,
      "grad_norm": 0.37916346845121185,
      "learning_rate": 4.364033563289494e-06,
      "loss": 2.2266,
      "step": 2037
    },
    {
      "epoch": 0.8152,
      "grad_norm": 0.37008590704495425,
      "learning_rate": 4.345768376299564e-06,
      "loss": 2.146,
      "step": 2038
    },
    {
      "epoch": 0.8156,
      "grad_norm": 0.37969017724614224,
      "learning_rate": 4.3275378538336994e-06,
      "loss": 2.1211,
      "step": 2039
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.37213351372267744,
      "learning_rate": 4.309342026488653e-06,
      "loss": 2.0176,
      "step": 2040
    },
    {
      "epoch": 0.8164,
      "grad_norm": 0.3767966238817884,
      "learning_rate": 4.291180924802945e-06,
      "loss": 2.1255,
      "step": 2041
    },
    {
      "epoch": 0.8168,
      "grad_norm": 0.37353523813015005,
      "learning_rate": 4.273054579256808e-06,
      "loss": 2.0898,
      "step": 2042
    },
    {
      "epoch": 0.8172,
      "grad_norm": 0.3677195391388266,
      "learning_rate": 4.254963020272154e-06,
      "loss": 2.1172,
      "step": 2043
    },
    {
      "epoch": 0.8176,
      "grad_norm": 0.36998491759058766,
      "learning_rate": 4.236906278212518e-06,
      "loss": 2.084,
      "step": 2044
    },
    {
      "epoch": 0.818,
      "grad_norm": 0.38958621841470126,
      "learning_rate": 4.218884383382987e-06,
      "loss": 2.0845,
      "step": 2045
    },
    {
      "epoch": 0.8184,
      "grad_norm": 0.394124284376886,
      "learning_rate": 4.20089736603016e-06,
      "loss": 2.1636,
      "step": 2046
    },
    {
      "epoch": 0.8188,
      "grad_norm": 0.3680940804318898,
      "learning_rate": 4.182945256342105e-06,
      "loss": 2.0938,
      "step": 2047
    },
    {
      "epoch": 0.8192,
      "grad_norm": 0.3801226590067457,
      "learning_rate": 4.165028084448314e-06,
      "loss": 2.186,
      "step": 2048
    },
    {
      "epoch": 0.8196,
      "grad_norm": 0.3637637212684739,
      "learning_rate": 4.147145880419634e-06,
      "loss": 2.1406,
      "step": 2049
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.37614784458058964,
      "learning_rate": 4.129298674268225e-06,
      "loss": 2.1904,
      "step": 2050
    },
    {
      "epoch": 0.8204,
      "grad_norm": 0.37498945100191666,
      "learning_rate": 4.111486495947497e-06,
      "loss": 2.2056,
      "step": 2051
    },
    {
      "epoch": 0.8208,
      "grad_norm": 0.3641024448588234,
      "learning_rate": 4.093709375352101e-06,
      "loss": 2.125,
      "step": 2052
    },
    {
      "epoch": 0.8212,
      "grad_norm": 0.37755381267341476,
      "learning_rate": 4.075967342317816e-06,
      "loss": 2.1221,
      "step": 2053
    },
    {
      "epoch": 0.8216,
      "grad_norm": 0.3774953792014703,
      "learning_rate": 4.058260426621563e-06,
      "loss": 2.0874,
      "step": 2054
    },
    {
      "epoch": 0.822,
      "grad_norm": 0.3750006492737029,
      "learning_rate": 4.040588657981301e-06,
      "loss": 2.1357,
      "step": 2055
    },
    {
      "epoch": 0.8224,
      "grad_norm": 0.3783901304489226,
      "learning_rate": 4.02295206605601e-06,
      "loss": 2.1748,
      "step": 2056
    },
    {
      "epoch": 0.8228,
      "grad_norm": 0.3828314126772624,
      "learning_rate": 4.005350680445633e-06,
      "loss": 2.1934,
      "step": 2057
    },
    {
      "epoch": 0.8232,
      "grad_norm": 0.36926254180883555,
      "learning_rate": 3.987784530691033e-06,
      "loss": 2.1543,
      "step": 2058
    },
    {
      "epoch": 0.8236,
      "grad_norm": 0.37411348188407356,
      "learning_rate": 3.970253646273925e-06,
      "loss": 2.1587,
      "step": 2059
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.3643110072724043,
      "learning_rate": 3.952758056616826e-06,
      "loss": 2.0806,
      "step": 2060
    },
    {
      "epoch": 0.8244,
      "grad_norm": 0.3706651430978312,
      "learning_rate": 3.935297791083048e-06,
      "loss": 2.1035,
      "step": 2061
    },
    {
      "epoch": 0.8248,
      "grad_norm": 0.39229241665540215,
      "learning_rate": 3.917872878976589e-06,
      "loss": 2.1255,
      "step": 2062
    },
    {
      "epoch": 0.8252,
      "grad_norm": 0.3659023884485663,
      "learning_rate": 3.9004833495421305e-06,
      "loss": 2.0791,
      "step": 2063
    },
    {
      "epoch": 0.8256,
      "grad_norm": 0.3682165208110633,
      "learning_rate": 3.883129231964963e-06,
      "loss": 2.0396,
      "step": 2064
    },
    {
      "epoch": 0.826,
      "grad_norm": 0.3662341103870271,
      "learning_rate": 3.865810555370936e-06,
      "loss": 2.1357,
      "step": 2065
    },
    {
      "epoch": 0.8264,
      "grad_norm": 0.367155281005798,
      "learning_rate": 3.848527348826439e-06,
      "loss": 2.1133,
      "step": 2066
    },
    {
      "epoch": 0.8268,
      "grad_norm": 0.37215952823109283,
      "learning_rate": 3.8312796413383086e-06,
      "loss": 2.1382,
      "step": 2067
    },
    {
      "epoch": 0.8272,
      "grad_norm": 0.38052106016845577,
      "learning_rate": 3.8140674618538207e-06,
      "loss": 2.2793,
      "step": 2068
    },
    {
      "epoch": 0.8276,
      "grad_norm": 0.36902264803269647,
      "learning_rate": 3.7968908392606057e-06,
      "loss": 2.1372,
      "step": 2069
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.3638173928889696,
      "learning_rate": 3.7797498023866396e-06,
      "loss": 2.0601,
      "step": 2070
    },
    {
      "epoch": 0.8284,
      "grad_norm": 0.38518220899003264,
      "learning_rate": 3.762644380000152e-06,
      "loss": 2.1606,
      "step": 2071
    },
    {
      "epoch": 0.8288,
      "grad_norm": 0.38322790912689825,
      "learning_rate": 3.7455746008096178e-06,
      "loss": 2.085,
      "step": 2072
    },
    {
      "epoch": 0.8292,
      "grad_norm": 0.3727979446871411,
      "learning_rate": 3.728540493463678e-06,
      "loss": 2.1084,
      "step": 2073
    },
    {
      "epoch": 0.8296,
      "grad_norm": 0.3777070682457663,
      "learning_rate": 3.7115420865511063e-06,
      "loss": 2.0991,
      "step": 2074
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.36224707596665,
      "learning_rate": 3.694579408600771e-06,
      "loss": 2.082,
      "step": 2075
    },
    {
      "epoch": 0.8304,
      "grad_norm": 0.3771102189898241,
      "learning_rate": 3.6776524880815595e-06,
      "loss": 2.1455,
      "step": 2076
    },
    {
      "epoch": 0.8308,
      "grad_norm": 0.3675160175420977,
      "learning_rate": 3.6607613534023644e-06,
      "loss": 2.1226,
      "step": 2077
    },
    {
      "epoch": 0.8312,
      "grad_norm": 0.36383259824483605,
      "learning_rate": 3.6439060329119977e-06,
      "loss": 2.1299,
      "step": 2078
    },
    {
      "epoch": 0.8316,
      "grad_norm": 0.3668062570102723,
      "learning_rate": 3.627086554899181e-06,
      "loss": 2.0815,
      "step": 2079
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.3615778753808046,
      "learning_rate": 3.6103029475924726e-06,
      "loss": 2.0771,
      "step": 2080
    },
    {
      "epoch": 0.8324,
      "grad_norm": 0.36685837594252435,
      "learning_rate": 3.593555239160223e-06,
      "loss": 2.1162,
      "step": 2081
    },
    {
      "epoch": 0.8328,
      "grad_norm": 0.36196311015672256,
      "learning_rate": 3.5768434577105435e-06,
      "loss": 2.0483,
      "step": 2082
    },
    {
      "epoch": 0.8332,
      "grad_norm": 0.3847469394950935,
      "learning_rate": 3.5601676312912474e-06,
      "loss": 2.2051,
      "step": 2083
    },
    {
      "epoch": 0.8336,
      "grad_norm": 0.3662425294068005,
      "learning_rate": 3.5435277878897972e-06,
      "loss": 2.1396,
      "step": 2084
    },
    {
      "epoch": 0.834,
      "grad_norm": 0.38065351584535406,
      "learning_rate": 3.5269239554332563e-06,
      "loss": 2.2446,
      "step": 2085
    },
    {
      "epoch": 0.8344,
      "grad_norm": 0.37231837442266863,
      "learning_rate": 3.510356161788278e-06,
      "loss": 2.1152,
      "step": 2086
    },
    {
      "epoch": 0.8348,
      "grad_norm": 0.36146455053303106,
      "learning_rate": 3.493824434760998e-06,
      "loss": 2.0708,
      "step": 2087
    },
    {
      "epoch": 0.8352,
      "grad_norm": 0.3720450199249925,
      "learning_rate": 3.477328802097046e-06,
      "loss": 2.085,
      "step": 2088
    },
    {
      "epoch": 0.8356,
      "grad_norm": 0.37612427728735764,
      "learning_rate": 3.460869291481461e-06,
      "loss": 2.1377,
      "step": 2089
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.36547625895478947,
      "learning_rate": 3.4444459305386507e-06,
      "loss": 2.0322,
      "step": 2090
    },
    {
      "epoch": 0.8364,
      "grad_norm": 0.36934596157586463,
      "learning_rate": 3.4280587468323716e-06,
      "loss": 2.2192,
      "step": 2091
    },
    {
      "epoch": 0.8368,
      "grad_norm": 0.3572697331665531,
      "learning_rate": 3.4117077678656518e-06,
      "loss": 2.0454,
      "step": 2092
    },
    {
      "epoch": 0.8372,
      "grad_norm": 0.37552628237731456,
      "learning_rate": 3.3953930210807533e-06,
      "loss": 2.1064,
      "step": 2093
    },
    {
      "epoch": 0.8376,
      "grad_norm": 0.3771898744849965,
      "learning_rate": 3.3791145338591346e-06,
      "loss": 2.1938,
      "step": 2094
    },
    {
      "epoch": 0.838,
      "grad_norm": 0.3690417404397475,
      "learning_rate": 3.3628723335213885e-06,
      "loss": 2.1045,
      "step": 2095
    },
    {
      "epoch": 0.8384,
      "grad_norm": 0.36525182068396395,
      "learning_rate": 3.3466664473272207e-06,
      "loss": 2.1328,
      "step": 2096
    },
    {
      "epoch": 0.8388,
      "grad_norm": 0.38786666861427754,
      "learning_rate": 3.3304969024753885e-06,
      "loss": 2.1743,
      "step": 2097
    },
    {
      "epoch": 0.8392,
      "grad_norm": 0.3697872941048309,
      "learning_rate": 3.314363726103645e-06,
      "loss": 2.1416,
      "step": 2098
    },
    {
      "epoch": 0.8396,
      "grad_norm": 0.37489307402348243,
      "learning_rate": 3.2982669452887083e-06,
      "loss": 2.1128,
      "step": 2099
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.371497616930891,
      "learning_rate": 3.2822065870462217e-06,
      "loss": 2.0513,
      "step": 2100
    },
    {
      "epoch": 0.8404,
      "grad_norm": 0.37074456028155317,
      "learning_rate": 3.266182678330698e-06,
      "loss": 2.0972,
      "step": 2101
    },
    {
      "epoch": 0.8408,
      "grad_norm": 0.36501471566613936,
      "learning_rate": 3.25019524603547e-06,
      "loss": 2.0254,
      "step": 2102
    },
    {
      "epoch": 0.8412,
      "grad_norm": 0.36631910355295144,
      "learning_rate": 3.234244316992649e-06,
      "loss": 2.0737,
      "step": 2103
    },
    {
      "epoch": 0.8416,
      "grad_norm": 0.3682476905668674,
      "learning_rate": 3.2183299179730843e-06,
      "loss": 2.1016,
      "step": 2104
    },
    {
      "epoch": 0.842,
      "grad_norm": 0.37447252662573316,
      "learning_rate": 3.2024520756863243e-06,
      "loss": 2.0835,
      "step": 2105
    },
    {
      "epoch": 0.8424,
      "grad_norm": 0.37325118327251594,
      "learning_rate": 3.186610816780558e-06,
      "loss": 2.1201,
      "step": 2106
    },
    {
      "epoch": 0.8428,
      "grad_norm": 0.3599966541840819,
      "learning_rate": 3.1708061678425714e-06,
      "loss": 2.0601,
      "step": 2107
    },
    {
      "epoch": 0.8432,
      "grad_norm": 0.3599305177018485,
      "learning_rate": 3.1550381553977047e-06,
      "loss": 2.0889,
      "step": 2108
    },
    {
      "epoch": 0.8436,
      "grad_norm": 0.36320021959483423,
      "learning_rate": 3.1393068059098224e-06,
      "loss": 2.124,
      "step": 2109
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.3789785399865868,
      "learning_rate": 3.1236121457812544e-06,
      "loss": 2.1289,
      "step": 2110
    },
    {
      "epoch": 0.8444,
      "grad_norm": 0.35655292868865224,
      "learning_rate": 3.1079542013527417e-06,
      "loss": 2.0317,
      "step": 2111
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.36521210928032427,
      "learning_rate": 3.092332998903416e-06,
      "loss": 2.1011,
      "step": 2112
    },
    {
      "epoch": 0.8452,
      "grad_norm": 0.36527775207397895,
      "learning_rate": 3.0767485646507306e-06,
      "loss": 2.1357,
      "step": 2113
    },
    {
      "epoch": 0.8456,
      "grad_norm": 0.3649174157237006,
      "learning_rate": 3.0612009247504458e-06,
      "loss": 2.0322,
      "step": 2114
    },
    {
      "epoch": 0.846,
      "grad_norm": 0.36621876911679885,
      "learning_rate": 3.0456901052965724e-06,
      "loss": 2.1611,
      "step": 2115
    },
    {
      "epoch": 0.8464,
      "grad_norm": 0.3685665238133229,
      "learning_rate": 3.0302161323213006e-06,
      "loss": 2.0815,
      "step": 2116
    },
    {
      "epoch": 0.8468,
      "grad_norm": 0.36621441708143976,
      "learning_rate": 3.014779031794998e-06,
      "loss": 2.0483,
      "step": 2117
    },
    {
      "epoch": 0.8472,
      "grad_norm": 0.3748654961732493,
      "learning_rate": 2.9993788296261426e-06,
      "loss": 2.1333,
      "step": 2118
    },
    {
      "epoch": 0.8476,
      "grad_norm": 0.37055926654132554,
      "learning_rate": 2.9840155516612955e-06,
      "loss": 2.1943,
      "step": 2119
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.3791110737770855,
      "learning_rate": 2.9686892236850337e-06,
      "loss": 2.1206,
      "step": 2120
    },
    {
      "epoch": 0.8484,
      "grad_norm": 0.37786071258285553,
      "learning_rate": 2.953399871419921e-06,
      "loss": 2.1367,
      "step": 2121
    },
    {
      "epoch": 0.8488,
      "grad_norm": 0.36955005901553234,
      "learning_rate": 2.938147520526466e-06,
      "loss": 2.0967,
      "step": 2122
    },
    {
      "epoch": 0.8492,
      "grad_norm": 0.3642324786678671,
      "learning_rate": 2.922932196603079e-06,
      "loss": 2.1411,
      "step": 2123
    },
    {
      "epoch": 0.8496,
      "grad_norm": 0.3670276812677826,
      "learning_rate": 2.907753925186038e-06,
      "loss": 2.1787,
      "step": 2124
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3759648502520564,
      "learning_rate": 2.892612731749414e-06,
      "loss": 2.1392,
      "step": 2125
    },
    {
      "epoch": 0.8504,
      "grad_norm": 0.37552896681333303,
      "learning_rate": 2.877508641705051e-06,
      "loss": 2.1753,
      "step": 2126
    },
    {
      "epoch": 0.8508,
      "grad_norm": 0.3785012428935607,
      "learning_rate": 2.8624416804025472e-06,
      "loss": 2.1211,
      "step": 2127
    },
    {
      "epoch": 0.8512,
      "grad_norm": 0.3603022502708238,
      "learning_rate": 2.8474118731291495e-06,
      "loss": 2.0361,
      "step": 2128
    },
    {
      "epoch": 0.8516,
      "grad_norm": 0.3689543681146944,
      "learning_rate": 2.8324192451097827e-06,
      "loss": 2.0952,
      "step": 2129
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.3631335620677338,
      "learning_rate": 2.8174638215069493e-06,
      "loss": 2.0537,
      "step": 2130
    },
    {
      "epoch": 0.8524,
      "grad_norm": 0.3684805461969634,
      "learning_rate": 2.8025456274207135e-06,
      "loss": 2.1025,
      "step": 2131
    },
    {
      "epoch": 0.8528,
      "grad_norm": 0.3672130733718322,
      "learning_rate": 2.7876646878886662e-06,
      "loss": 2.1802,
      "step": 2132
    },
    {
      "epoch": 0.8532,
      "grad_norm": 0.3622344107471349,
      "learning_rate": 2.7728210278858746e-06,
      "loss": 1.9727,
      "step": 2133
    },
    {
      "epoch": 0.8536,
      "grad_norm": 0.3720297977329075,
      "learning_rate": 2.758014672324824e-06,
      "loss": 2.0757,
      "step": 2134
    },
    {
      "epoch": 0.854,
      "grad_norm": 0.371018735448687,
      "learning_rate": 2.743245646055398e-06,
      "loss": 2.0767,
      "step": 2135
    },
    {
      "epoch": 0.8544,
      "grad_norm": 0.3577823431541398,
      "learning_rate": 2.728513973864838e-06,
      "loss": 2.0625,
      "step": 2136
    },
    {
      "epoch": 0.8548,
      "grad_norm": 0.36979138267718337,
      "learning_rate": 2.713819680477675e-06,
      "loss": 2.0718,
      "step": 2137
    },
    {
      "epoch": 0.8552,
      "grad_norm": 0.36697166341243215,
      "learning_rate": 2.699162790555729e-06,
      "loss": 2.1558,
      "step": 2138
    },
    {
      "epoch": 0.8556,
      "grad_norm": 0.37685774060497096,
      "learning_rate": 2.684543328698025e-06,
      "loss": 2.1162,
      "step": 2139
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.364726361229739,
      "learning_rate": 2.6699613194407725e-06,
      "loss": 2.1587,
      "step": 2140
    },
    {
      "epoch": 0.8564,
      "grad_norm": 0.369453373873538,
      "learning_rate": 2.6554167872573447e-06,
      "loss": 2.166,
      "step": 2141
    },
    {
      "epoch": 0.8568,
      "grad_norm": 0.37358201399014224,
      "learning_rate": 2.640909756558185e-06,
      "loss": 2.1465,
      "step": 2142
    },
    {
      "epoch": 0.8572,
      "grad_norm": 0.3648168842665773,
      "learning_rate": 2.6264402516908286e-06,
      "loss": 2.0801,
      "step": 2143
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.36343949516014945,
      "learning_rate": 2.6120082969398053e-06,
      "loss": 2.0981,
      "step": 2144
    },
    {
      "epoch": 0.858,
      "grad_norm": 0.3759257756673278,
      "learning_rate": 2.597613916526637e-06,
      "loss": 2.1724,
      "step": 2145
    },
    {
      "epoch": 0.8584,
      "grad_norm": 0.36645340625469314,
      "learning_rate": 2.5832571346097736e-06,
      "loss": 2.2139,
      "step": 2146
    },
    {
      "epoch": 0.8588,
      "grad_norm": 0.36696062802597196,
      "learning_rate": 2.56893797528458e-06,
      "loss": 2.1294,
      "step": 2147
    },
    {
      "epoch": 0.8592,
      "grad_norm": 0.35944026927850625,
      "learning_rate": 2.5546564625832602e-06,
      "loss": 2.0859,
      "step": 2148
    },
    {
      "epoch": 0.8596,
      "grad_norm": 0.36891132341546784,
      "learning_rate": 2.5404126204748355e-06,
      "loss": 2.1484,
      "step": 2149
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.37283997859664214,
      "learning_rate": 2.52620647286512e-06,
      "loss": 2.2129,
      "step": 2150
    },
    {
      "epoch": 0.8604,
      "grad_norm": 0.366505821809769,
      "learning_rate": 2.5120380435966456e-06,
      "loss": 2.0908,
      "step": 2151
    },
    {
      "epoch": 0.8608,
      "grad_norm": 0.3708100352582146,
      "learning_rate": 2.497907356448656e-06,
      "loss": 2.145,
      "step": 2152
    },
    {
      "epoch": 0.8612,
      "grad_norm": 0.37724851302816453,
      "learning_rate": 2.4838144351370357e-06,
      "loss": 2.1562,
      "step": 2153
    },
    {
      "epoch": 0.8616,
      "grad_norm": 0.3699478983663544,
      "learning_rate": 2.4697593033143033e-06,
      "loss": 2.1855,
      "step": 2154
    },
    {
      "epoch": 0.862,
      "grad_norm": 0.36035277831606266,
      "learning_rate": 2.4557419845695427e-06,
      "loss": 2.1714,
      "step": 2155
    },
    {
      "epoch": 0.8624,
      "grad_norm": 0.3636665502873354,
      "learning_rate": 2.4417625024283685e-06,
      "loss": 2.0767,
      "step": 2156
    },
    {
      "epoch": 0.8628,
      "grad_norm": 0.3595982869299948,
      "learning_rate": 2.4278208803529186e-06,
      "loss": 2.1377,
      "step": 2157
    },
    {
      "epoch": 0.8632,
      "grad_norm": 0.36962336165919657,
      "learning_rate": 2.413917141741756e-06,
      "loss": 2.0903,
      "step": 2158
    },
    {
      "epoch": 0.8636,
      "grad_norm": 0.36937591682515697,
      "learning_rate": 2.400051309929896e-06,
      "loss": 2.1157,
      "step": 2159
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.3773544807228001,
      "learning_rate": 2.3862234081887036e-06,
      "loss": 2.0928,
      "step": 2160
    },
    {
      "epoch": 0.8644,
      "grad_norm": 0.35835640811109454,
      "learning_rate": 2.3724334597259118e-06,
      "loss": 2.022,
      "step": 2161
    },
    {
      "epoch": 0.8648,
      "grad_norm": 0.37071983243272,
      "learning_rate": 2.3586814876855294e-06,
      "loss": 2.1509,
      "step": 2162
    },
    {
      "epoch": 0.8652,
      "grad_norm": 0.36210932925656,
      "learning_rate": 2.3449675151478585e-06,
      "loss": 2.1108,
      "step": 2163
    },
    {
      "epoch": 0.8656,
      "grad_norm": 0.36611978241923415,
      "learning_rate": 2.331291565129398e-06,
      "loss": 2.1392,
      "step": 2164
    },
    {
      "epoch": 0.866,
      "grad_norm": 0.36273480718071693,
      "learning_rate": 2.317653660582844e-06,
      "loss": 2.1274,
      "step": 2165
    },
    {
      "epoch": 0.8664,
      "grad_norm": 0.3545188978357561,
      "learning_rate": 2.3040538243970457e-06,
      "loss": 2.0757,
      "step": 2166
    },
    {
      "epoch": 0.8668,
      "grad_norm": 0.36038365046622983,
      "learning_rate": 2.290492079396947e-06,
      "loss": 2.0796,
      "step": 2167
    },
    {
      "epoch": 0.8672,
      "grad_norm": 0.3677510623118601,
      "learning_rate": 2.2769684483435806e-06,
      "loss": 2.1621,
      "step": 2168
    },
    {
      "epoch": 0.8676,
      "grad_norm": 0.36373985683528054,
      "learning_rate": 2.2634829539339986e-06,
      "loss": 2.1025,
      "step": 2169
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.3639319173076369,
      "learning_rate": 2.250035618801241e-06,
      "loss": 2.1704,
      "step": 2170
    },
    {
      "epoch": 0.8684,
      "grad_norm": 0.3729452347379865,
      "learning_rate": 2.2366264655143214e-06,
      "loss": 2.2119,
      "step": 2171
    },
    {
      "epoch": 0.8688,
      "grad_norm": 0.3653466306880565,
      "learning_rate": 2.223255516578168e-06,
      "loss": 1.9614,
      "step": 2172
    },
    {
      "epoch": 0.8692,
      "grad_norm": 0.35216615514523575,
      "learning_rate": 2.2099227944335806e-06,
      "loss": 2.0498,
      "step": 2173
    },
    {
      "epoch": 0.8696,
      "grad_norm": 0.367571856406117,
      "learning_rate": 2.1966283214572085e-06,
      "loss": 2.1372,
      "step": 2174
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.37161693724165534,
      "learning_rate": 2.183372119961499e-06,
      "loss": 2.1685,
      "step": 2175
    },
    {
      "epoch": 0.8704,
      "grad_norm": 0.36927713242812393,
      "learning_rate": 2.1701542121946777e-06,
      "loss": 2.2026,
      "step": 2176
    },
    {
      "epoch": 0.8708,
      "grad_norm": 0.37197230795634023,
      "learning_rate": 2.1569746203407043e-06,
      "loss": 2.1958,
      "step": 2177
    },
    {
      "epoch": 0.8712,
      "grad_norm": 0.36105542184554834,
      "learning_rate": 2.1438333665192158e-06,
      "loss": 2.1147,
      "step": 2178
    },
    {
      "epoch": 0.8716,
      "grad_norm": 0.36269504524180585,
      "learning_rate": 2.130730472785508e-06,
      "loss": 2.0059,
      "step": 2179
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.37005969611506323,
      "learning_rate": 2.117665961130513e-06,
      "loss": 2.186,
      "step": 2180
    },
    {
      "epoch": 0.8724,
      "grad_norm": 0.3654746996079733,
      "learning_rate": 2.1046398534807333e-06,
      "loss": 2.1836,
      "step": 2181
    },
    {
      "epoch": 0.8728,
      "grad_norm": 0.3705908383546445,
      "learning_rate": 2.0916521716982136e-06,
      "loss": 2.188,
      "step": 2182
    },
    {
      "epoch": 0.8732,
      "grad_norm": 0.37127531714937195,
      "learning_rate": 2.078702937580515e-06,
      "loss": 2.0918,
      "step": 2183
    },
    {
      "epoch": 0.8736,
      "grad_norm": 0.367823195065325,
      "learning_rate": 2.065792172860656e-06,
      "loss": 2.1221,
      "step": 2184
    },
    {
      "epoch": 0.874,
      "grad_norm": 0.3567488977455527,
      "learning_rate": 2.05291989920712e-06,
      "loss": 2.1104,
      "step": 2185
    },
    {
      "epoch": 0.8744,
      "grad_norm": 0.36335140669849547,
      "learning_rate": 2.040086138223765e-06,
      "loss": 2.1392,
      "step": 2186
    },
    {
      "epoch": 0.8748,
      "grad_norm": 0.36602423144576407,
      "learning_rate": 2.0272909114498166e-06,
      "loss": 2.1909,
      "step": 2187
    },
    {
      "epoch": 0.8752,
      "grad_norm": 0.36256747271475775,
      "learning_rate": 2.014534240359833e-06,
      "loss": 2.1206,
      "step": 2188
    },
    {
      "epoch": 0.8756,
      "grad_norm": 0.36214498960099595,
      "learning_rate": 2.0018161463636583e-06,
      "loss": 2.125,
      "step": 2189
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.36133106809803733,
      "learning_rate": 1.9891366508064003e-06,
      "loss": 2.0542,
      "step": 2190
    },
    {
      "epoch": 0.8764,
      "grad_norm": 0.36112001821502276,
      "learning_rate": 1.976495774968376e-06,
      "loss": 2.1172,
      "step": 2191
    },
    {
      "epoch": 0.8768,
      "grad_norm": 0.37695472382883544,
      "learning_rate": 1.9638935400650926e-06,
      "loss": 2.1587,
      "step": 2192
    },
    {
      "epoch": 0.8772,
      "grad_norm": 0.36247574728941007,
      "learning_rate": 1.9513299672471894e-06,
      "loss": 2.085,
      "step": 2193
    },
    {
      "epoch": 0.8776,
      "grad_norm": 0.36315972670490154,
      "learning_rate": 1.938805077600453e-06,
      "loss": 2.0522,
      "step": 2194
    },
    {
      "epoch": 0.878,
      "grad_norm": 0.3679277228951443,
      "learning_rate": 1.926318892145712e-06,
      "loss": 2.083,
      "step": 2195
    },
    {
      "epoch": 0.8784,
      "grad_norm": 0.35132835153799774,
      "learning_rate": 1.913871431838854e-06,
      "loss": 2.0337,
      "step": 2196
    },
    {
      "epoch": 0.8788,
      "grad_norm": 0.3680918773642306,
      "learning_rate": 1.9014627175707622e-06,
      "loss": 2.2002,
      "step": 2197
    },
    {
      "epoch": 0.8792,
      "grad_norm": 0.35843516269202674,
      "learning_rate": 1.8890927701673056e-06,
      "loss": 2.0312,
      "step": 2198
    },
    {
      "epoch": 0.8796,
      "grad_norm": 0.3661185411642596,
      "learning_rate": 1.8767616103892854e-06,
      "loss": 2.1479,
      "step": 2199
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3661221693685658,
      "learning_rate": 1.864469258932397e-06,
      "loss": 2.1714,
      "step": 2200
    },
    {
      "epoch": 0.8804,
      "grad_norm": 0.3691522438461118,
      "learning_rate": 1.8522157364272097e-06,
      "loss": 2.1104,
      "step": 2201
    },
    {
      "epoch": 0.8808,
      "grad_norm": 0.3653449255522312,
      "learning_rate": 1.8400010634391147e-06,
      "loss": 2.1152,
      "step": 2202
    },
    {
      "epoch": 0.8812,
      "grad_norm": 0.36621383545113645,
      "learning_rate": 1.8278252604683188e-06,
      "loss": 2.0547,
      "step": 2203
    },
    {
      "epoch": 0.8816,
      "grad_norm": 0.35792203162569775,
      "learning_rate": 1.8156883479497817e-06,
      "loss": 2.0771,
      "step": 2204
    },
    {
      "epoch": 0.882,
      "grad_norm": 0.3555823666126556,
      "learning_rate": 1.803590346253195e-06,
      "loss": 2.0308,
      "step": 2205
    },
    {
      "epoch": 0.8824,
      "grad_norm": 0.3695787746532447,
      "learning_rate": 1.7915312756829338e-06,
      "loss": 2.1973,
      "step": 2206
    },
    {
      "epoch": 0.8828,
      "grad_norm": 0.38253698485034593,
      "learning_rate": 1.7795111564780532e-06,
      "loss": 2.0903,
      "step": 2207
    },
    {
      "epoch": 0.8832,
      "grad_norm": 0.35466887351457665,
      "learning_rate": 1.7675300088122265e-06,
      "loss": 2.0454,
      "step": 2208
    },
    {
      "epoch": 0.8836,
      "grad_norm": 0.37444423732886417,
      "learning_rate": 1.7555878527937164e-06,
      "loss": 2.1597,
      "step": 2209
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.36954002835155664,
      "learning_rate": 1.7436847084653456e-06,
      "loss": 2.2075,
      "step": 2210
    },
    {
      "epoch": 0.8844,
      "grad_norm": 0.3628515573465924,
      "learning_rate": 1.731820595804473e-06,
      "loss": 2.1284,
      "step": 2211
    },
    {
      "epoch": 0.8848,
      "grad_norm": 0.3619023482232167,
      "learning_rate": 1.719995534722929e-06,
      "loss": 2.1157,
      "step": 2212
    },
    {
      "epoch": 0.8852,
      "grad_norm": 0.36691670680835636,
      "learning_rate": 1.70820954506703e-06,
      "loss": 2.1558,
      "step": 2213
    },
    {
      "epoch": 0.8856,
      "grad_norm": 0.36329372798648546,
      "learning_rate": 1.6964626466174972e-06,
      "loss": 2.1406,
      "step": 2214
    },
    {
      "epoch": 0.886,
      "grad_norm": 0.35931018312376967,
      "learning_rate": 1.6847548590894435e-06,
      "loss": 2.1152,
      "step": 2215
    },
    {
      "epoch": 0.8864,
      "grad_norm": 0.3685805605511333,
      "learning_rate": 1.6730862021323568e-06,
      "loss": 2.1445,
      "step": 2216
    },
    {
      "epoch": 0.8868,
      "grad_norm": 0.36238774709252664,
      "learning_rate": 1.6614566953300354e-06,
      "loss": 2.1714,
      "step": 2217
    },
    {
      "epoch": 0.8872,
      "grad_norm": 0.372241867015467,
      "learning_rate": 1.649866358200583e-06,
      "loss": 2.0376,
      "step": 2218
    },
    {
      "epoch": 0.8876,
      "grad_norm": 0.3632673885180771,
      "learning_rate": 1.6383152101963534e-06,
      "loss": 2.2026,
      "step": 2219
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.3591480555982487,
      "learning_rate": 1.626803270703936e-06,
      "loss": 2.1494,
      "step": 2220
    },
    {
      "epoch": 0.8884,
      "grad_norm": 0.3690565667025512,
      "learning_rate": 1.6153305590441093e-06,
      "loss": 2.1821,
      "step": 2221
    },
    {
      "epoch": 0.8888,
      "grad_norm": 0.36447672392015645,
      "learning_rate": 1.6038970944718262e-06,
      "loss": 2.1396,
      "step": 2222
    },
    {
      "epoch": 0.8892,
      "grad_norm": 0.38048789865847604,
      "learning_rate": 1.592502896176154e-06,
      "loss": 2.2104,
      "step": 2223
    },
    {
      "epoch": 0.8896,
      "grad_norm": 0.40139205901116565,
      "learning_rate": 1.5811479832802678e-06,
      "loss": 2.1899,
      "step": 2224
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.37659318053308244,
      "learning_rate": 1.5698323748414124e-06,
      "loss": 2.1055,
      "step": 2225
    },
    {
      "epoch": 0.8904,
      "grad_norm": 0.3622685259020049,
      "learning_rate": 1.5585560898508516e-06,
      "loss": 2.1201,
      "step": 2226
    },
    {
      "epoch": 0.8908,
      "grad_norm": 0.3632630795456983,
      "learning_rate": 1.547319147233875e-06,
      "loss": 2.1606,
      "step": 2227
    },
    {
      "epoch": 0.8912,
      "grad_norm": 0.3604196899559701,
      "learning_rate": 1.5361215658497214e-06,
      "loss": 2.0239,
      "step": 2228
    },
    {
      "epoch": 0.8916,
      "grad_norm": 0.3712580802370232,
      "learning_rate": 1.5249633644915856e-06,
      "loss": 2.1479,
      "step": 2229
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.36680816525224286,
      "learning_rate": 1.5138445618865544e-06,
      "loss": 2.1348,
      "step": 2230
    },
    {
      "epoch": 0.8924,
      "grad_norm": 0.362602414752844,
      "learning_rate": 1.5027651766955976e-06,
      "loss": 2.1006,
      "step": 2231
    },
    {
      "epoch": 0.8928,
      "grad_norm": 0.367725176687045,
      "learning_rate": 1.491725227513535e-06,
      "loss": 2.1035,
      "step": 2232
    },
    {
      "epoch": 0.8932,
      "grad_norm": 0.3663276435564807,
      "learning_rate": 1.4807247328689933e-06,
      "loss": 2.105,
      "step": 2233
    },
    {
      "epoch": 0.8936,
      "grad_norm": 0.37178701225741345,
      "learning_rate": 1.469763711224384e-06,
      "loss": 2.1821,
      "step": 2234
    },
    {
      "epoch": 0.894,
      "grad_norm": 0.3633049095122503,
      "learning_rate": 1.458842180975864e-06,
      "loss": 2.1519,
      "step": 2235
    },
    {
      "epoch": 0.8944,
      "grad_norm": 0.36983358369187225,
      "learning_rate": 1.4479601604533238e-06,
      "loss": 2.0718,
      "step": 2236
    },
    {
      "epoch": 0.8948,
      "grad_norm": 0.3737495754963695,
      "learning_rate": 1.4371176679203318e-06,
      "loss": 2.147,
      "step": 2237
    },
    {
      "epoch": 0.8952,
      "grad_norm": 0.3640580981887476,
      "learning_rate": 1.4263147215741235e-06,
      "loss": 2.1147,
      "step": 2238
    },
    {
      "epoch": 0.8956,
      "grad_norm": 0.349750173321334,
      "learning_rate": 1.4155513395455566e-06,
      "loss": 2.1177,
      "step": 2239
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.3614629137163345,
      "learning_rate": 1.4048275398990896e-06,
      "loss": 2.1543,
      "step": 2240
    },
    {
      "epoch": 0.8964,
      "grad_norm": 0.3611541939995502,
      "learning_rate": 1.3941433406327503e-06,
      "loss": 2.1016,
      "step": 2241
    },
    {
      "epoch": 0.8968,
      "grad_norm": 0.35656417586582084,
      "learning_rate": 1.3834987596781007e-06,
      "loss": 2.0898,
      "step": 2242
    },
    {
      "epoch": 0.8972,
      "grad_norm": 0.3739663927105937,
      "learning_rate": 1.3728938149002197e-06,
      "loss": 2.1304,
      "step": 2243
    },
    {
      "epoch": 0.8976,
      "grad_norm": 0.3644406984623081,
      "learning_rate": 1.3623285240976502e-06,
      "loss": 2.0342,
      "step": 2244
    },
    {
      "epoch": 0.898,
      "grad_norm": 0.3641870854073763,
      "learning_rate": 1.351802905002386e-06,
      "loss": 2.0981,
      "step": 2245
    },
    {
      "epoch": 0.8984,
      "grad_norm": 0.3684793974573832,
      "learning_rate": 1.3413169752798493e-06,
      "loss": 2.0806,
      "step": 2246
    },
    {
      "epoch": 0.8988,
      "grad_norm": 0.35950589608177763,
      "learning_rate": 1.3308707525288455e-06,
      "loss": 2.0981,
      "step": 2247
    },
    {
      "epoch": 0.8992,
      "grad_norm": 0.3635205247450614,
      "learning_rate": 1.320464254281531e-06,
      "loss": 2.1514,
      "step": 2248
    },
    {
      "epoch": 0.8996,
      "grad_norm": 0.3615538916471879,
      "learning_rate": 1.3100974980034015e-06,
      "loss": 2.1338,
      "step": 2249
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.35802061470293184,
      "learning_rate": 1.2997705010932393e-06,
      "loss": 2.043,
      "step": 2250
    },
    {
      "epoch": 0.9004,
      "grad_norm": 0.3577207950221075,
      "learning_rate": 1.2894832808831164e-06,
      "loss": 2.1289,
      "step": 2251
    },
    {
      "epoch": 0.9008,
      "grad_norm": 0.3601209157391939,
      "learning_rate": 1.2792358546383386e-06,
      "loss": 2.2324,
      "step": 2252
    },
    {
      "epoch": 0.9012,
      "grad_norm": 0.3605826387939412,
      "learning_rate": 1.2690282395574183e-06,
      "loss": 2.1123,
      "step": 2253
    },
    {
      "epoch": 0.9016,
      "grad_norm": 0.3593322399453818,
      "learning_rate": 1.258860452772051e-06,
      "loss": 2.165,
      "step": 2254
    },
    {
      "epoch": 0.902,
      "grad_norm": 0.36468823117103955,
      "learning_rate": 1.2487325113471032e-06,
      "loss": 2.0596,
      "step": 2255
    },
    {
      "epoch": 0.9024,
      "grad_norm": 0.3674219380116801,
      "learning_rate": 1.2386444322805529e-06,
      "loss": 2.1108,
      "step": 2256
    },
    {
      "epoch": 0.9028,
      "grad_norm": 0.36410049500040415,
      "learning_rate": 1.2285962325034818e-06,
      "loss": 2.1855,
      "step": 2257
    },
    {
      "epoch": 0.9032,
      "grad_norm": 0.3653593483035959,
      "learning_rate": 1.2185879288800383e-06,
      "loss": 2.1353,
      "step": 2258
    },
    {
      "epoch": 0.9036,
      "grad_norm": 0.3608993423872481,
      "learning_rate": 1.2086195382074145e-06,
      "loss": 2.0664,
      "step": 2259
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.37323952133743293,
      "learning_rate": 1.1986910772158104e-06,
      "loss": 2.1802,
      "step": 2260
    },
    {
      "epoch": 0.9044,
      "grad_norm": 0.36804404657041584,
      "learning_rate": 1.188802562568425e-06,
      "loss": 2.1113,
      "step": 2261
    },
    {
      "epoch": 0.9048,
      "grad_norm": 0.3627484004629711,
      "learning_rate": 1.1789540108614023e-06,
      "loss": 2.1426,
      "step": 2262
    },
    {
      "epoch": 0.9052,
      "grad_norm": 0.3561714369384183,
      "learning_rate": 1.1691454386238087e-06,
      "loss": 2.0332,
      "step": 2263
    },
    {
      "epoch": 0.9056,
      "grad_norm": 0.3654705354939019,
      "learning_rate": 1.1593768623176293e-06,
      "loss": 2.1167,
      "step": 2264
    },
    {
      "epoch": 0.906,
      "grad_norm": 0.36167706803194843,
      "learning_rate": 1.1496482983377189e-06,
      "loss": 2.1279,
      "step": 2265
    },
    {
      "epoch": 0.9064,
      "grad_norm": 0.37153236573324405,
      "learning_rate": 1.1399597630117665e-06,
      "loss": 2.144,
      "step": 2266
    },
    {
      "epoch": 0.9068,
      "grad_norm": 0.3621973169238381,
      "learning_rate": 1.130311272600293e-06,
      "loss": 2.0474,
      "step": 2267
    },
    {
      "epoch": 0.9072,
      "grad_norm": 0.35835605285142186,
      "learning_rate": 1.1207028432966004e-06,
      "loss": 2.1006,
      "step": 2268
    },
    {
      "epoch": 0.9076,
      "grad_norm": 0.3670720906199575,
      "learning_rate": 1.1111344912267646e-06,
      "loss": 2.1538,
      "step": 2269
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.36134343532358293,
      "learning_rate": 1.1016062324496008e-06,
      "loss": 2.1143,
      "step": 2270
    },
    {
      "epoch": 0.9084,
      "grad_norm": 0.36132811322446823,
      "learning_rate": 1.0921180829566196e-06,
      "loss": 2.1177,
      "step": 2271
    },
    {
      "epoch": 0.9088,
      "grad_norm": 0.3641851039900736,
      "learning_rate": 1.082670058672028e-06,
      "loss": 2.0894,
      "step": 2272
    },
    {
      "epoch": 0.9092,
      "grad_norm": 0.351733824812392,
      "learning_rate": 1.0732621754526856e-06,
      "loss": 2.0039,
      "step": 2273
    },
    {
      "epoch": 0.9096,
      "grad_norm": 0.3607714182548031,
      "learning_rate": 1.0638944490880876e-06,
      "loss": 2.1089,
      "step": 2274
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.37705305268205364,
      "learning_rate": 1.0545668953003241e-06,
      "loss": 2.1221,
      "step": 2275
    },
    {
      "epoch": 0.9104,
      "grad_norm": 0.35896917256223954,
      "learning_rate": 1.0452795297440671e-06,
      "loss": 2.1704,
      "step": 2276
    },
    {
      "epoch": 0.9108,
      "grad_norm": 0.36907591242259136,
      "learning_rate": 1.0360323680065342e-06,
      "loss": 2.0913,
      "step": 2277
    },
    {
      "epoch": 0.9112,
      "grad_norm": 0.36570542616819807,
      "learning_rate": 1.0268254256074805e-06,
      "loss": 2.1597,
      "step": 2278
    },
    {
      "epoch": 0.9116,
      "grad_norm": 0.3715422880488811,
      "learning_rate": 1.0176587179991538e-06,
      "loss": 2.2163,
      "step": 2279
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.36159709032861614,
      "learning_rate": 1.0085322605662666e-06,
      "loss": 2.1514,
      "step": 2280
    },
    {
      "epoch": 0.9124,
      "grad_norm": 0.3699545203089215,
      "learning_rate": 9.994460686259865e-07,
      "loss": 2.2124,
      "step": 2281
    },
    {
      "epoch": 0.9128,
      "grad_norm": 0.35845891653980627,
      "learning_rate": 9.904001574279038e-07,
      "loss": 2.1006,
      "step": 2282
    },
    {
      "epoch": 0.9132,
      "grad_norm": 0.362325572985731,
      "learning_rate": 9.813945421540015e-07,
      "loss": 2.1562,
      "step": 2283
    },
    {
      "epoch": 0.9136,
      "grad_norm": 0.373011566071689,
      "learning_rate": 9.724292379186374e-07,
      "loss": 2.2158,
      "step": 2284
    },
    {
      "epoch": 0.914,
      "grad_norm": 0.35879123269667357,
      "learning_rate": 9.635042597685023e-07,
      "loss": 2.1294,
      "step": 2285
    },
    {
      "epoch": 0.9144,
      "grad_norm": 0.3551587832389625,
      "learning_rate": 9.546196226826177e-07,
      "loss": 2.0713,
      "step": 2286
    },
    {
      "epoch": 0.9148,
      "grad_norm": 0.3544867584616476,
      "learning_rate": 9.457753415722997e-07,
      "loss": 2.0156,
      "step": 2287
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.36862187044149425,
      "learning_rate": 9.369714312811307e-07,
      "loss": 2.1177,
      "step": 2288
    },
    {
      "epoch": 0.9156,
      "grad_norm": 0.3598238533079547,
      "learning_rate": 9.28207906584938e-07,
      "loss": 2.0864,
      "step": 2289
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.36551889504063734,
      "learning_rate": 9.194847821917623e-07,
      "loss": 2.0942,
      "step": 2290
    },
    {
      "epoch": 0.9164,
      "grad_norm": 0.3602818680837164,
      "learning_rate": 9.108020727418537e-07,
      "loss": 2.1973,
      "step": 2291
    },
    {
      "epoch": 0.9168,
      "grad_norm": 0.3628178302894008,
      "learning_rate": 9.021597928076219e-07,
      "loss": 2.083,
      "step": 2292
    },
    {
      "epoch": 0.9172,
      "grad_norm": 0.36513513842074646,
      "learning_rate": 8.935579568936286e-07,
      "loss": 2.1191,
      "step": 2293
    },
    {
      "epoch": 0.9176,
      "grad_norm": 0.36085126462060557,
      "learning_rate": 8.849965794365506e-07,
      "loss": 2.0562,
      "step": 2294
    },
    {
      "epoch": 0.918,
      "grad_norm": 0.36465827204982953,
      "learning_rate": 8.764756748051662e-07,
      "loss": 2.1743,
      "step": 2295
    },
    {
      "epoch": 0.9184,
      "grad_norm": 0.3640769856418778,
      "learning_rate": 8.679952573003303e-07,
      "loss": 2.0576,
      "step": 2296
    },
    {
      "epoch": 0.9188,
      "grad_norm": 0.3528058444906498,
      "learning_rate": 8.595553411549439e-07,
      "loss": 2.0854,
      "step": 2297
    },
    {
      "epoch": 0.9192,
      "grad_norm": 0.3674894367081242,
      "learning_rate": 8.51155940533932e-07,
      "loss": 2.2349,
      "step": 2298
    },
    {
      "epoch": 0.9196,
      "grad_norm": 0.3655995032052605,
      "learning_rate": 8.427970695342208e-07,
      "loss": 2.1675,
      "step": 2299
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.35703612473390967,
      "learning_rate": 8.344787421847217e-07,
      "loss": 2.0513,
      "step": 2300
    },
    {
      "epoch": 0.9204,
      "grad_norm": 0.36654605767295934,
      "learning_rate": 8.262009724462893e-07,
      "loss": 2.1357,
      "step": 2301
    },
    {
      "epoch": 0.9208,
      "grad_norm": 0.36804195444715976,
      "learning_rate": 8.179637742117247e-07,
      "loss": 2.1602,
      "step": 2302
    },
    {
      "epoch": 0.9212,
      "grad_norm": 0.36854821444468827,
      "learning_rate": 8.097671613057245e-07,
      "loss": 2.1899,
      "step": 2303
    },
    {
      "epoch": 0.9216,
      "grad_norm": 0.36803944077406825,
      "learning_rate": 8.016111474848681e-07,
      "loss": 2.0688,
      "step": 2304
    },
    {
      "epoch": 0.922,
      "grad_norm": 0.361417952162124,
      "learning_rate": 7.934957464376058e-07,
      "loss": 2.1353,
      "step": 2305
    },
    {
      "epoch": 0.9224,
      "grad_norm": 0.36134086335602805,
      "learning_rate": 7.854209717842231e-07,
      "loss": 2.1221,
      "step": 2306
    },
    {
      "epoch": 0.9228,
      "grad_norm": 0.36818432806047013,
      "learning_rate": 7.773868370768183e-07,
      "loss": 2.1592,
      "step": 2307
    },
    {
      "epoch": 0.9232,
      "grad_norm": 0.3625290449077917,
      "learning_rate": 7.69393355799286e-07,
      "loss": 2.1924,
      "step": 2308
    },
    {
      "epoch": 0.9236,
      "grad_norm": 0.3628372263209284,
      "learning_rate": 7.61440541367292e-07,
      "loss": 2.0938,
      "step": 2309
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.3625516041556194,
      "learning_rate": 7.535284071282455e-07,
      "loss": 2.1846,
      "step": 2310
    },
    {
      "epoch": 0.9244,
      "grad_norm": 0.3623826737213432,
      "learning_rate": 7.456569663612772e-07,
      "loss": 2.0869,
      "step": 2311
    },
    {
      "epoch": 0.9248,
      "grad_norm": 0.35620762064945066,
      "learning_rate": 7.378262322772389e-07,
      "loss": 2.0229,
      "step": 2312
    },
    {
      "epoch": 0.9252,
      "grad_norm": 0.35601516429516833,
      "learning_rate": 7.300362180186426e-07,
      "loss": 2.0728,
      "step": 2313
    },
    {
      "epoch": 0.9256,
      "grad_norm": 0.3618184228061469,
      "learning_rate": 7.222869366596747e-07,
      "loss": 2.0786,
      "step": 2314
    },
    {
      "epoch": 0.926,
      "grad_norm": 0.36685860249124685,
      "learning_rate": 7.145784012061424e-07,
      "loss": 2.2119,
      "step": 2315
    },
    {
      "epoch": 0.9264,
      "grad_norm": 0.3616019198332285,
      "learning_rate": 7.069106245954888e-07,
      "loss": 2.1006,
      "step": 2316
    },
    {
      "epoch": 0.9268,
      "grad_norm": 0.37177352755097004,
      "learning_rate": 6.992836196967278e-07,
      "loss": 2.1484,
      "step": 2317
    },
    {
      "epoch": 0.9272,
      "grad_norm": 0.3617600666162766,
      "learning_rate": 6.916973993104675e-07,
      "loss": 2.0864,
      "step": 2318
    },
    {
      "epoch": 0.9276,
      "grad_norm": 0.35799832579954916,
      "learning_rate": 6.841519761688481e-07,
      "loss": 2.1118,
      "step": 2319
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.36274312275368137,
      "learning_rate": 6.766473629355452e-07,
      "loss": 2.1577,
      "step": 2320
    },
    {
      "epoch": 0.9284,
      "grad_norm": 0.360078868592437,
      "learning_rate": 6.691835722057477e-07,
      "loss": 2.1069,
      "step": 2321
    },
    {
      "epoch": 0.9288,
      "grad_norm": 0.3655841199512691,
      "learning_rate": 6.617606165061213e-07,
      "loss": 2.1987,
      "step": 2322
    },
    {
      "epoch": 0.9292,
      "grad_norm": 0.35990305093444647,
      "learning_rate": 6.54378508294809e-07,
      "loss": 2.1909,
      "step": 2323
    },
    {
      "epoch": 0.9296,
      "grad_norm": 0.353471186019548,
      "learning_rate": 6.470372599613833e-07,
      "loss": 2.0991,
      "step": 2324
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3590185780817161,
      "learning_rate": 6.397368838268497e-07,
      "loss": 2.0566,
      "step": 2325
    },
    {
      "epoch": 0.9304,
      "grad_norm": 0.36106175731280393,
      "learning_rate": 6.324773921436184e-07,
      "loss": 2.1187,
      "step": 2326
    },
    {
      "epoch": 0.9308,
      "grad_norm": 0.35955718749496507,
      "learning_rate": 6.252587970954821e-07,
      "loss": 2.0947,
      "step": 2327
    },
    {
      "epoch": 0.9312,
      "grad_norm": 0.360844260360399,
      "learning_rate": 6.180811107975887e-07,
      "loss": 2.0884,
      "step": 2328
    },
    {
      "epoch": 0.9316,
      "grad_norm": 0.35149737937311404,
      "learning_rate": 6.109443452964325e-07,
      "loss": 2.0669,
      "step": 2329
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.3603289157974417,
      "learning_rate": 6.038485125698295e-07,
      "loss": 2.2163,
      "step": 2330
    },
    {
      "epoch": 0.9324,
      "grad_norm": 0.3598866929609894,
      "learning_rate": 5.967936245269034e-07,
      "loss": 2.0264,
      "step": 2331
    },
    {
      "epoch": 0.9328,
      "grad_norm": 0.356097803964108,
      "learning_rate": 5.89779693008044e-07,
      "loss": 2.0967,
      "step": 2332
    },
    {
      "epoch": 0.9332,
      "grad_norm": 0.3604476857622858,
      "learning_rate": 5.828067297849155e-07,
      "loss": 2.1104,
      "step": 2333
    },
    {
      "epoch": 0.9336,
      "grad_norm": 0.35430006916500084,
      "learning_rate": 5.758747465604175e-07,
      "loss": 2.0791,
      "step": 2334
    },
    {
      "epoch": 0.934,
      "grad_norm": 0.35620167174035167,
      "learning_rate": 5.689837549686744e-07,
      "loss": 2.1084,
      "step": 2335
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.35513674750596286,
      "learning_rate": 5.621337665750181e-07,
      "loss": 2.0156,
      "step": 2336
    },
    {
      "epoch": 0.9348,
      "grad_norm": 0.3504562860798197,
      "learning_rate": 5.553247928759581e-07,
      "loss": 2.042,
      "step": 2337
    },
    {
      "epoch": 0.9352,
      "grad_norm": 0.3700085505999409,
      "learning_rate": 5.485568452991641e-07,
      "loss": 2.1587,
      "step": 2338
    },
    {
      "epoch": 0.9356,
      "grad_norm": 0.3651285906117236,
      "learning_rate": 5.418299352034529e-07,
      "loss": 2.1753,
      "step": 2339
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.35554489526933347,
      "learning_rate": 5.351440738787794e-07,
      "loss": 2.0659,
      "step": 2340
    },
    {
      "epoch": 0.9364,
      "grad_norm": 0.3575740210788103,
      "learning_rate": 5.284992725461901e-07,
      "loss": 2.0942,
      "step": 2341
    },
    {
      "epoch": 0.9368,
      "grad_norm": 0.3569684094418709,
      "learning_rate": 5.218955423578253e-07,
      "loss": 2.0684,
      "step": 2342
    },
    {
      "epoch": 0.9372,
      "grad_norm": 0.3627053320970607,
      "learning_rate": 5.153328943968915e-07,
      "loss": 2.1455,
      "step": 2343
    },
    {
      "epoch": 0.9376,
      "grad_norm": 0.35017997550655294,
      "learning_rate": 5.088113396776478e-07,
      "loss": 1.9951,
      "step": 2344
    },
    {
      "epoch": 0.938,
      "grad_norm": 0.3652041098242839,
      "learning_rate": 5.023308891453915e-07,
      "loss": 2.1538,
      "step": 2345
    },
    {
      "epoch": 0.9384,
      "grad_norm": 0.35349764334116907,
      "learning_rate": 4.958915536764252e-07,
      "loss": 2.103,
      "step": 2346
    },
    {
      "epoch": 0.9388,
      "grad_norm": 0.3618989195566433,
      "learning_rate": 4.894933440780486e-07,
      "loss": 2.1138,
      "step": 2347
    },
    {
      "epoch": 0.9392,
      "grad_norm": 0.3579838157232136,
      "learning_rate": 4.831362710885384e-07,
      "loss": 2.0713,
      "step": 2348
    },
    {
      "epoch": 0.9396,
      "grad_norm": 0.3630502946385668,
      "learning_rate": 4.7682034537713807e-07,
      "loss": 2.0874,
      "step": 2349
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3613722693436363,
      "learning_rate": 4.7054557754402373e-07,
      "loss": 2.1548,
      "step": 2350
    },
    {
      "epoch": 0.9404,
      "grad_norm": 0.3666495301698661,
      "learning_rate": 4.6431197812029925e-07,
      "loss": 2.2236,
      "step": 2351
    },
    {
      "epoch": 0.9408,
      "grad_norm": 0.3653662870232413,
      "learning_rate": 4.5811955756797086e-07,
      "loss": 2.0483,
      "step": 2352
    },
    {
      "epoch": 0.9412,
      "grad_norm": 0.36149864261799664,
      "learning_rate": 4.51968326279939e-07,
      "loss": 2.1104,
      "step": 2353
    },
    {
      "epoch": 0.9416,
      "grad_norm": 0.3555532986557938,
      "learning_rate": 4.458582945799733e-07,
      "loss": 2.0181,
      "step": 2354
    },
    {
      "epoch": 0.942,
      "grad_norm": 0.3513440982471692,
      "learning_rate": 4.397894727226931e-07,
      "loss": 2.0776,
      "step": 2355
    },
    {
      "epoch": 0.9424,
      "grad_norm": 0.36556282187743605,
      "learning_rate": 4.337618708935537e-07,
      "loss": 2.1567,
      "step": 2356
    },
    {
      "epoch": 0.9428,
      "grad_norm": 0.3581995293365843,
      "learning_rate": 4.2777549920884065e-07,
      "loss": 2.1582,
      "step": 2357
    },
    {
      "epoch": 0.9432,
      "grad_norm": 0.36333962414897103,
      "learning_rate": 4.21830367715631e-07,
      "loss": 2.2241,
      "step": 2358
    },
    {
      "epoch": 0.9436,
      "grad_norm": 0.3644008189894917,
      "learning_rate": 4.1592648639179054e-07,
      "loss": 2.2114,
      "step": 2359
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.35429201580232733,
      "learning_rate": 4.100638651459543e-07,
      "loss": 1.9951,
      "step": 2360
    },
    {
      "epoch": 0.9444,
      "grad_norm": 0.3724919396962247,
      "learning_rate": 4.042425138175071e-07,
      "loss": 2.1851,
      "step": 2361
    },
    {
      "epoch": 0.9448,
      "grad_norm": 0.35212015822180043,
      "learning_rate": 3.984624421765726e-07,
      "loss": 2.0449,
      "step": 2362
    },
    {
      "epoch": 0.9452,
      "grad_norm": 0.35455964034892845,
      "learning_rate": 3.927236599239964e-07,
      "loss": 2.1475,
      "step": 2363
    },
    {
      "epoch": 0.9456,
      "grad_norm": 0.36156903044111277,
      "learning_rate": 3.870261766913186e-07,
      "loss": 2.1313,
      "step": 2364
    },
    {
      "epoch": 0.946,
      "grad_norm": 0.3672176245811741,
      "learning_rate": 3.8137000204077065e-07,
      "loss": 2.2173,
      "step": 2365
    },
    {
      "epoch": 0.9464,
      "grad_norm": 0.36314858830879926,
      "learning_rate": 3.7575514546525634e-07,
      "loss": 2.1479,
      "step": 2366
    },
    {
      "epoch": 0.9468,
      "grad_norm": 0.3574966787353623,
      "learning_rate": 3.7018161638833203e-07,
      "loss": 2.1523,
      "step": 2367
    },
    {
      "epoch": 0.9472,
      "grad_norm": 0.3544854243577017,
      "learning_rate": 3.646494241641957e-07,
      "loss": 2.0957,
      "step": 2368
    },
    {
      "epoch": 0.9476,
      "grad_norm": 0.3627803050317926,
      "learning_rate": 3.591585780776674e-07,
      "loss": 2.1143,
      "step": 2369
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.36134895058810296,
      "learning_rate": 3.5370908734417006e-07,
      "loss": 2.1719,
      "step": 2370
    },
    {
      "epoch": 0.9484,
      "grad_norm": 0.36091441810634817,
      "learning_rate": 3.4830096110972656e-07,
      "loss": 2.1455,
      "step": 2371
    },
    {
      "epoch": 0.9488,
      "grad_norm": 0.35123184352198067,
      "learning_rate": 3.4293420845092903e-07,
      "loss": 2.0103,
      "step": 2372
    },
    {
      "epoch": 0.9492,
      "grad_norm": 0.3710177550880191,
      "learning_rate": 3.376088383749421e-07,
      "loss": 2.2007,
      "step": 2373
    },
    {
      "epoch": 0.9496,
      "grad_norm": 0.3551849434082111,
      "learning_rate": 3.323248598194634e-07,
      "loss": 2.0601,
      "step": 2374
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.362516374355003,
      "learning_rate": 3.270822816527325e-07,
      "loss": 2.1104,
      "step": 2375
    },
    {
      "epoch": 0.9504,
      "grad_norm": 0.3499386972413994,
      "learning_rate": 3.218811126735027e-07,
      "loss": 2.103,
      "step": 2376
    },
    {
      "epoch": 0.9508,
      "grad_norm": 0.3642011714498499,
      "learning_rate": 3.167213616110276e-07,
      "loss": 2.1045,
      "step": 2377
    },
    {
      "epoch": 0.9512,
      "grad_norm": 0.3638942418915895,
      "learning_rate": 3.1160303712504945e-07,
      "loss": 2.1294,
      "step": 2378
    },
    {
      "epoch": 0.9516,
      "grad_norm": 0.3622849100459254,
      "learning_rate": 3.0652614780578295e-07,
      "loss": 2.1499,
      "step": 2379
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.3603695634196293,
      "learning_rate": 3.014907021739011e-07,
      "loss": 2.1455,
      "step": 2380
    },
    {
      "epoch": 0.9524,
      "grad_norm": 0.362616401641678,
      "learning_rate": 2.964967086805187e-07,
      "loss": 2.0674,
      "step": 2381
    },
    {
      "epoch": 0.9528,
      "grad_norm": 0.35149750648370964,
      "learning_rate": 2.915441757071841e-07,
      "loss": 2.0054,
      "step": 2382
    },
    {
      "epoch": 0.9532,
      "grad_norm": 0.35291296145703016,
      "learning_rate": 2.866331115658594e-07,
      "loss": 2.0918,
      "step": 2383
    },
    {
      "epoch": 0.9536,
      "grad_norm": 0.36515235238150295,
      "learning_rate": 2.8176352449891255e-07,
      "loss": 2.0679,
      "step": 2384
    },
    {
      "epoch": 0.954,
      "grad_norm": 0.3589894463651835,
      "learning_rate": 2.7693542267908935e-07,
      "loss": 2.0957,
      "step": 2385
    },
    {
      "epoch": 0.9544,
      "grad_norm": 0.3625410175620419,
      "learning_rate": 2.721488142095191e-07,
      "loss": 2.1289,
      "step": 2386
    },
    {
      "epoch": 0.9548,
      "grad_norm": 0.3554838741926306,
      "learning_rate": 2.6740370712369235e-07,
      "loss": 2.0835,
      "step": 2387
    },
    {
      "epoch": 0.9552,
      "grad_norm": 0.35395317905264656,
      "learning_rate": 2.6270010938543865e-07,
      "loss": 2.0762,
      "step": 2388
    },
    {
      "epoch": 0.9556,
      "grad_norm": 0.3639165673734822,
      "learning_rate": 2.5803802888892947e-07,
      "loss": 2.0674,
      "step": 2389
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.37247280198377253,
      "learning_rate": 2.534174734586503e-07,
      "loss": 2.2246,
      "step": 2390
    },
    {
      "epoch": 0.9564,
      "grad_norm": 0.3612940751907455,
      "learning_rate": 2.4883845084939795e-07,
      "loss": 2.0903,
      "step": 2391
    },
    {
      "epoch": 0.9568,
      "grad_norm": 0.3681961527810607,
      "learning_rate": 2.4430096874626663e-07,
      "loss": 2.1133,
      "step": 2392
    },
    {
      "epoch": 0.9572,
      "grad_norm": 0.36419778372920303,
      "learning_rate": 2.39805034764623e-07,
      "loss": 2.0566,
      "step": 2393
    },
    {
      "epoch": 0.9576,
      "grad_norm": 0.3557615311052242,
      "learning_rate": 2.3535065645011455e-07,
      "loss": 2.0537,
      "step": 2394
    },
    {
      "epoch": 0.958,
      "grad_norm": 0.3653099113560544,
      "learning_rate": 2.3093784127863062e-07,
      "loss": 2.1929,
      "step": 2395
    },
    {
      "epoch": 0.9584,
      "grad_norm": 0.36402788052809953,
      "learning_rate": 2.2656659665631354e-07,
      "loss": 2.1333,
      "step": 2396
    },
    {
      "epoch": 0.9588,
      "grad_norm": 0.3601579925633392,
      "learning_rate": 2.2223692991953927e-07,
      "loss": 2.0518,
      "step": 2397
    },
    {
      "epoch": 0.9592,
      "grad_norm": 0.36522579598262805,
      "learning_rate": 2.1794884833489236e-07,
      "loss": 2.0693,
      "step": 2398
    },
    {
      "epoch": 0.9596,
      "grad_norm": 0.35428738799544673,
      "learning_rate": 2.1370235909917435e-07,
      "loss": 2.0454,
      "step": 2399
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3554886845871811,
      "learning_rate": 2.094974693393731e-07,
      "loss": 2.1104,
      "step": 2400
    },
    {
      "epoch": 0.9604,
      "grad_norm": 0.3609172766976815,
      "learning_rate": 2.0533418611266286e-07,
      "loss": 2.1426,
      "step": 2401
    },
    {
      "epoch": 0.9608,
      "grad_norm": 0.3614365800257143,
      "learning_rate": 2.0121251640638773e-07,
      "loss": 2.0718,
      "step": 2402
    },
    {
      "epoch": 0.9612,
      "grad_norm": 0.36209087231013776,
      "learning_rate": 1.9713246713805588e-07,
      "loss": 2.0908,
      "step": 2403
    },
    {
      "epoch": 0.9616,
      "grad_norm": 0.3619044514618699,
      "learning_rate": 1.9309404515530926e-07,
      "loss": 2.1011,
      "step": 2404
    },
    {
      "epoch": 0.962,
      "grad_norm": 0.35534368638569136,
      "learning_rate": 1.8909725723594563e-07,
      "loss": 2.0894,
      "step": 2405
    },
    {
      "epoch": 0.9624,
      "grad_norm": 0.35756952250655405,
      "learning_rate": 1.8514211008786586e-07,
      "loss": 2.0659,
      "step": 2406
    },
    {
      "epoch": 0.9628,
      "grad_norm": 0.3576166566807924,
      "learning_rate": 1.81228610349099e-07,
      "loss": 2.0752,
      "step": 2407
    },
    {
      "epoch": 0.9632,
      "grad_norm": 0.3564829577609105,
      "learning_rate": 1.7735676458777438e-07,
      "loss": 2.1104,
      "step": 2408
    },
    {
      "epoch": 0.9636,
      "grad_norm": 0.35495011210267186,
      "learning_rate": 1.7352657930210237e-07,
      "loss": 2.1289,
      "step": 2409
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.35497035692966805,
      "learning_rate": 1.6973806092038525e-07,
      "loss": 2.0635,
      "step": 2410
    },
    {
      "epoch": 0.9644,
      "grad_norm": 0.35527961659249513,
      "learning_rate": 1.6599121580099242e-07,
      "loss": 2.0239,
      "step": 2411
    },
    {
      "epoch": 0.9648,
      "grad_norm": 0.35328236412492725,
      "learning_rate": 1.6228605023234646e-07,
      "loss": 1.9497,
      "step": 2412
    },
    {
      "epoch": 0.9652,
      "grad_norm": 0.3620202261793159,
      "learning_rate": 1.586225704329203e-07,
      "loss": 2.0713,
      "step": 2413
    },
    {
      "epoch": 0.9656,
      "grad_norm": 0.353818925428642,
      "learning_rate": 1.5500078255122617e-07,
      "loss": 2.0596,
      "step": 2414
    },
    {
      "epoch": 0.966,
      "grad_norm": 0.364309333257813,
      "learning_rate": 1.5142069266580462e-07,
      "loss": 2.1836,
      "step": 2415
    },
    {
      "epoch": 0.9664,
      "grad_norm": 0.35190440640903037,
      "learning_rate": 1.478823067852131e-07,
      "loss": 2.1094,
      "step": 2416
    },
    {
      "epoch": 0.9668,
      "grad_norm": 0.358943637847783,
      "learning_rate": 1.4438563084801237e-07,
      "loss": 2.0293,
      "step": 2417
    },
    {
      "epoch": 0.9672,
      "grad_norm": 0.3694434768499443,
      "learning_rate": 1.409306707227609e-07,
      "loss": 2.1367,
      "step": 2418
    },
    {
      "epoch": 0.9676,
      "grad_norm": 0.3634479273768039,
      "learning_rate": 1.3751743220801195e-07,
      "loss": 2.1572,
      "step": 2419
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.3521165044330895,
      "learning_rate": 1.3414592103228595e-07,
      "loss": 2.0269,
      "step": 2420
    },
    {
      "epoch": 0.9684,
      "grad_norm": 0.36673353893021415,
      "learning_rate": 1.3081614285408162e-07,
      "loss": 2.2153,
      "step": 2421
    },
    {
      "epoch": 0.9688,
      "grad_norm": 0.3691468188740762,
      "learning_rate": 1.2752810326184529e-07,
      "loss": 2.1177,
      "step": 2422
    },
    {
      "epoch": 0.9692,
      "grad_norm": 0.367444441186893,
      "learning_rate": 1.2428180777397658e-07,
      "loss": 2.1182,
      "step": 2423
    },
    {
      "epoch": 0.9696,
      "grad_norm": 0.35542572095429115,
      "learning_rate": 1.2107726183882283e-07,
      "loss": 2.104,
      "step": 2424
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.36023974896193084,
      "learning_rate": 1.1791447083465134e-07,
      "loss": 2.1313,
      "step": 2425
    },
    {
      "epoch": 0.9704,
      "grad_norm": 0.3791803060544363,
      "learning_rate": 1.1479344006965486e-07,
      "loss": 2.2417,
      "step": 2426
    },
    {
      "epoch": 0.9708,
      "grad_norm": 0.351029520417569,
      "learning_rate": 1.117141747819378e-07,
      "loss": 1.9976,
      "step": 2427
    },
    {
      "epoch": 0.9712,
      "grad_norm": 0.35775019156647403,
      "learning_rate": 1.086766801395106e-07,
      "loss": 2.1406,
      "step": 2428
    },
    {
      "epoch": 0.9716,
      "grad_norm": 0.3610448625252007,
      "learning_rate": 1.0568096124028148e-07,
      "loss": 2.105,
      "step": 2429
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.35469848082472466,
      "learning_rate": 1.0272702311203696e-07,
      "loss": 2.1113,
      "step": 2430
    },
    {
      "epoch": 0.9724,
      "grad_norm": 0.3594980086634506,
      "learning_rate": 9.981487071245021e-08,
      "loss": 2.0352,
      "step": 2431
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.3700419438596762,
      "learning_rate": 9.694450892905882e-08,
      "loss": 2.1699,
      "step": 2432
    },
    {
      "epoch": 0.9732,
      "grad_norm": 0.3601234330941595,
      "learning_rate": 9.411594257926481e-08,
      "loss": 2.1343,
      "step": 2433
    },
    {
      "epoch": 0.9736,
      "grad_norm": 0.360234304656069,
      "learning_rate": 9.132917641032634e-08,
      "loss": 2.0508,
      "step": 2434
    },
    {
      "epoch": 0.974,
      "grad_norm": 0.3605742305316678,
      "learning_rate": 8.858421509933823e-08,
      "loss": 2.1797,
      "step": 2435
    },
    {
      "epoch": 0.9744,
      "grad_norm": 0.35316087910775223,
      "learning_rate": 8.588106325324308e-08,
      "loss": 2.0688,
      "step": 2436
    },
    {
      "epoch": 0.9748,
      "grad_norm": 0.35630115780547766,
      "learning_rate": 8.321972540880907e-08,
      "loss": 2.1206,
      "step": 2437
    },
    {
      "epoch": 0.9752,
      "grad_norm": 0.364876870611971,
      "learning_rate": 8.060020603262441e-08,
      "loss": 2.1733,
      "step": 2438
    },
    {
      "epoch": 0.9756,
      "grad_norm": 0.35923409937316675,
      "learning_rate": 7.80225095211029e-08,
      "loss": 2.1636,
      "step": 2439
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.3642714000937072,
      "learning_rate": 7.54866402004506e-08,
      "loss": 2.1455,
      "step": 2440
    },
    {
      "epoch": 0.9764,
      "grad_norm": 0.3615262755807048,
      "learning_rate": 7.299260232668525e-08,
      "loss": 2.124,
      "step": 2441
    },
    {
      "epoch": 0.9768,
      "grad_norm": 0.3659888885807962,
      "learning_rate": 7.054040008561136e-08,
      "loss": 2.0918,
      "step": 2442
    },
    {
      "epoch": 0.9772,
      "grad_norm": 0.36233735589973864,
      "learning_rate": 6.813003759282844e-08,
      "loss": 2.0869,
      "step": 2443
    },
    {
      "epoch": 0.9776,
      "grad_norm": 0.36426246464178513,
      "learning_rate": 6.57615188937033e-08,
      "loss": 2.1294,
      "step": 2444
    },
    {
      "epoch": 0.978,
      "grad_norm": 0.3526675402323109,
      "learning_rate": 6.343484796338395e-08,
      "loss": 2.0698,
      "step": 2445
    },
    {
      "epoch": 0.9784,
      "grad_norm": 0.36387436868259493,
      "learning_rate": 6.115002870678288e-08,
      "loss": 2.1548,
      "step": 2446
    },
    {
      "epoch": 0.9788,
      "grad_norm": 0.35899161826825904,
      "learning_rate": 5.890706495856879e-08,
      "loss": 2.123,
      "step": 2447
    },
    {
      "epoch": 0.9792,
      "grad_norm": 0.36449982736792674,
      "learning_rate": 5.6705960483166564e-08,
      "loss": 2.1704,
      "step": 2448
    },
    {
      "epoch": 0.9796,
      "grad_norm": 0.35342354965180944,
      "learning_rate": 5.4546718974740616e-08,
      "loss": 2.0537,
      "step": 2449
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.3606454343201096,
      "learning_rate": 5.242934405720879e-08,
      "loss": 2.1362,
      "step": 2450
    },
    {
      "epoch": 0.9804,
      "grad_norm": 0.36294931749621,
      "learning_rate": 5.0353839284209e-08,
      "loss": 2.1455,
      "step": 2451
    },
    {
      "epoch": 0.9808,
      "grad_norm": 0.363688931785001,
      "learning_rate": 4.832020813911875e-08,
      "loss": 2.1533,
      "step": 2452
    },
    {
      "epoch": 0.9812,
      "grad_norm": 0.3611857800191968,
      "learning_rate": 4.632845403503283e-08,
      "loss": 2.1274,
      "step": 2453
    },
    {
      "epoch": 0.9816,
      "grad_norm": 0.3618336533985919,
      "learning_rate": 4.4378580314757835e-08,
      "loss": 2.1982,
      "step": 2454
    },
    {
      "epoch": 0.982,
      "grad_norm": 0.35664713446523183,
      "learning_rate": 4.247059025082323e-08,
      "loss": 2.0527,
      "step": 2455
    },
    {
      "epoch": 0.9824,
      "grad_norm": 0.3571193282215033,
      "learning_rate": 4.060448704545083e-08,
      "loss": 2.1636,
      "step": 2456
    },
    {
      "epoch": 0.9828,
      "grad_norm": 0.3537284958682915,
      "learning_rate": 3.8780273830574255e-08,
      "loss": 2.1602,
      "step": 2457
    },
    {
      "epoch": 0.9832,
      "grad_norm": 0.35444207049156773,
      "learning_rate": 3.699795366781389e-08,
      "loss": 2.0952,
      "step": 2458
    },
    {
      "epoch": 0.9836,
      "grad_norm": 0.3637753173298729,
      "learning_rate": 3.525752954848804e-08,
      "loss": 2.1655,
      "step": 2459
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.35527274794849284,
      "learning_rate": 3.355900439359072e-08,
      "loss": 2.1807,
      "step": 2460
    },
    {
      "epoch": 0.9844,
      "grad_norm": 0.36081314820794524,
      "learning_rate": 3.190238105379995e-08,
      "loss": 2.0942,
      "step": 2461
    },
    {
      "epoch": 0.9848,
      "grad_norm": 0.3610996217226918,
      "learning_rate": 3.028766230946945e-08,
      "loss": 2.1016,
      "step": 2462
    },
    {
      "epoch": 0.9852,
      "grad_norm": 0.36173098823560773,
      "learning_rate": 2.8714850870623087e-08,
      "loss": 2.1929,
      "step": 2463
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.361981262577762,
      "learning_rate": 2.7183949376952122e-08,
      "loss": 2.0181,
      "step": 2464
    },
    {
      "epoch": 0.986,
      "grad_norm": 0.3624095745037414,
      "learning_rate": 2.5694960397806833e-08,
      "loss": 2.0913,
      "step": 2465
    },
    {
      "epoch": 0.9864,
      "grad_norm": 0.36371523308105264,
      "learning_rate": 2.4247886432193777e-08,
      "loss": 2.0659,
      "step": 2466
    },
    {
      "epoch": 0.9868,
      "grad_norm": 0.36459829459312854,
      "learning_rate": 2.2842729908775784e-08,
      "loss": 2.1099,
      "step": 2467
    },
    {
      "epoch": 0.9872,
      "grad_norm": 0.3518493628597441,
      "learning_rate": 2.1479493185860845e-08,
      "loss": 2.0791,
      "step": 2468
    },
    {
      "epoch": 0.9876,
      "grad_norm": 0.3563651033564378,
      "learning_rate": 2.015817855140767e-08,
      "loss": 2.0742,
      "step": 2469
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.36178882439798155,
      "learning_rate": 1.8878788223009036e-08,
      "loss": 2.1621,
      "step": 2470
    },
    {
      "epoch": 0.9884,
      "grad_norm": 0.3644231446119855,
      "learning_rate": 1.7641324347897336e-08,
      "loss": 2.2666,
      "step": 2471
    },
    {
      "epoch": 0.9888,
      "grad_norm": 0.3590887521507252,
      "learning_rate": 1.6445789002944577e-08,
      "loss": 2.1577,
      "step": 2472
    },
    {
      "epoch": 0.9892,
      "grad_norm": 0.3509194172973477,
      "learning_rate": 1.529218419464573e-08,
      "loss": 2.0312,
      "step": 2473
    },
    {
      "epoch": 0.9896,
      "grad_norm": 0.35905170427747746,
      "learning_rate": 1.4180511859124279e-08,
      "loss": 2.1143,
      "step": 2474
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.362142047807131,
      "learning_rate": 1.3110773862126669e-08,
      "loss": 2.0464,
      "step": 2475
    },
    {
      "epoch": 0.9904,
      "grad_norm": 0.3485547930798265,
      "learning_rate": 1.2082971999025084e-08,
      "loss": 1.9819,
      "step": 2476
    },
    {
      "epoch": 0.9908,
      "grad_norm": 0.36057154541718967,
      "learning_rate": 1.1097107994806344e-08,
      "loss": 2.0845,
      "step": 2477
    },
    {
      "epoch": 0.9912,
      "grad_norm": 0.35720923176778296,
      "learning_rate": 1.015318350406913e-08,
      "loss": 2.1523,
      "step": 2478
    },
    {
      "epoch": 0.9916,
      "grad_norm": 0.35041327856117105,
      "learning_rate": 9.251200111023984e-09,
      "loss": 2.0786,
      "step": 2479
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.35565296787873063,
      "learning_rate": 8.39115932949608e-09,
      "loss": 2.1685,
      "step": 2480
    },
    {
      "epoch": 0.9924,
      "grad_norm": 0.35904282976412943,
      "learning_rate": 7.573062602911351e-09,
      "loss": 2.2222,
      "step": 2481
    },
    {
      "epoch": 0.9928,
      "grad_norm": 0.3557280546532279,
      "learning_rate": 6.79691130430482e-09,
      "loss": 2.1504,
      "step": 2482
    },
    {
      "epoch": 0.9932,
      "grad_norm": 0.3545678056258402,
      "learning_rate": 6.062706736306712e-09,
      "loss": 2.1768,
      "step": 2483
    },
    {
      "epoch": 0.9936,
      "grad_norm": 0.36989330462655434,
      "learning_rate": 5.370450131156335e-09,
      "loss": 2.1362,
      "step": 2484
    },
    {
      "epoch": 0.994,
      "grad_norm": 0.3661589904831377,
      "learning_rate": 4.720142650685433e-09,
      "loss": 2.1553,
      "step": 2485
    },
    {
      "epoch": 0.9944,
      "grad_norm": 0.3835547268573784,
      "learning_rate": 4.111785386318179e-09,
      "loss": 2.0767,
      "step": 2486
    },
    {
      "epoch": 0.9948,
      "grad_norm": 0.37781101330952416,
      "learning_rate": 3.545379359076728e-09,
      "loss": 2.1348,
      "step": 2487
    },
    {
      "epoch": 0.9952,
      "grad_norm": 0.3565556450720903,
      "learning_rate": 3.020925519575668e-09,
      "loss": 2.1089,
      "step": 2488
    },
    {
      "epoch": 0.9956,
      "grad_norm": 0.36193844562803984,
      "learning_rate": 2.538424748022017e-09,
      "loss": 2.1616,
      "step": 2489
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.34982489511346543,
      "learning_rate": 2.0978778542041222e-09,
      "loss": 2.0146,
      "step": 2490
    },
    {
      "epoch": 0.9964,
      "grad_norm": 0.35510902913031467,
      "learning_rate": 1.6992855775055382e-09,
      "loss": 2.0864,
      "step": 2491
    },
    {
      "epoch": 0.9968,
      "grad_norm": 0.35356782454807445,
      "learning_rate": 1.3426485868939242e-09,
      "loss": 2.1206,
      "step": 2492
    },
    {
      "epoch": 0.9972,
      "grad_norm": 0.37005232336790816,
      "learning_rate": 1.0279674809210438e-09,
      "loss": 2.1602,
      "step": 2493
    },
    {
      "epoch": 0.9976,
      "grad_norm": 0.3560521357159848,
      "learning_rate": 7.552427877283164e-10,
      "loss": 2.0391,
      "step": 2494
    },
    {
      "epoch": 0.998,
      "grad_norm": 0.3570869040530189,
      "learning_rate": 5.244749650301639e-10,
      "loss": 2.1567,
      "step": 2495
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.3594235753330622,
      "learning_rate": 3.3566440013621526e-10,
      "loss": 2.0986,
      "step": 2496
    },
    {
      "epoch": 0.9988,
      "grad_norm": 0.35893955890976664,
      "learning_rate": 1.8881140992632606e-10,
      "loss": 2.1323,
      "step": 2497
    },
    {
      "epoch": 0.9992,
      "grad_norm": 0.3520666368167298,
      "learning_rate": 8.391624087278338e-11,
      "loss": 2.0454,
      "step": 2498
    },
    {
      "epoch": 0.9996,
      "grad_norm": 0.36649361689509624,
      "learning_rate": 2.0979069020876653e-11,
      "loss": 2.1094,
      "step": 2499
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.35944703877317,
      "learning_rate": 0.0,
      "loss": 2.1401,
      "step": 2500
    }
  ],
  "logging_steps": 1,
  "max_steps": 2500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 2500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1691101094215680.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
